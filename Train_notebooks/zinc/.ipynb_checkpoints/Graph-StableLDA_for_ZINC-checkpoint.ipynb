{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d9881",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e55d9881",
    "outputId": "2c6b6f8d-31f6-477f-85e7-d27396f5a714"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "root = '/'\n",
    "pprint.pprint(sys.path)\n",
    "\n",
    "sys.path.append(import_path)\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49371560-39f9-4463-8d46-1bfb7329595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "import_path = root + 'pigvae_all'\n",
    "sys.path.append(import_path)\n",
    "pprint.pprint(sys.path)\n",
    "\n",
    "import_path1 = root + 'pigvae_all/pigvae'\n",
    "sys.path.append(import_path1)\n",
    "pprint.pprint(sys.path)\n",
    "\n",
    "import_path2 = root + 'ddpm-torch'\n",
    "sys.path.append(import_path2)\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4b829",
   "metadata": {
    "id": "62f4b829"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f58ea",
   "metadata": {
    "id": "958f58ea"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "#import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.dense import floyd_warshall_numpy\n",
    "\n",
    "from networkx.generators.random_graphs import *\n",
    "from networkx.generators.ego import ego_graph\n",
    "from networkx.generators.geometric import random_geometric_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be3ff5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9be3ff5",
    "outputId": "3f1bf291-cc0d-43d3-c9c3-c4dfe0fd7299"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-9f298e5238d8>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(root + 'zinc_gdata/tensor_data.pkl')\n"
     ]
    }
   ],
   "source": [
    "loaded_data = torch.load(root + 'dataset/train_dataset/zinc_gdata/tensor_data.pkl')\n",
    "\n",
    "# 各テンソルにアクセス\n",
    "node_features = loaded_data['node_features']\n",
    "edge_features = loaded_data['edge_features']\n",
    "mask = loaded_data['mask']\n",
    "props = loaded_data['props']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d433a13",
   "metadata": {
    "id": "7d433a13"
   },
   "outputs": [],
   "source": [
    "num_node_f, num_edge_f = 43, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb765c38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb765c38",
    "outputId": "f7728c2f-c79b-42d0-be35-bb252b5ecdc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([75000, 26, 43]),\n",
       " torch.Size([75000, 26, 26, 13]),\n",
       " torch.Size([75000, 26]),\n",
       " torch.Size([75000]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape, edge_features.shape, mask.shape, props.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c7e34",
   "metadata": {
    "id": "350c7e34"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(node_features[0:50000], edge_features[0:50000], mask[0:50000], props[0:50000])\n",
    "val_dataset = torch.utils.data.TensorDataset(node_features[50000:60000], edge_features[50000:60000], mask[50000:60000], props[50000:60000])\n",
    "test_dataset = torch.utils.data.TensorDataset(node_features[60000:70000], edge_features[60000:70000], mask[60000:70000], props[60000:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4bd79",
   "metadata": {
    "id": "c8b4bd79"
   },
   "outputs": [],
   "source": [
    "n_batch = 20\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=n_batch, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=n_batch, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=n_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93691d",
   "metadata": {
    "id": "ac93691d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e664c",
   "metadata": {
    "id": "5b6e664c"
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"vae\":True,\n",
    "    \"kld_loss_scale\":0.01,\n",
    "    \"perm_loss_scale\":0.1,\n",
    "    \"property_loss_scale\":0.5,\n",
    "    \"num_node_features\":num_node_f,\n",
    "    \"num_edge_features\":6+num_edge_f+1,\n",
    "    \"emb_dim\": 90,\n",
    "    'graph_encoder_hidden_dim': 256,\n",
    "    'graph_encoder_k_dim': 64,\n",
    "    'graph_encoder_v_dim': 64,\n",
    "    'graph_encoder_num_heads': 16,\n",
    "    'graph_encoder_ppf_hidden_dim': 512,\n",
    "    'graph_encoder_num_layers': 16,\n",
    "    'graph_decoder_hidden_dim': 256,\n",
    "    'graph_decoder_k_dim': 64,\n",
    "    'graph_decoder_v_dim': 64,\n",
    "    'graph_decoder_num_heads': 16,\n",
    "    'graph_decoder_ppf_hidden_dim': 512,\n",
    "    'graph_decoder_num_layers': 16,\n",
    "    \"graph_decoder_pos_emb_dim\": 64,\n",
    "    'property_predictor_hidden_dim': 3,\n",
    "    'num_properties': 1\n",
    "}\n",
    "\n",
    "model_load_dir = root + 'save_models/pig-ae_models/'\n",
    "model_save_dir = root + 'save_models/pig-beta-diffvae_with_trained-ae_models/'\n",
    "\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7W7b4mNh8J_",
   "metadata": {
    "id": "k7W7b4mNh8J_"
   },
   "outputs": [],
   "source": [
    "load_model_path1 = model_load_dir + \"pig_enc\" + \".pt\"\n",
    "load_model_path2 = model_load_dir + \"pig_dec\" + \".pt\"\n",
    "load_model_path3 = model_load_dir + \"pig_bn_enc\" + \".pt\"\n",
    "load_model_path4 = model_load_dir + \"pig_bn_dec\" + \".pt\"\n",
    "load_model_path5 = model_load_dir + \"pig_prop\" + \".pt\"\n",
    "load_model_path6 = model_load_dir + \"pig_perm\" + \".pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34XXLgQPihx0",
   "metadata": {
    "id": "34XXLgQPihx0"
   },
   "outputs": [],
   "source": [
    "load_ddpm_path = model_load_dir + \"ddpm/ddpm_best_model\" + \".pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T1-yKkGbih55",
   "metadata": {
    "id": "T1-yKkGbih55"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear, LayerNorm, Dropout\n",
    "from torch.nn.functional import relu, pad\n",
    "from pigvae.graph_transformer import Transformer, PositionalEncoding\n",
    "from pigvae.models import GraphEncoder, GraphDecoder, Permuter\n",
    "from torch import nn\n",
    "from torch.nn import Linear, LayerNorm, Dropout\n",
    "from torch.nn.functional import relu, pad\n",
    "from pigvae.graph_transformer import Transformer, PositionalEncoding\n",
    "from pigvae.models import GraphAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb7c17",
   "metadata": {
    "id": "b3fb7c17"
   },
   "source": [
    "## Denoising Model Calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7e48b",
   "metadata": {
    "id": "88f7e48b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from ddpm_torch.utils import seed_all, infer_range\n",
    "from ddpm_torch.toy import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ddpm_torch.modules import Linear, Sequential\n",
    "from ddpm_torch.functions import get_timestep_embedding\n",
    "\n",
    "\n",
    "DEFAULT_NORMALIZER = nn.LayerNorm\n",
    "DEFAULT_NONLINEARITY = nn.LeakyReLU(negative_slope=0.02, inplace=True)\n",
    "\n",
    "\n",
    "class TemporalLayer(nn.Module):\n",
    "    normalize = DEFAULT_NORMALIZER\n",
    "    nonlinearity = DEFAULT_NONLINEARITY\n",
    "\n",
    "    def __init__(self, in_features, out_features, temporal_features):\n",
    "        super(TemporalLayer, self).__init__()\n",
    "        self.norm1 = self.normalize(in_features)\n",
    "        self.fc1 = Linear(in_features, out_features, bias=False)\n",
    "        self.norm2 = self.normalize(out_features)\n",
    "        self.fc2 = Linear(out_features, out_features, bias=False)\n",
    "        self.enc = Linear(temporal_features, out_features)\n",
    "\n",
    "        self.skip = nn.Identity() if in_features == out_features else Linear(in_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        out = self.fc1(self.nonlinearity(self.norm1(x)))\n",
    "        out += self.enc(t_emb)\n",
    "        out = self.fc2(self.nonlinearity(self.norm2(out)))\n",
    "        skip = self.skip(x)\n",
    "        return out + skip\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    normalize = DEFAULT_NORMALIZER\n",
    "    nonlinearity = DEFAULT_NONLINEARITY\n",
    "\n",
    "    def __init__(self, in_features, mid_features, num_temporal_layers):\n",
    "        super(Denoiser, self).__init__()\n",
    "\n",
    "        self.in_fc = Linear(in_features, mid_features, bias=False)\n",
    "        self.temp_fc = Sequential(*([TemporalLayer(\n",
    "            mid_features, mid_features, mid_features), ] * num_temporal_layers))\n",
    "        self.out_norm = self.normalize(mid_features)\n",
    "        self.out_fc = Linear(mid_features, in_features)\n",
    "        self.t_proj = nn.Sequential(\n",
    "            Linear(mid_features, mid_features),\n",
    "            self.nonlinearity)\n",
    "        self.mid_features = mid_features\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = get_timestep_embedding(t, self.mid_features)\n",
    "        t_emb = self.t_proj(t_emb)\n",
    "        out = self.in_fc(x)\n",
    "        out = self.temp_fc(out, t_emb=t_emb)\n",
    "        out = self.out_fc(self.out_norm(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a41ed7",
   "metadata": {
    "id": "65a41ed7"
   },
   "outputs": [],
   "source": [
    "# denoising model parameters\n",
    "model_mean_type = \"eps\"\n",
    "model_var_type = \"fixed-large\"\n",
    "loss_type = \"mse\"\n",
    "lat_dim = 90\n",
    "in_features = lat_dim\n",
    "out_features = 2 * in_features if model_var_type == \"learned\" else in_features\n",
    "mid_features = 256\n",
    "num_temporal_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249082c",
   "metadata": {
    "id": "9249082c"
   },
   "outputs": [],
   "source": [
    "# diffusion parameters\n",
    "beta_schedule = \"linear\"\n",
    "beta_start, beta_end = 0.001, 0.2\n",
    "timesteps = 1000\n",
    "betas = get_beta_schedule(beta_schedule, beta_start=beta_start, beta_end=beta_end, timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07111ebd",
   "metadata": {
    "id": "07111ebd"
   },
   "source": [
    "## Graph Latent Diffusion Variational Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WdA_GZI8ipjw",
   "metadata": {
    "id": "WdA_GZI8ipjw"
   },
   "outputs": [],
   "source": [
    "from pigvae.models import GraphEncoder, GraphDecoder, Permuter\n",
    "from pigvae.models import BottleNeckEncoder, BottleNeckDecoder, PropertyPredictor\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, Dropout\n",
    "from torch.nn.functional import relu, pad\n",
    "from pigvae.graph_transformer import Transformer, PositionalEncoding\n",
    "from pigvae.synthetic_graphs.data import DenseGraphBatch\n",
    "\n",
    "\n",
    "class GraphLDA(torch.nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        #self.vae = hparams[\"vae\"]\n",
    "        self.encoder = GraphEncoder(hparams)\n",
    "        self.bottle_neck_encoder = BottleNeckEncoder(hparams)\n",
    "        self.bottle_neck_decoder = BottleNeckDecoder(hparams)\n",
    "        self.property_predictor = PropertyPredictor(hparams)\n",
    "        self.permuter = Permuter(hparams)\n",
    "        self.decoder = GraphDecoder(hparams)\n",
    "\n",
    "        self.dense_fn = Denoiser(in_features, mid_features, num_temporal_layers)\n",
    "        self.diffusion = GaussianDiffusion(betas=betas, model_mean_type=model_mean_type, model_var_type=model_var_type, loss_type=loss_type)\n",
    "\n",
    "    def encode(self, node_features, edge_features, mask):\n",
    "\n",
    "        graph_emb, node_features = self.encoder(\n",
    "            node_features=node_features,\n",
    "            edge_features=edge_features,\n",
    "            mask=mask,\n",
    "        )\n",
    "        graph_emb, mu, logvar = self.bottle_neck_encoder(graph_emb)\n",
    "        return  graph_emb, mu, logvar, node_features\n",
    "\n",
    "    def decode(self, graph_emb, perm, mask=None):\n",
    "        props = self.property_predictor(graph_emb).squeeze()\n",
    "\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            num_nodes = torch.round(props * STD_NUM_NODES + MEAN_NUM_NODES).long()\n",
    "            mask = torch.arange(max(num_nodes)).type_as(num_nodes).unsqueeze(0) < num_nodes.unsqueeze(1)\n",
    "        \"\"\"\n",
    "\n",
    "        graph_emb = self.bottle_neck_decoder(graph_emb)\n",
    "        node_logits, edge_logits = self.decoder(\n",
    "            graph_emb=graph_emb,\n",
    "            perm=perm,\n",
    "            mask=mask\n",
    "        )\n",
    "\n",
    "        return node_logits, edge_logits, props\n",
    "\n",
    "    def forward(self, node_features, edge_features, mask, training, tau):\n",
    "        graph_emb, mu, logvar, node_features = self.encode(node_features, edge_features, mask)\n",
    "        perm = self.permuter(node_features, mask=mask, hard=not training, tau=tau)\n",
    "\n",
    "        #diffusion process\n",
    "        z_0 = graph_emb\n",
    "        B = z_0.shape[0]\n",
    "        T = self.diffusion.timesteps\n",
    "        t = torch.randint(T, size=(B, ), dtype=torch.int64, device=device)\n",
    "        t_noise = torch.randn_like(graph_emb)\n",
    "        z_t = self.diffusion.q_sample(z_0, t, noise=t_noise)\n",
    "\n",
    "        #denoising\n",
    "        model_out = self.dense_fn(z_t, t) #model_out : 出力, t_noise : 予測するターゲット\n",
    "\n",
    "        #deocde from noisy latent vector\n",
    "        graph_pred = self.decode(z_0, perm, mask)\n",
    "\n",
    "        return graph_pred, perm, graph_emb, mu, logvar, model_out, t_noise\n",
    "\n",
    "class BottleNeckEncoder(torch.nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.d_in = hparams[\"graph_encoder_hidden_dim\"]\n",
    "        self.d_out = hparams[\"emb_dim\"]\n",
    "        self.wu = Linear(self.d_in, self.d_out)\n",
    "        self.wv = Linear(self.d_in, self.d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu = self.wu(relu(x))\n",
    "        logvar = self.wv(relu(x))\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88b799",
   "metadata": {
    "id": "7b88b799"
   },
   "outputs": [],
   "source": [
    "model = GraphLDA(hparams).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930ae31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4930ae31",
    "outputId": "25d04948-8502-4a2e-f936-ac4136e19c60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-695f9bcaa5f4>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.encoder = torch.load(load_model_path1)\n",
      "<ipython-input-25-695f9bcaa5f4>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.decoder = torch.load(load_model_path2)\n",
      "<ipython-input-25-695f9bcaa5f4>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.bottle_neck_encoder.wu = torch.load(load_model_path3)\n",
      "<ipython-input-25-695f9bcaa5f4>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.bottle_neck_decoder = torch.load(load_model_path4)\n",
      "<ipython-input-25-695f9bcaa5f4>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.property_predictor = torch.load(load_model_path5)\n",
      "<ipython-input-25-695f9bcaa5f4>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.permuter = torch.load(load_model_path6)\n",
      "<ipython-input-25-695f9bcaa5f4>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.dense_fn = torch.load(load_ddpm_path)\n"
     ]
    }
   ],
   "source": [
    "model.encoder = torch.load(load_model_path1)\n",
    "model.decoder = torch.load(load_model_path2)\n",
    "model.bottle_neck_encoder.wu = torch.load(load_model_path3)\n",
    "model.bottle_neck_decoder = torch.load(load_model_path4)\n",
    "model.property_predictor = torch.load(load_model_path5)\n",
    "model.permuter = torch.load(load_model_path6)\n",
    "model.dense_fn = torch.load(load_ddpm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b243f08",
   "metadata": {
    "id": "6b243f08"
   },
   "outputs": [],
   "source": [
    "from pigvae.synthetic_graphs.critic_zinc import Critic\n",
    "\n",
    "critic = Critic(hparams, device)\n",
    "lr=0.00001\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.encoder.parameters()},\n",
    "    {'params': model.decoder.parameters()},\n",
    "    {'params': model.bottle_neck_encoder.parameters()},\n",
    "    {'params': model.bottle_neck_decoder.parameters()},\n",
    "    {'params': model.property_predictor.parameters()},\n",
    "    {'params': model.permuter.parameters()},\n",
    "    {'params': model.dense_fn.parameters(), 'lr': 0.0001}\n",
    "], lr=lr, betas=(0.9, 0.98))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee79c4e",
   "metadata": {
    "id": "0ee79c4e"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6cc6a",
   "metadata": {
    "id": "6af6cc6a"
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "def val_preds(epoch):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    sum_errors = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(val_loader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                node_features, edge_features, mask, props = batch_data\n",
    "                node_features, edge_features, mask, props = node_features.to(device), edge_features.to(device), mask.to(device), props.to(device)\n",
    "\n",
    "            graph_pred, perm, graph_emb, mu, logvar, model_out, t_noise = model(node_features, edge_features, mask, training=True, tau=1.0)\n",
    "            node_logits, edge_logits, pred_props = graph_pred\n",
    "\n",
    "            vae_loss = critic(node_features, edge_features, props, node_logits, edge_logits, pred_props, mask, perm, mu, logvar)\n",
    "\n",
    "            batch_vae_loss = vae_loss['node_loss'] * 10 + vae_loss['edge_loss'] * 10 + vae_loss['perm_loss'] * 0.1\n",
    "            diffusion_loss = torch.sum((t_noise - model_out).pow(2), dim = 1).mean()\n",
    "            negative_entropy = - torch.mean(torch.sum(logvar,dim=1))\n",
    "            batch_all_loss = batch_vae_loss + diffusion_loss * beta + negative_entropy.data * gamma\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(vae_loss)\n",
    "                print(\"Epoch (val) : \", epoch, \"  batch (val) : \", batch_idx , \"Loss sum : \", batch_all_loss.data.item(), \"dsm : \", diffusion_loss.data.item(), \"neg entropy : \", negative_entropy.data.item())\n",
    "\n",
    "            sum_errors = sum_errors + vae_loss['node_loss'].data.item() * 10 + vae_loss['edge_loss'].data.item() * 10 \\\n",
    "             + diffusion_loss.data.item() * beta + negative_entropy.data.item() * gamma\n",
    "\n",
    "            del batch_all_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return sum_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d5067",
   "metadata": {
    "id": "2b9d5067"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# テキストファイルのパスを指定\n",
    "log_path = model_save_dir + 'log.txt'\n",
    "\n",
    "f = open(log_path, 'w')\n",
    "f.write('train -- logs')\n",
    "f.close()\n",
    "\n",
    "def logging_txt(epoch):\n",
    "    dt_now = datetime.datetime.now()\n",
    "\n",
    "    # ファイルを読み込んで、末尾の行を取得\n",
    "    with open(log_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        last_line = lines[-1].strip()\n",
    "\n",
    "    # 末尾の行に追記する文字列を指定\n",
    "    append_string = \"epoch \" + str(epoch) + \" : \" + str(dt_now)\n",
    "\n",
    "    # ファイルに追記\n",
    "    with open(log_path, 'a') as file:\n",
    "        file.write('\\n' + append_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005570c3",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "005570c3",
    "outputId": "4a2620bb-be79-4c3f-d9af-f8ba15105636",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7780, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4098, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.8905, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2220  Loss :  0.5800220370292664 dsm :  0.49170637130737305 neg entropy :  556.2369384765625\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7263, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3400, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0544, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2230  Loss :  0.607532262802124 dsm :  1.548179030418396 neg entropy :  558.16357421875\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8127, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3936, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.9408, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2240  Loss :  0.525543749332428 dsm :  1.2876821756362915 neg entropy :  561.3505249023438\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0921, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.2546, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2250  Loss :  0.5385955572128296 dsm :  0.2688468396663666 neg entropy :  564.0960083007812\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5098, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3723, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.0267, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2260  Loss :  0.49728089570999146 dsm :  0.6822614073753357 neg entropy :  560.0419921875\n",
      "{'edge_loss': tensor(0.0279, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7019, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4402, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.8454, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2270  Loss :  0.603381335735321 dsm :  0.8467643857002258 neg entropy :  559.2467041015625\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2591, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5399, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(552.4756, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2280  Loss :  0.6148240566253662 dsm :  4.773942470550537 neg entropy :  556.199462890625\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1712, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3652, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3198, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2290  Loss :  0.54390549659729 dsm :  2.268512010574341 neg entropy :  567.56787109375\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.9952, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3705, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.2555, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2300  Loss :  0.44910919666290283 dsm :  3.604236364364624 neg entropy :  561.3432006835938\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8273, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.3410, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2310  Loss :  0.6232865452766418 dsm :  2.8901593685150146 neg entropy :  560.3383178710938\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6513, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3932, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.0491, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2320  Loss :  0.6136137843132019 dsm :  0.40721216797828674 neg entropy :  555.730224609375\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1547, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.4882, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2330  Loss :  0.52249675989151 dsm :  0.7091497778892517 neg entropy :  560.8741455078125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4135, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1692, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2340  Loss :  0.5499284863471985 dsm :  0.6367276906967163 neg entropy :  557.0675659179688\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7526, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3709, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.1642, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2350  Loss :  0.589604377746582 dsm :  1.1100918054580688 neg entropy :  553.4734497070312\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1180, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4373, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.3958, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2360  Loss :  0.5183364152908325 dsm :  0.22345910966396332 neg entropy :  562.3751831054688\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7695, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4360, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.9708, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2370  Loss :  0.33275556564331055 dsm :  1.9526195526123047 neg entropy :  551.7520751953125\n",
      "{'edge_loss': tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0304, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7946, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3547, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.1294, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2380  Loss :  0.6125742793083191 dsm :  2.724355459213257 neg entropy :  562.2861328125\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4754, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4077, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.9009, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2390  Loss :  0.4315233528614044 dsm :  1.6939598321914673 neg entropy :  558.8059692382812\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5298, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.6079, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2400  Loss :  0.4433076083660126 dsm :  1.2406699657440186 neg entropy :  559.49951171875\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4229, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4860, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.7648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2410  Loss :  0.4116060733795166 dsm :  0.33758270740509033 neg entropy :  560.968994140625\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8144, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3910, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.4754, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2420  Loss :  0.5370144844055176 dsm :  2.3528411388397217 neg entropy :  562.8085327148438\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5433, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4207, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.8650, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2430  Loss :  0.6861572265625 dsm :  0.3974972367286682 neg entropy :  554.0267944335938\n",
      "{'edge_loss': tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3667, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1366, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2440  Loss :  0.5602779984474182 dsm :  1.0760716199874878 neg entropy :  558.7963256835938\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1643, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.4955, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2450  Loss :  0.559738278388977 dsm :  0.575665295124054 neg entropy :  559.9293212890625\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5555, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.4681, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2460  Loss :  0.4076894521713257 dsm :  3.3315179347991943 neg entropy :  556.6283569335938\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2012, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4390, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(541.7104, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2470  Loss :  0.524254560470581 dsm :  0.7418985366821289 neg entropy :  563.62548828125\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4477, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3516, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.7319, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2480  Loss :  0.558609664440155 dsm :  0.17800860106945038 neg entropy :  560.6212158203125\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3274, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.0375, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  89  Batch :  2490  Loss :  0.595760703086853 dsm :  1.7128130197525024 neg entropy :  555.708251953125\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1011, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4613, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(538.7668, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3202, device='cuda:0'), 'property_loss': tensor(488.7589, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  0 Loss sum :  0.49299731850624084 dsm :  0.05975967273116112 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0257, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3573, device='cuda:0'), 'property_loss': tensor(509.0292, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  10 Loss sum :  0.30023184418678284 dsm :  0.559773862361908 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0252, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2729, device='cuda:0'), 'property_loss': tensor(496.8431, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  20 Loss sum :  0.4571368992328644 dsm :  1.2455625534057617 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2608, device='cuda:0'), 'property_loss': tensor(482.0240, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  30 Loss sum :  0.5220032334327698 dsm :  2.3471293449401855 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3833, device='cuda:0'), 'property_loss': tensor(505.1551, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  40 Loss sum :  0.5541815757751465 dsm :  2.9565420150756836 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0292, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3073, device='cuda:0'), 'property_loss': tensor(470.4473, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  50 Loss sum :  0.49561554193496704 dsm :  1.1797736883163452 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0'), 'node_loss': tensor(0.0015, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5077, device='cuda:0'), 'property_loss': tensor(527.9293, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  60 Loss sum :  0.6370989084243774 dsm :  1.288834810256958 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2493, device='cuda:0'), 'property_loss': tensor(456.3255, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  70 Loss sum :  0.5157589316368103 dsm :  1.6317020654678345 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4449, device='cuda:0'), 'property_loss': tensor(529.8140, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  80 Loss sum :  0.5745911598205566 dsm :  1.6578887701034546 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0'), 'node_loss': tensor(0.0018, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3457, device='cuda:0'), 'property_loss': tensor(485.5072, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  90 Loss sum :  0.5559107661247253 dsm :  0.04452010989189148 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4207, device='cuda:0'), 'property_loss': tensor(527.3315, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  100 Loss sum :  0.5497795343399048 dsm :  1.837996482849121 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0'), 'node_loss': tensor(0.0015, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3901, device='cuda:0'), 'property_loss': tensor(521.8687, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  110 Loss sum :  0.5392195582389832 dsm :  1.512027621269226 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.3026, device='cuda:0'), 'property_loss': tensor(484.4952, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  120 Loss sum :  0.5161434412002563 dsm :  2.7067229747772217 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3445, device='cuda:0'), 'property_loss': tensor(491.2539, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  130 Loss sum :  0.5185366272926331 dsm :  1.3368279933929443 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0'), 'node_loss': tensor(-0.0153, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2615, device='cuda:0'), 'property_loss': tensor(470.0943, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  140 Loss sum :  0.3394201695919037 dsm :  0.7377369999885559 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0'), 'node_loss': tensor(-0.0486, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4771, device='cuda:0'), 'property_loss': tensor(515.6260, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  150 Loss sum :  0.09857441484928131 dsm :  2.2331924438476562 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2788, device='cuda:0'), 'property_loss': tensor(481.0876, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  160 Loss sum :  0.3880658447742462 dsm :  6.13102912902832 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0'), 'node_loss': tensor(-0.0147, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2467, device='cuda:0'), 'property_loss': tensor(441.3569, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  170 Loss sum :  0.3995401859283447 dsm :  2.1562740802764893 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0257, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3055, device='cuda:0'), 'property_loss': tensor(493.4053, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  180 Loss sum :  0.4639624357223511 dsm :  1.49738347530365 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0296, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3121, device='cuda:0'), 'property_loss': tensor(506.4282, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  190 Loss sum :  0.49505615234375 dsm :  0.0120695186778903 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2842, device='cuda:0'), 'property_loss': tensor(468.7514, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  200 Loss sum :  0.5475939512252808 dsm :  0.9843809008598328 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3812, device='cuda:0'), 'property_loss': tensor(504.2068, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  210 Loss sum :  0.544945240020752 dsm :  0.8059747815132141 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3325, device='cuda:0'), 'property_loss': tensor(486.3989, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  220 Loss sum :  0.4989226162433624 dsm :  1.6644477844238281 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3797, device='cuda:0'), 'property_loss': tensor(506.3916, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  230 Loss sum :  0.3735998570919037 dsm :  3.319694995880127 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0'), 'node_loss': tensor(-0.0158, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4288, device='cuda:0'), 'property_loss': tensor(519.0568, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  240 Loss sum :  0.3716508150100708 dsm :  0.8605939745903015 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2412, device='cuda:0'), 'property_loss': tensor(462.6148, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  250 Loss sum :  0.47538989782333374 dsm :  0.3163471817970276 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0241, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3895, device='cuda:0'), 'property_loss': tensor(526.8281, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  260 Loss sum :  0.44772273302078247 dsm :  0.6415753364562988 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0'), 'node_loss': tensor(0.0021, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3503, device='cuda:0'), 'property_loss': tensor(493.6745, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  270 Loss sum :  0.5575318336486816 dsm :  2.1675806045532227 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0278, device='cuda:0'), 'node_loss': tensor(0.0011, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4322, device='cuda:0'), 'property_loss': tensor(535.5021, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  280 Loss sum :  0.49620717763900757 dsm :  0.7725509405136108 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4067, device='cuda:0'), 'property_loss': tensor(495.1479, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  290 Loss sum :  0.39233270287513733 dsm :  1.66769540309906 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0'), 'node_loss': tensor(0.0025, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3543, device='cuda:0'), 'property_loss': tensor(473.8546, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  300 Loss sum :  0.6183403134346008 dsm :  2.268866777420044 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0'), 'node_loss': tensor(0.0028, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2339, device='cuda:0'), 'property_loss': tensor(464.1436, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  310 Loss sum :  0.5505279302597046 dsm :  1.7840133905410767 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0'), 'node_loss': tensor(-0.0143, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3094, device='cuda:0'), 'property_loss': tensor(497.1514, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  320 Loss sum :  0.3388698995113373 dsm :  0.5828048586845398 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0286, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4436, device='cuda:0'), 'property_loss': tensor(537.5202, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  330 Loss sum :  0.5211892127990723 dsm :  2.0362589359283447 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3278, device='cuda:0'), 'property_loss': tensor(476.2506, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  340 Loss sum :  0.4000781774520874 dsm :  3.069350242614746 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2946, device='cuda:0'), 'property_loss': tensor(471.3933, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  350 Loss sum :  0.5425150990486145 dsm :  0.006572711747139692 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0258, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3198, device='cuda:0'), 'property_loss': tensor(509.4395, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  360 Loss sum :  0.4590436816215515 dsm :  0.7189149856567383 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(-0.0153, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2224, device='cuda:0'), 'property_loss': tensor(469.3914, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  370 Loss sum :  0.3461589813232422 dsm :  1.1827415227890015 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2818, device='cuda:0'), 'property_loss': tensor(472.7339, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  380 Loss sum :  0.5093706250190735 dsm :  0.7542001605033875 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4217, device='cuda:0'), 'property_loss': tensor(516.3685, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  390 Loss sum :  0.5826926231384277 dsm :  3.7563717365264893 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3552, device='cuda:0'), 'property_loss': tensor(492.2271, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  400 Loss sum :  0.5212838053703308 dsm :  0.015918245539069176 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0011, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3422, device='cuda:0'), 'property_loss': tensor(493.5221, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  410 Loss sum :  0.5396808981895447 dsm :  0.011309975758194923 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0272, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2695, device='cuda:0'), 'property_loss': tensor(471.4511, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  420 Loss sum :  0.3087848424911499 dsm :  1.4235433340072632 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0240, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2922, device='cuda:0'), 'property_loss': tensor(491.6316, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  430 Loss sum :  0.44532251358032227 dsm :  1.4627574682235718 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3423, device='cuda:0'), 'property_loss': tensor(499.7813, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  440 Loss sum :  0.5210080146789551 dsm :  1.1473560333251953 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3506, device='cuda:0'), 'property_loss': tensor(474.7737, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  450 Loss sum :  0.5994203090667725 dsm :  0.9095861315727234 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0'), 'node_loss': tensor(0.0022, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3425, device='cuda:0'), 'property_loss': tensor(498.2209, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  460 Loss sum :  0.5837934613227844 dsm :  0.7964874505996704 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.2990, device='cuda:0'), 'property_loss': tensor(474.9628, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  470 Loss sum :  0.38339877128601074 dsm :  0.6247286200523376 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2560, device='cuda:0'), 'property_loss': tensor(456.0045, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  480 Loss sum :  0.39999812841415405 dsm :  0.6732420325279236 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0270, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2869, device='cuda:0'), 'property_loss': tensor(484.9716, device='cuda:0')}\n",
      "Epoch (val) :  89   batch (val) :  490 Loss sum :  0.47435566782951355 dsm :  1.4450600147247314 neg entropy :  568.9645385742188\n",
      "Epoch :  90  Batch :  0  Loss :  0.6547987461090088 dsm :  5.980157375335693 neg entropy :  557.1962280273438\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7046, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4668, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.2835, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  10  Loss :  0.5747214555740356 dsm :  0.614102840423584 neg entropy :  558.6104736328125\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6432, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.3064, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  20  Loss :  0.6179222464561462 dsm :  1.224955439567566 neg entropy :  554.7521362304688\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3275, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.0326, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  30  Loss :  0.34757059812545776 dsm :  0.018478836864233017 neg entropy :  560.8601684570312\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3109, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.6826, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  40  Loss :  0.6300381422042847 dsm :  5.285130977630615 neg entropy :  559.01025390625\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5581, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4580, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.6852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  50  Loss :  0.5495759844779968 dsm :  0.5802721381187439 neg entropy :  566.5729370117188\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.9605, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.3087, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  60  Loss :  0.5626838207244873 dsm :  0.4257572293281555 neg entropy :  557.5928955078125\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7882, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3628, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.0012, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  70  Loss :  0.6976521015167236 dsm :  3.6625332832336426 neg entropy :  549.1616821289062\n",
      "{'edge_loss': tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.4262, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5076, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.9596, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  80  Loss :  0.5853154063224792 dsm :  0.7831447124481201 neg entropy :  558.581787109375\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6341, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.5676, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  90  Loss :  0.5199832320213318 dsm :  2.538623571395874 neg entropy :  564.2847290039062\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8266, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.9605, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  100  Loss :  0.3062727451324463 dsm :  0.5963746309280396 neg entropy :  557.23291015625\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9786, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4497, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.3648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  110  Loss :  0.6066257357597351 dsm :  1.028317928314209 neg entropy :  555.8184814453125\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8850, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4712, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  120  Loss :  0.5270352959632874 dsm :  0.4995117783546448 neg entropy :  563.4154052734375\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4192, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.7895, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  130  Loss :  0.561942458152771 dsm :  3.0673787593841553 neg entropy :  553.097900390625\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0238, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4085, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.8648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  140  Loss :  0.5438866019248962 dsm :  1.0833463668823242 neg entropy :  566.24169921875\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6080, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.2569, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  150  Loss :  0.3993058204650879 dsm :  0.7816433906555176 neg entropy :  558.2345581054688\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0063, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4025, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.7914, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  160  Loss :  0.5494458675384521 dsm :  0.9764999747276306 neg entropy :  560.6943359375\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2823, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3149, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.7542, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  170  Loss :  0.3821552097797394 dsm :  2.0801563262939453 neg entropy :  558.7821655273438\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8724, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  180  Loss :  0.5769369602203369 dsm :  1.4319466352462769 neg entropy :  558.0116577148438\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3950, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4096, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.0114, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  190  Loss :  0.44369688630104065 dsm :  1.9052475690841675 neg entropy :  557.5608520507812\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4695, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4382, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1654, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  200  Loss :  0.6572482585906982 dsm :  0.5348357558250427 neg entropy :  547.2741088867188\n",
      "{'edge_loss': tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.6994, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5249, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.0096, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  210  Loss :  0.5850265026092529 dsm :  1.9035027027130127 neg entropy :  555.8995361328125\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2327, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.6914, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  220  Loss :  0.5429552793502808 dsm :  1.385654330253601 neg entropy :  559.4926147460938\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8086, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.9231, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  230  Loss :  0.4380647540092468 dsm :  1.555230975151062 neg entropy :  556.9622192382812\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0251, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4365, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.8922, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  240  Loss :  0.5833743810653687 dsm :  2.0059316158294678 neg entropy :  562.9246215820312\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7817, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.3270, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  250  Loss :  0.5615171194076538 dsm :  1.0746744871139526 neg entropy :  555.3302001953125\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3383, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.8246, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  260  Loss :  0.5208563208580017 dsm :  1.7285537719726562 neg entropy :  563.2926635742188\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2175, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2369, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.6541, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  270  Loss :  0.45568323135375977 dsm :  0.670956552028656 neg entropy :  555.6536254882812\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7529, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4063, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.2085, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  280  Loss :  0.21279945969581604 dsm :  0.24176715314388275 neg entropy :  563.5249633789062\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0307, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0615, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.8275, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  290  Loss :  0.631340742111206 dsm :  3.3620173931121826 neg entropy :  555.5782470703125\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2394, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.8634, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  300  Loss :  0.6037296056747437 dsm :  0.549731433391571 neg entropy :  559.5675659179688\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2835, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2014, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(421.9017, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  310  Loss :  0.6362295150756836 dsm :  1.1451443433761597 neg entropy :  561.40625\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9230, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.7212, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  320  Loss :  0.6002930998802185 dsm :  3.472700595855713 neg entropy :  564.1254272460938\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.7730, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3574, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.3232, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  330  Loss :  0.5691392421722412 dsm :  1.636728286743164 neg entropy :  560.8097534179688\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0065, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3565, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1644, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  340  Loss :  0.5288744568824768 dsm :  1.961005449295044 neg entropy :  564.5601806640625\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2679, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.8204, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  350  Loss :  0.294160395860672 dsm :  1.3087490797042847 neg entropy :  556.4472045898438\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0315, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3762, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5096, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(531.6833, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  360  Loss :  0.5127308368682861 dsm :  1.8221256732940674 neg entropy :  563.9755859375\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5228, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2132, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.2577, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  370  Loss :  0.4932505488395691 dsm :  0.5762075781822205 neg entropy :  562.28955078125\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3096, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3290, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.7728, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  380  Loss :  0.5623174905776978 dsm :  1.0816437005996704 neg entropy :  560.8159790039062\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1207, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.0201, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  390  Loss :  0.5597968101501465 dsm :  1.1649411916732788 neg entropy :  557.0846557617188\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9001, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.2246, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  400  Loss :  0.5793551206588745 dsm :  0.9094752669334412 neg entropy :  560.67822265625\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4564, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.6194, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  410  Loss :  0.6040872931480408 dsm :  1.9244556427001953 neg entropy :  561.2841186523438\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3000, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.5693, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  420  Loss :  0.5545197129249573 dsm :  1.509843349456787 neg entropy :  560.884765625\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7248, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.0566, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  430  Loss :  0.5874367356300354 dsm :  0.3713808059692383 neg entropy :  552.2079467773438\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3473, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3122, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.3114, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  440  Loss :  0.5230609178543091 dsm :  0.3095391094684601 neg entropy :  562.6672973632812\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3593, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3543, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.7421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  450  Loss :  0.6512408256530762 dsm :  3.2352492809295654 neg entropy :  555.2080078125\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0028, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.7768, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  460  Loss :  0.3482748866081238 dsm :  0.05529540777206421 neg entropy :  559.50537109375\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0868, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2446, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.7085, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  470  Loss :  0.5566587448120117 dsm :  0.8296080827713013 neg entropy :  561.9928588867188\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9078, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2253, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(454.2885, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  480  Loss :  0.5914324522018433 dsm :  1.7211389541625977 neg entropy :  554.7626342773438\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8670, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4641, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.1596, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  490  Loss :  0.5841017365455627 dsm :  2.2718517780303955 neg entropy :  557.8141479492188\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8286, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.3366, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  500  Loss :  0.415168821811676 dsm :  5.086614608764648 neg entropy :  559.7781372070312\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1814, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3503, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.2160, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  510  Loss :  0.40508151054382324 dsm :  0.6175402998924255 neg entropy :  557.8939819335938\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6285, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.1379, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  520  Loss :  0.6567125916481018 dsm :  2.4921703338623047 neg entropy :  553.9937133789062\n",
      "{'edge_loss': tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5170, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.0852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  530  Loss :  0.3577824532985687 dsm :  1.2332838773727417 neg entropy :  561.0421752929688\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3180, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2390, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.0797, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  540  Loss :  0.5763811469078064 dsm :  2.04400634765625 neg entropy :  563.9025268554688\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9154, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3501, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.7924, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  550  Loss :  0.511794924736023 dsm :  3.226151704788208 neg entropy :  551.779052734375\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.3258, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5684, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(541.3594, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  560  Loss :  0.6098712682723999 dsm :  3.542628526687622 neg entropy :  561.3804931640625\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2422, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.3191, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  570  Loss :  0.5509666204452515 dsm :  0.03528697043657303 neg entropy :  564.5543823242188\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1038, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.1544, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  580  Loss :  0.5857770442962646 dsm :  1.7794908285140991 neg entropy :  560.1911010742188\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4880, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.8924, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  590  Loss :  0.558212161064148 dsm :  0.051192570477724075 neg entropy :  556.0258178710938\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5605, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3407, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9076, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  600  Loss :  0.5531765818595886 dsm :  0.7346175909042358 neg entropy :  554.985595703125\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4663, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4246, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.8507, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  610  Loss :  0.5626449584960938 dsm :  0.7547815442085266 neg entropy :  555.39697265625\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3687, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.2704, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  620  Loss :  0.5941044092178345 dsm :  4.1376237869262695 neg entropy :  563.9437866210938\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3199, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2708, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.5628, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  630  Loss :  0.5310618281364441 dsm :  2.059077501296997 neg entropy :  566.7831420898438\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5794, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.8363, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  640  Loss :  0.4778822362422943 dsm :  0.38079243898391724 neg entropy :  563.566162109375\n",
      "{'edge_loss': tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3388, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2538, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.2790, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  650  Loss :  0.5570197105407715 dsm :  1.3239567279815674 neg entropy :  562.0748901367188\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4912, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4407, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.5525, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  660  Loss :  0.43508845567703247 dsm :  4.288351058959961 neg entropy :  561.8474731445312\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0275, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.2338, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  670  Loss :  0.44260263442993164 dsm :  0.24321508407592773 neg entropy :  558.0802612304688\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5596, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4592, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.7090, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  680  Loss :  0.5784000158309937 dsm :  1.083994746208191 neg entropy :  562.5595092773438\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5391, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4009, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.4858, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  690  Loss :  0.5364660024642944 dsm :  0.011666021309792995 neg entropy :  561.7854614257812\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2041, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3364, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.0941, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  700  Loss :  0.3968580663204193 dsm :  0.27659252285957336 neg entropy :  560.0160522460938\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3326, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9925, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  710  Loss :  0.37532517313957214 dsm :  0.48111462593078613 neg entropy :  560.3910522460938\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9930, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5654, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  720  Loss :  0.5381621718406677 dsm :  0.662634551525116 neg entropy :  557.9369506835938\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1499, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.7269, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  730  Loss :  0.3931877613067627 dsm :  0.3762941360473633 neg entropy :  560.0223999023438\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3064, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.3948, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  740  Loss :  0.5386362075805664 dsm :  2.2349605560302734 neg entropy :  562.083251953125\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6784, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2880, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.6523, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  750  Loss :  0.4354391098022461 dsm :  1.252968668937683 neg entropy :  557.2272338867188\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7661, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3192, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.8088, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  760  Loss :  0.6324878334999084 dsm :  1.2939404249191284 neg entropy :  560.8406372070312\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7293, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.5828, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  770  Loss :  0.6292935609817505 dsm :  2.98819899559021 neg entropy :  556.6343994140625\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2714, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.1006, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  780  Loss :  0.5858986377716064 dsm :  1.906625747680664 neg entropy :  559.53857421875\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1065, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.4070, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  790  Loss :  0.585259735584259 dsm :  2.8832201957702637 neg entropy :  557.8168334960938\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7281, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.2528, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  800  Loss :  0.5773373246192932 dsm :  1.9701801538467407 neg entropy :  563.8253784179688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2761, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2887, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.4461, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  810  Loss :  0.640807032585144 dsm :  3.3637218475341797 neg entropy :  555.7135620117188\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1932, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.5458, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  820  Loss :  0.6185799837112427 dsm :  3.0800750255584717 neg entropy :  561.4818725585938\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5841, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4263, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.6655, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  830  Loss :  0.5662651658058167 dsm :  2.9951226711273193 neg entropy :  559.7118530273438\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5924, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.5210, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  840  Loss :  0.673916757106781 dsm :  3.137352466583252 neg entropy :  553.6025390625\n",
      "{'edge_loss': tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5222, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5086, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.4152, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  850  Loss :  0.5633019208908081 dsm :  2.558367967605591 neg entropy :  560.9822387695312\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0188, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.9659, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  860  Loss :  0.5030392408370972 dsm :  1.7092323303222656 neg entropy :  563.50244140625\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5136, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2187, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.8463, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  870  Loss :  0.4076080322265625 dsm :  0.8206998705863953 neg entropy :  556.8738403320312\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0564, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3014, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.9785, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  880  Loss :  0.6001921892166138 dsm :  0.05414941906929016 neg entropy :  553.8396606445312\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8758, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4122, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.6472, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  890  Loss :  0.6100565195083618 dsm :  3.8164429664611816 neg entropy :  553.087890625\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9725, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.9118, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  900  Loss :  0.5542930364608765 dsm :  2.1019184589385986 neg entropy :  560.5720825195312\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9831, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4749, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(546.2812, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  910  Loss :  0.40096205472946167 dsm :  0.45359188318252563 neg entropy :  557.7229614257812\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5144, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8586, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  920  Loss :  0.6752109527587891 dsm :  4.771062850952148 neg entropy :  554.7413330078125\n",
      "{'edge_loss': tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2501, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4499, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.2118, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  930  Loss :  0.6804994344711304 dsm :  4.690187454223633 neg entropy :  551.7155151367188\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.4057, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4357, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.7432, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  940  Loss :  0.48963841795921326 dsm :  0.6245443224906921 neg entropy :  562.7855834960938\n",
      "{'edge_loss': tensor(0.0277, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6302, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.0797, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  950  Loss :  0.5635876059532166 dsm :  1.8467270135879517 neg entropy :  562.6265258789062\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5533, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2409, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.1218, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  960  Loss :  0.5768736600875854 dsm :  0.17281411588191986 neg entropy :  553.6629028320312\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9714, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0504, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  970  Loss :  0.366872102022171 dsm :  1.9455629587173462 neg entropy :  561.1234741210938\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6999, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.9501, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  980  Loss :  0.5316656231880188 dsm :  2.2519659996032715 neg entropy :  561.4805908203125\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7942, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4133, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.9912, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  990  Loss :  0.5472313165664673 dsm :  0.07499188929796219 neg entropy :  559.4793090820312\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2751, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.3619, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1000  Loss :  0.7018111348152161 dsm :  3.1670989990234375 neg entropy :  551.7489624023438\n",
      "{'edge_loss': tensor(0.0476, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3015, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2450, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(430.8413, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1010  Loss :  0.6648993492126465 dsm :  1.349557876586914 neg entropy :  547.6488647460938\n",
      "{'edge_loss': tensor(0.0440, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2230, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4491, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.7081, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1020  Loss :  0.5572705268859863 dsm :  0.7183151245117188 neg entropy :  559.9039306640625\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3341, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4580, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.8364, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1030  Loss :  0.6112068295478821 dsm :  3.8701932430267334 neg entropy :  554.7830200195312\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4272, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.1562, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1040  Loss :  0.645380437374115 dsm :  1.2021799087524414 neg entropy :  552.2636108398438\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2078, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5038, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.3757, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1050  Loss :  0.39637649059295654 dsm :  5.593100547790527 neg entropy :  552.2218627929688\n",
      "{'edge_loss': tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8754, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.0982, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1060  Loss :  0.56340491771698 dsm :  0.16291336715221405 neg entropy :  560.069091796875\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1914, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4050, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.0038, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1070  Loss :  0.5123869180679321 dsm :  0.49821606278419495 neg entropy :  562.7477416992188\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3780, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.5765, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1080  Loss :  0.5817890763282776 dsm :  1.255027174949646 neg entropy :  557.231201171875\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5788, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.1545, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1090  Loss :  0.5682780146598816 dsm :  0.02506151609122753 neg entropy :  554.6406860351562\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8701, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3230, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.2734, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1100  Loss :  0.5799398422241211 dsm :  0.4684659540653229 neg entropy :  557.3655395507812\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4469, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3561, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8025, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1110  Loss :  0.5642524361610413 dsm :  1.0509834289550781 neg entropy :  556.4130859375\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3615, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2798, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.0015, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1120  Loss :  0.5148873329162598 dsm :  0.08442740142345428 neg entropy :  560.3073120117188\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8820, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.7622, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1130  Loss :  0.5557946562767029 dsm :  0.307898610830307 neg entropy :  561.2052612304688\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9672, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.1416, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1140  Loss :  0.5195318460464478 dsm :  1.0549980401992798 neg entropy :  559.526611328125\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9690, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.8505, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1150  Loss :  0.6160873174667358 dsm :  1.2154563665390015 neg entropy :  557.0225830078125\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4685, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2891, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.4309, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1160  Loss :  0.6453137993812561 dsm :  0.14202651381492615 neg entropy :  559.4844970703125\n",
      "{'edge_loss': tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3887, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4296, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.4814, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1170  Loss :  0.4041227102279663 dsm :  0.10786639899015427 neg entropy :  560.3587036132812\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4007, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.5651, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1180  Loss :  0.5962841510772705 dsm :  1.7486164569854736 neg entropy :  553.207763671875\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3290, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2680, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.3367, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1190  Loss :  0.37334689497947693 dsm :  0.6198444366455078 neg entropy :  558.7698364257812\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4870, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.2757, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1200  Loss :  0.5415332317352295 dsm :  3.802025318145752 neg entropy :  562.0863037109375\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9300, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.4100, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1210  Loss :  0.5685515403747559 dsm :  0.21104185283184052 neg entropy :  561.1295166015625\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3206, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3597, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.0291, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1220  Loss :  0.4823661744594574 dsm :  4.475470542907715 neg entropy :  554.1121826171875\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1620, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3180, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.5062, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1230  Loss :  0.559332013130188 dsm :  4.2348222732543945 neg entropy :  559.658203125\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5234, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2448, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.6594, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1240  Loss :  0.5638320446014404 dsm :  2.152085542678833 neg entropy :  564.1786499023438\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5209, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2667, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.9971, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1250  Loss :  0.6115289330482483 dsm :  0.3773126006126404 neg entropy :  557.1866455078125\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5356, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4257, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.9879, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1260  Loss :  0.6094675064086914 dsm :  2.848029375076294 neg entropy :  553.72216796875\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3771, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2238, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.3272, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1270  Loss :  0.5564971566200256 dsm :  0.6947252154350281 neg entropy :  558.712158203125\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0101, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.8162, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1280  Loss :  0.5648189783096313 dsm :  0.7542895674705505 neg entropy :  559.5076293945312\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3850, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2304, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(441.7169, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1290  Loss :  0.6371712684631348 dsm :  0.3538215756416321 neg entropy :  560.2545776367188\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0033, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8773, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4449, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.2929, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1300  Loss :  0.5427589416503906 dsm :  0.4353254735469818 neg entropy :  563.2819213867188\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9204, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.1323, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1310  Loss :  0.5726102590560913 dsm :  2.604259729385376 neg entropy :  558.7080078125\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8906, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3966, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.9199, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1320  Loss :  0.43737223744392395 dsm :  1.2607635259628296 neg entropy :  557.0217895507812\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0133, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6543, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.0138, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1330  Loss :  0.5208184123039246 dsm :  0.16582731902599335 neg entropy :  567.8395385742188\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.2818, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.2674, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1340  Loss :  0.6323278546333313 dsm :  8.194891929626465 neg entropy :  555.5365600585938\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5673, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2665, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.0260, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1350  Loss :  0.06563212722539902 dsm :  0.43180638551712036 neg entropy :  557.7277221679688\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0473, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7168, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3476, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1658, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1360  Loss :  0.5933718085289001 dsm :  0.4312055706977844 neg entropy :  552.4558715820312\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3997, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2824, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.9141, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1370  Loss :  0.5688916444778442 dsm :  3.47105073928833 neg entropy :  557.9075317382812\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3137, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3646, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.2403, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1380  Loss :  0.6044267416000366 dsm :  0.8780472874641418 neg entropy :  556.4654541015625\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6328, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3605, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.3997, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1390  Loss :  0.24118860065937042 dsm :  1.382188081741333 neg entropy :  556.976318359375\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0316, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9719, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3795, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.8355, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1400  Loss :  0.7131427526473999 dsm :  4.9381303787231445 neg entropy :  548.3959350585938\n",
      "{'edge_loss': tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.6469, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4275, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.0534, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1410  Loss :  0.4153187870979309 dsm :  0.11852893978357315 neg entropy :  558.8141479492188\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6121, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4566, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.2630, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1420  Loss :  0.5781940221786499 dsm :  0.2709686756134033 neg entropy :  560.9312744140625\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3944, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.6374, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1430  Loss :  0.5354812145233154 dsm :  0.10261119902133942 neg entropy :  562.6998291015625\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7577, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4305, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.6573, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1440  Loss :  0.5481297969818115 dsm :  0.20597100257873535 neg entropy :  559.3701171875\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3083, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5361, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1450  Loss :  0.5539039373397827 dsm :  0.4790319502353668 neg entropy :  561.5657348632812\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5265, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.2057, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1460  Loss :  0.420183002948761 dsm :  0.7801080346107483 neg entropy :  559.40966796875\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4826, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3453, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9289, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1470  Loss :  0.5535632967948914 dsm :  0.6082072257995605 neg entropy :  560.2677612304688\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0410, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3338, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.8905, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1480  Loss :  0.6877977252006531 dsm :  1.0060491561889648 neg entropy :  551.9176635742188\n",
      "{'edge_loss': tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0810, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3783, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.4690, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1490  Loss :  0.6377816200256348 dsm :  3.3122551441192627 neg entropy :  554.2603759765625\n",
      "{'edge_loss': tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5365, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2017, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1500  Loss :  0.5983692407608032 dsm :  1.6006220579147339 neg entropy :  561.8585815429688\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5246, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4919, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(533.2896, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1510  Loss :  0.5360651612281799 dsm :  2.3338277339935303 neg entropy :  559.3814697265625\n",
      "{'edge_loss': tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9962, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1068, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1520  Loss :  0.590186595916748 dsm :  2.54093599319458 neg entropy :  555.6324462890625\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4126, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3381, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.7177, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1530  Loss :  0.6604602932929993 dsm :  1.3169530630111694 neg entropy :  553.1310424804688\n",
      "{'edge_loss': tensor(0.0441, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2026, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4107, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.3450, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1540  Loss :  0.43598809838294983 dsm :  1.5128297805786133 neg entropy :  555.9581909179688\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7088, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.0351, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1550  Loss :  0.6066974401473999 dsm :  1.6044895648956299 neg entropy :  563.3670043945312\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7187, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3182, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.1439, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1560  Loss :  0.5315784215927124 dsm :  1.1290395259857178 neg entropy :  562.7965698242188\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4921, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3249, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.5370, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1570  Loss :  0.5573223233222961 dsm :  0.4720340371131897 neg entropy :  553.0396728515625\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0850, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4090, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.5601, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1580  Loss :  0.37896737456321716 dsm :  0.5011082887649536 neg entropy :  558.5492553710938\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9959, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.4453, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1590  Loss :  0.47391045093536377 dsm :  1.095123052597046 neg entropy :  565.562744140625\n",
      "{'edge_loss': tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1061, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.8141, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1600  Loss :  0.587302565574646 dsm :  2.1486122608184814 neg entropy :  561.0120239257812\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6964, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.2425, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1610  Loss :  0.5533074140548706 dsm :  1.5748718976974487 neg entropy :  565.6578979492188\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.7645, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2793, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.6167, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1620  Loss :  0.5730398893356323 dsm :  2.039731740951538 neg entropy :  562.6446533203125\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9383, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3934, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.8951, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1630  Loss :  0.6169970631599426 dsm :  1.6235935688018799 neg entropy :  561.5007934570312\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3507, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4394, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.6356, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1640  Loss :  0.3995061218738556 dsm :  0.7243546843528748 neg entropy :  556.0053100585938\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0076, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4300, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.4913, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1650  Loss :  0.6467214822769165 dsm :  0.6696224212646484 neg entropy :  557.2794189453125\n",
      "{'edge_loss': tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5934, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.7615, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1660  Loss :  0.6522943377494812 dsm :  0.05976926162838936 neg entropy :  559.4414672851562\n",
      "{'edge_loss': tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1937, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.2151, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1670  Loss :  0.6592538952827454 dsm :  4.033092498779297 neg entropy :  556.6068725585938\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9768, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3339, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.4786, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1680  Loss :  0.7110046148300171 dsm :  4.000960826873779 neg entropy :  545.1069946289062\n",
      "{'edge_loss': tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.9408, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4414, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.7290, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1690  Loss :  0.6300567388534546 dsm :  2.5266776084899902 neg entropy :  555.4020385742188\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3730, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4460, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.5654, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1700  Loss :  0.4278077483177185 dsm :  6.94860315322876 neg entropy :  555.4866943359375\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3778, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3221, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.1687, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1710  Loss :  0.4339360296726227 dsm :  3.3634324073791504 neg entropy :  563.2412109375\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0525, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3806, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.8581, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1720  Loss :  0.5545545220375061 dsm :  2.5504958629608154 neg entropy :  561.4972534179688\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2837, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.6058, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1730  Loss :  0.5912972688674927 dsm :  5.1393656730651855 neg entropy :  562.1998901367188\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7789, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3350, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.7357, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1740  Loss :  0.5624549984931946 dsm :  0.5733359456062317 neg entropy :  557.30615234375\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3498, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3030, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.2017, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1750  Loss :  0.5497382879257202 dsm :  1.0106512308120728 neg entropy :  562.7355346679688\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7533, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4238, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(531.5750, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1760  Loss :  0.635826826095581 dsm :  2.32985782623291 neg entropy :  553.4426879882812\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0510, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.3276, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1770  Loss :  0.5881296396255493 dsm :  0.9932898879051208 neg entropy :  560.7072143554688\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1049, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9197, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1780  Loss :  0.5473406314849854 dsm :  0.08071120083332062 neg entropy :  559.0858764648438\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8400, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.2578, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1790  Loss :  0.42789238691329956 dsm :  2.780125141143799 neg entropy :  560.8562622070312\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7032, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4516, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(528.1265, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1800  Loss :  0.6666525602340698 dsm :  1.4609932899475098 neg entropy :  556.1845092773438\n",
      "{'edge_loss': tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2915, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.0033, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1810  Loss :  0.6016621589660645 dsm :  1.4731483459472656 neg entropy :  559.9017333984375\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2965, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.3061, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1820  Loss :  0.5722343921661377 dsm :  1.011506199836731 neg entropy :  563.6266479492188\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9675, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0256, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1830  Loss :  0.4950743317604065 dsm :  1.6166117191314697 neg entropy :  560.1481323242188\n",
      "{'edge_loss': tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8741, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9653, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1840  Loss :  0.5303443670272827 dsm :  0.24345572292804718 neg entropy :  558.4619140625\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4316, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3511, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.5741, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1850  Loss :  0.5790814757347107 dsm :  1.7147756814956665 neg entropy :  553.5418090820312\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8406, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.0472, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1860  Loss :  0.5116987824440002 dsm :  2.502464771270752 neg entropy :  565.8328247070312\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2907, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2729, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.3945, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1870  Loss :  0.6160163879394531 dsm :  3.28006911277771 neg entropy :  556.3603515625\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1320, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.7307, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1880  Loss :  0.5736090540885925 dsm :  1.732461929321289 neg entropy :  559.2548217773438\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6069, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.8015, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1890  Loss :  0.6461799740791321 dsm :  1.0918477773666382 neg entropy :  554.5031127929688\n",
      "{'edge_loss': tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6974, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4146, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8839, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1900  Loss :  0.5601426959037781 dsm :  1.9331378936767578 neg entropy :  561.3687133789062\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9142, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.4059, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1910  Loss :  0.5516526699066162 dsm :  3.212900161743164 neg entropy :  559.498046875\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8830, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2867, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.3533, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1920  Loss :  0.5944264531135559 dsm :  1.2037668228149414 neg entropy :  561.8157348632812\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1814, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4201, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.9556, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1930  Loss :  0.6528592705726624 dsm :  0.32479214668273926 neg entropy :  551.1932373046875\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.7484, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5070, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.8516, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1940  Loss :  0.3821333348751068 dsm :  0.7728459239006042 neg entropy :  561.1829223632812\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2620, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2356, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.2219, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1950  Loss :  0.6070061922073364 dsm :  1.4529614448547363 neg entropy :  563.47998046875\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4643, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.2540, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1960  Loss :  0.5823217630386353 dsm :  3.394594192504883 neg entropy :  558.4080200195312\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4157, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.3240, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1970  Loss :  0.5462494492530823 dsm :  3.025132179260254 neg entropy :  560.2296752929688\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4833, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3409, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.9200, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1980  Loss :  0.5493068099021912 dsm :  2.6228420734405518 neg entropy :  559.7800903320312\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0096, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4333, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.1432, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  1990  Loss :  0.5687419176101685 dsm :  1.1957639455795288 neg entropy :  557.07080078125\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5117, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3726, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.4383, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2000  Loss :  0.5329862833023071 dsm :  2.2256391048431396 neg entropy :  559.4120483398438\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2699, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3609, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.4621, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2010  Loss :  0.5747826099395752 dsm :  1.2852805852890015 neg entropy :  554.5486450195312\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9924, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4108, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.2506, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2020  Loss :  0.5878560543060303 dsm :  0.5717409253120422 neg entropy :  554.074951171875\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.1590, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.3725, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2030  Loss :  0.6848698258399963 dsm :  4.53046989440918 neg entropy :  555.3739624023438\n",
      "{'edge_loss': tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0465, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.7011, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2040  Loss :  0.36075741052627563 dsm :  0.9017715454101562 neg entropy :  561.8644409179688\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0413, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4264, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(533.7579, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2050  Loss :  0.5403046607971191 dsm :  1.0304964780807495 neg entropy :  557.906494140625\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4700, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.5421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2060  Loss :  0.5591699481010437 dsm :  3.8200740814208984 neg entropy :  562.5385131835938\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6626, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3162, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.2814, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2070  Loss :  0.5071206092834473 dsm :  4.75429105758667 neg entropy :  555.7133178710938\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6412, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4116, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.3327, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2080  Loss :  0.5404886603355408 dsm :  0.012849059887230396 neg entropy :  560.9326171875\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1304, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3212, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.3591, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2090  Loss :  0.5561020374298096 dsm :  0.04987442493438721 neg entropy :  560.4657592773438\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8675, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3552, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8576, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2100  Loss :  0.5621220469474792 dsm :  0.7307793498039246 neg entropy :  561.3551025390625\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9683, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3001, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.5116, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2110  Loss :  0.5825877785682678 dsm :  2.3834750652313232 neg entropy :  563.3855590820312\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4244, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.2203, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2120  Loss :  0.5582526922225952 dsm :  2.675492286682129 neg entropy :  562.3873291015625\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9145, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3610, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.2689, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2130  Loss :  0.42083579301834106 dsm :  2.8117268085479736 neg entropy :  558.41015625\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8052, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3715, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.0648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2140  Loss :  0.4610787630081177 dsm :  1.096821665763855 neg entropy :  561.3607788085938\n",
      "{'edge_loss': tensor(0.0264, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5840, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1964, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.2565, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2150  Loss :  0.4198206961154938 dsm :  3.5287892818450928 neg entropy :  556.7001342773438\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6544, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4651, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.3095, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2160  Loss :  0.572533130645752 dsm :  1.5899556875228882 neg entropy :  557.9376831054688\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7687, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3735, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.6431, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2170  Loss :  0.5656376481056213 dsm :  2.870490789413452 neg entropy :  563.9745483398438\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8773, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2737, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.1855, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2180  Loss :  0.5663095712661743 dsm :  3.9144723415374756 neg entropy :  562.1253051757812\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6816, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.0926, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2190  Loss :  0.5313938856124878 dsm :  0.947583794593811 neg entropy :  563.9818725585938\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9169, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2295, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(447.6045, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2200  Loss :  0.560410737991333 dsm :  0.11748867481946945 neg entropy :  561.1441040039062\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2806, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.0858, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2210  Loss :  0.5380066633224487 dsm :  0.31051281094551086 neg entropy :  559.4140014648438\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4328, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.7636, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2220  Loss :  0.5547297596931458 dsm :  0.10131343454122543 neg entropy :  562.1775512695312\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0816, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2370, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.4980, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2230  Loss :  0.5475424528121948 dsm :  0.7539361119270325 neg entropy :  560.2882690429688\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5803, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3633, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.4895, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2240  Loss :  0.5485979318618774 dsm :  1.0922783613204956 neg entropy :  556.6846923828125\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1141, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4462, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.5609, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2250  Loss :  0.6437393426895142 dsm :  3.488417387008667 neg entropy :  561.5010986328125\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0030, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3489, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.5372, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2260  Loss :  0.41632145643234253 dsm :  0.5089489817619324 neg entropy :  559.9984741210938\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5221, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.7493, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2270  Loss :  0.5457788109779358 dsm :  2.1505982875823975 neg entropy :  563.7791137695312\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9655, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3783, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.8199, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2280  Loss :  0.5829721689224243 dsm :  0.8261305689811707 neg entropy :  557.1654663085938\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3595, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.5864, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2290  Loss :  0.4127568006515503 dsm :  2.7792301177978516 neg entropy :  563.8511962890625\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0140, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3949, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1081, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2300  Loss :  0.5462403297424316 dsm :  3.3980813026428223 neg entropy :  563.3851928710938\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0887, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2809, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.7764, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2310  Loss :  0.5953840017318726 dsm :  2.3842954635620117 neg entropy :  560.0750732421875\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0188, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.6425, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2320  Loss :  0.6071692705154419 dsm :  1.2408044338226318 neg entropy :  557.5244140625\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8220, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3890, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4398, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2330  Loss :  0.5638266801834106 dsm :  1.9757860898971558 neg entropy :  564.3421020507812\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2191, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5746, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2340  Loss :  0.3727252781391144 dsm :  1.4343185424804688 neg entropy :  561.3541870117188\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2829, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.5882, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2350  Loss :  0.41712749004364014 dsm :  1.5655467510223389 neg entropy :  561.4011840820312\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4174, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.0639, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2360  Loss :  0.58277827501297 dsm :  2.794667959213257 neg entropy :  556.9841918945312\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2366, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.4200, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2370  Loss :  0.5676172375679016 dsm :  0.32377320528030396 neg entropy :  564.9619140625\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1263, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.6827, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2380  Loss :  0.507155179977417 dsm :  1.2691134214401245 neg entropy :  563.7755126953125\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7337, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3840, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.2634, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2390  Loss :  0.5981153845787048 dsm :  0.7696311473846436 neg entropy :  557.6608276367188\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7610, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3378, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.8752, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2400  Loss :  0.6904774904251099 dsm :  0.2983205020427704 neg entropy :  547.47900390625\n",
      "{'edge_loss': tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.6379, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4589, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.0570, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2410  Loss :  0.5958382487297058 dsm :  2.2716171741485596 neg entropy :  556.4111328125\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2273, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.4454, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2420  Loss :  0.5897730588912964 dsm :  3.285400867462158 neg entropy :  557.7779541015625\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4031, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.9877, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2430  Loss :  0.5935698747634888 dsm :  1.9407933950424194 neg entropy :  558.7623291015625\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5491, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.7673, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2440  Loss :  0.5316519737243652 dsm :  0.10396478325128555 neg entropy :  559.8034057617188\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9310, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.0387, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2450  Loss :  0.5956913232803345 dsm :  2.5131828784942627 neg entropy :  561.1813354492188\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9075, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4825, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.8363, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2460  Loss :  0.619225263595581 dsm :  0.28049251437187195 neg entropy :  552.9329223632812\n",
      "{'edge_loss': tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.9426, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.7259, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2470  Loss :  0.5532512664794922 dsm :  0.9495588541030884 neg entropy :  562.1541137695312\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3328, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2990, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.5386, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2480  Loss :  0.5676969289779663 dsm :  1.0160127878189087 neg entropy :  560.0444946289062\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1024, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4087, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.0019, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  90  Batch :  2490  Loss :  0.4080807566642761 dsm :  0.3128868639469147 neg entropy :  555.9576416015625\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9084, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3282, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1335, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3276, device='cuda:0'), 'property_loss': tensor(485.6108, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  0 Loss sum :  0.5242586731910706 dsm :  2.7181718349456787 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0259, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3586, device='cuda:0'), 'property_loss': tensor(509.2065, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  10 Loss sum :  0.3167541027069092 dsm :  2.173663377761841 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0245, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2775, device='cuda:0'), 'property_loss': tensor(498.1511, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  20 Loss sum :  0.4422367513179779 dsm :  0.6178106665611267 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2615, device='cuda:0'), 'property_loss': tensor(480.4773, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  30 Loss sum :  0.5017700791358948 dsm :  0.7781388163566589 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3869, device='cuda:0'), 'property_loss': tensor(503.8026, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  40 Loss sum :  0.532968282699585 dsm :  2.1935882568359375 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3056, device='cuda:0'), 'property_loss': tensor(472.6206, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  50 Loss sum :  0.4887576401233673 dsm :  0.6938983798027039 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5078, device='cuda:0'), 'property_loss': tensor(528.9103, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  60 Loss sum :  0.6819949150085449 dsm :  4.911580562591553 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2478, device='cuda:0'), 'property_loss': tensor(456.2796, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  70 Loss sum :  0.5084160566329956 dsm :  0.41355106234550476 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4489, device='cuda:0'), 'property_loss': tensor(529.4980, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  80 Loss sum :  0.6127035617828369 dsm :  6.073654651641846 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0'), 'node_loss': tensor(0.0021, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3440, device='cuda:0'), 'property_loss': tensor(486.6552, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  90 Loss sum :  0.5905880928039551 dsm :  3.061394691467285 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4166, device='cuda:0'), 'property_loss': tensor(526.3496, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  100 Loss sum :  0.5310889482498169 dsm :  1.5957833528518677 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3915, device='cuda:0'), 'property_loss': tensor(522.0284, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  110 Loss sum :  0.5598698258399963 dsm :  2.5438573360443115 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.2941, device='cuda:0'), 'property_loss': tensor(484.1086, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  120 Loss sum :  0.4864862561225891 dsm :  0.341371089220047 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3434, device='cuda:0'), 'property_loss': tensor(491.1019, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  130 Loss sum :  0.5205093622207642 dsm :  2.347093343734741 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2655, device='cuda:0'), 'property_loss': tensor(470.1278, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  140 Loss sum :  0.33993059396743774 dsm :  1.508757472038269 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0'), 'node_loss': tensor(-0.0485, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4761, device='cuda:0'), 'property_loss': tensor(517.8552, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  150 Loss sum :  0.09064231812953949 dsm :  0.3420620858669281 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2758, device='cuda:0'), 'property_loss': tensor(482.2133, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  160 Loss sum :  0.34034639596939087 dsm :  1.7369540929794312 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0'), 'node_loss': tensor(-0.0147, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2538, device='cuda:0'), 'property_loss': tensor(447.1945, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  170 Loss sum :  0.3873724341392517 dsm :  0.7267665266990662 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0254, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3094, device='cuda:0'), 'property_loss': tensor(492.6288, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  180 Loss sum :  0.4514538645744324 dsm :  0.44729048013687134 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3104, device='cuda:0'), 'property_loss': tensor(505.4714, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  190 Loss sum :  0.4921899437904358 dsm :  0.04023643210530281 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2841, device='cuda:0'), 'property_loss': tensor(466.3947, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  200 Loss sum :  0.5439686179161072 dsm :  0.20543061196804047 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(0.0025, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3776, device='cuda:0'), 'property_loss': tensor(501.4993, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  210 Loss sum :  0.5624426007270813 dsm :  1.6451209783554077 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3315, device='cuda:0'), 'property_loss': tensor(492.7529, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  220 Loss sum :  0.5317903161048889 dsm :  4.3797831535339355 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3795, device='cuda:0'), 'property_loss': tensor(507.0709, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  230 Loss sum :  0.37836992740631104 dsm :  2.507697343826294 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(-0.0157, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4251, device='cuda:0'), 'property_loss': tensor(515.4127, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  240 Loss sum :  0.3862379789352417 dsm :  1.7578344345092773 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2375, device='cuda:0'), 'property_loss': tensor(461.8369, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  250 Loss sum :  0.48669496178627014 dsm :  1.549776554107666 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0244, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3896, device='cuda:0'), 'property_loss': tensor(525.3076, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  260 Loss sum :  0.45684748888015747 dsm :  1.148990511894226 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3501, device='cuda:0'), 'property_loss': tensor(493.4013, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  270 Loss sum :  0.5493093132972717 dsm :  1.2408405542373657 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0283, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4353, device='cuda:0'), 'property_loss': tensor(534.2198, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  280 Loss sum :  0.4986003041267395 dsm :  0.3474608361721039 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4109, device='cuda:0'), 'property_loss': tensor(496.6040, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  290 Loss sum :  0.39630457758903503 dsm :  2.567438840866089 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0'), 'node_loss': tensor(0.0038, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3527, device='cuda:0'), 'property_loss': tensor(474.5111, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  300 Loss sum :  0.6588321328163147 dsm :  4.575227737426758 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0'), 'node_loss': tensor(0.0031, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2391, device='cuda:0'), 'property_loss': tensor(465.0379, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  310 Loss sum :  0.5814790725708008 dsm :  3.556039571762085 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0278, device='cuda:0'), 'node_loss': tensor(-0.0148, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3055, device='cuda:0'), 'property_loss': tensor(497.7296, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  320 Loss sum :  0.33044832944869995 dsm :  1.26427161693573 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4444, device='cuda:0'), 'property_loss': tensor(536.2954, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  330 Loss sum :  0.5715224146842957 dsm :  5.9444899559021 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3262, device='cuda:0'), 'property_loss': tensor(477.1265, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  340 Loss sum :  0.40050551295280457 dsm :  1.6970903873443604 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2950, device='cuda:0'), 'property_loss': tensor(473.5663, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  350 Loss sum :  0.5911175608634949 dsm :  3.807014226913452 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0257, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3189, device='cuda:0'), 'property_loss': tensor(506.7176, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  360 Loss sum :  0.5004362463951111 dsm :  4.980897426605225 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0'), 'node_loss': tensor(-0.0153, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2213, device='cuda:0'), 'property_loss': tensor(467.7066, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  370 Loss sum :  0.3817276954650879 dsm :  5.321495532989502 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0'), 'node_loss': tensor(0.0015, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2771, device='cuda:0'), 'property_loss': tensor(471.5475, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  380 Loss sum :  0.5075020790100098 dsm :  1.5412992238998413 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4181, device='cuda:0'), 'property_loss': tensor(517.1873, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  390 Loss sum :  0.5530178546905518 dsm :  1.0432995557785034 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3580, device='cuda:0'), 'property_loss': tensor(490.8734, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  400 Loss sum :  0.5368236303329468 dsm :  1.9521316289901733 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3476, device='cuda:0'), 'property_loss': tensor(496.8341, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  410 Loss sum :  0.5505544543266296 dsm :  0.993859589099884 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0284, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2679, device='cuda:0'), 'property_loss': tensor(469.3431, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  420 Loss sum :  0.32778269052505493 dsm :  2.199791431427002 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0245, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2910, device='cuda:0'), 'property_loss': tensor(492.0261, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  430 Loss sum :  0.44266897439956665 dsm :  0.6820651888847351 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3405, device='cuda:0'), 'property_loss': tensor(496.9185, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  440 Loss sum :  0.5114047527313232 dsm :  0.17840944230556488 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3514, device='cuda:0'), 'property_loss': tensor(476.3730, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  450 Loss sum :  0.6100414991378784 dsm :  1.3276784420013428 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(0.0021, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3401, device='cuda:0'), 'property_loss': tensor(496.8992, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  460 Loss sum :  0.6018853187561035 dsm :  4.337027072906494 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.3035, device='cuda:0'), 'property_loss': tensor(474.4956, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  470 Loss sum :  0.3710523843765259 dsm :  0.07039682567119598 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2546, device='cuda:0'), 'property_loss': tensor(457.0193, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  480 Loss sum :  0.42839908599853516 dsm :  2.177485227584839 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0258, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2851, device='cuda:0'), 'property_loss': tensor(486.0405, device='cuda:0')}\n",
      "Epoch (val) :  90   batch (val) :  490 Loss sum :  0.4508146643638611 dsm :  0.18194670975208282 neg entropy :  568.9645385742188\n",
      "Epoch :  91  Batch :  0  Loss :  0.5964188575744629 dsm :  3.0387020111083984 neg entropy :  558.2703247070312\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3414, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3308, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.8794, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  10  Loss :  0.6335886716842651 dsm :  0.60033118724823 neg entropy :  551.6905517578125\n",
      "{'edge_loss': tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.6979, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.6497, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  20  Loss :  0.5161882042884827 dsm :  0.9355852007865906 neg entropy :  560.4282836914062\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5677, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2712, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.7555, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  30  Loss :  0.4063531458377838 dsm :  2.1552836894989014 neg entropy :  561.2200927734375\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7914, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9456, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  40  Loss :  0.5457292795181274 dsm :  2.3366546630859375 neg entropy :  558.2388916015625\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3435, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.6333, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  50  Loss :  0.4572908282279968 dsm :  2.716547727584839 neg entropy :  563.5172119140625\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9787, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.7306, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  60  Loss :  0.5749111771583557 dsm :  1.2368358373641968 neg entropy :  557.97705078125\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2214, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.4136, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  70  Loss :  0.44423937797546387 dsm :  2.5297610759735107 neg entropy :  553.9415893554688\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.9250, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3691, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.7637, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  80  Loss :  0.49401065707206726 dsm :  0.8386169672012329 neg entropy :  562.5897827148438\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2288, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.5827, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  90  Loss :  0.5862157344818115 dsm :  2.5649795532226562 neg entropy :  558.3585205078125\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9940, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.0833, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  100  Loss :  0.5617254972457886 dsm :  0.487415611743927 neg entropy :  559.8245239257812\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3140, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2843, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.4745, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  110  Loss :  0.5700516104698181 dsm :  0.36883193254470825 neg entropy :  559.5343627929688\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7655, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.8320, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  120  Loss :  0.5889523029327393 dsm :  3.638146162033081 neg entropy :  561.0516967773438\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4017, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.4694, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  130  Loss :  0.5528998374938965 dsm :  3.937391996383667 neg entropy :  561.76123046875\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2648, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.2166, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  140  Loss :  0.5483006834983826 dsm :  1.592246651649475 neg entropy :  560.5546264648438\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1883, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.8429, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  150  Loss :  0.5889450311660767 dsm :  1.6709133386611938 neg entropy :  556.2472534179688\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4924, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3709, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.5101, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  160  Loss :  0.5800397396087646 dsm :  7.061304569244385 neg entropy :  561.2637329101562\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4040, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.4950, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  170  Loss :  0.614997148513794 dsm :  1.1827144622802734 neg entropy :  559.6815185546875\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4395, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4092, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.6270, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  180  Loss :  0.603339672088623 dsm :  1.183278203010559 neg entropy :  560.1039428710938\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6447, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.5223, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  190  Loss :  0.5546237826347351 dsm :  1.0285707712173462 neg entropy :  561.2811889648438\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9830, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4561, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.7214, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  200  Loss :  0.6179718971252441 dsm :  6.040111541748047 neg entropy :  560.0983276367188\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2876, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3524, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.7050, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  210  Loss :  0.5227528810501099 dsm :  0.7041016817092896 neg entropy :  559.9465942382812\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1780, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.1824, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  220  Loss :  0.5905136466026306 dsm :  0.16039088368415833 neg entropy :  558.7249145507812\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2796, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5029, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  230  Loss :  0.4150332510471344 dsm :  0.7553392648696899 neg entropy :  555.79638671875\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0506, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.0234, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  240  Loss :  0.5802010297775269 dsm :  0.7436321377754211 neg entropy :  553.8978881835938\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9263, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.3699, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  250  Loss :  0.46885016560554504 dsm :  4.009171962738037 neg entropy :  558.4134521484375\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7514, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.0905, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  260  Loss :  0.6338701844215393 dsm :  0.9265634417533875 neg entropy :  545.1996459960938\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.5385, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4518, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.0629, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  270  Loss :  0.5628264546394348 dsm :  0.3913991153240204 neg entropy :  558.6257934570312\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0038, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0589, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3344, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9083, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  280  Loss :  0.5529298782348633 dsm :  0.31249159574508667 neg entropy :  562.2250366210938\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6886, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3088, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0075, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  290  Loss :  0.6293222904205322 dsm :  0.43138834834098816 neg entropy :  553.6539916992188\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6975, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3765, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.8369, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  300  Loss :  0.5687030553817749 dsm :  0.17434687912464142 neg entropy :  557.3982543945312\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5380, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.3648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  310  Loss :  0.6541420221328735 dsm :  3.8505637645721436 neg entropy :  557.5166625976562\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5925, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.1224, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  320  Loss :  0.550948441028595 dsm :  0.43687841296195984 neg entropy :  558.0637817382812\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5395, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4591, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(527.8471, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  330  Loss :  0.5322875380516052 dsm :  0.2139527052640915 neg entropy :  561.4054565429688\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9635, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2582, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.6523, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  340  Loss :  0.3604910671710968 dsm :  0.6698610782623291 neg entropy :  556.4508666992188\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1440, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2125, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(429.5322, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  350  Loss :  0.41793209314346313 dsm :  1.3876266479492188 neg entropy :  562.125\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0137, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4662, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4254, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(531.0744, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  360  Loss :  0.2184833288192749 dsm :  1.209585428237915 neg entropy :  556.8624267578125\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0316, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3418, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.1479, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  370  Loss :  0.4019005298614502 dsm :  2.1222591400146484 neg entropy :  561.9918823242188\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7594, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3022, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.4401, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  380  Loss :  0.5193809270858765 dsm :  0.8327116966247559 neg entropy :  567.564453125\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5592, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3078, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.4163, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  390  Loss :  0.615121603012085 dsm :  2.333648443222046 neg entropy :  560.0504150390625\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0042, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8187, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2794, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.0088, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  400  Loss :  0.38491538166999817 dsm :  0.2998100221157074 neg entropy :  563.9008178710938\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3003, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3382, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.0166, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  410  Loss :  0.6013186573982239 dsm :  0.5653007626533508 neg entropy :  556.9000854492188\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1999, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3909, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.8250, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  420  Loss :  0.6030460596084595 dsm :  1.8254457712173462 neg entropy :  564.9318237304688\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3433, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.3936, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  430  Loss :  0.5523776412010193 dsm :  0.15280784666538239 neg entropy :  557.2401733398438\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7613, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3698, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.1009, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  440  Loss :  0.41959571838378906 dsm :  2.0082101821899414 neg entropy :  551.9067993164062\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.6581, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.6313, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  450  Loss :  0.5797231793403625 dsm :  0.3085760176181793 neg entropy :  555.871337890625\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9283, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.0356, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  460  Loss :  0.5641040802001953 dsm :  3.713029623031616 neg entropy :  564.3043823242188\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6485, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2916, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.1605, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  470  Loss :  0.5786991119384766 dsm :  4.208553314208984 neg entropy :  565.5443115234375\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3588, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2864, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.5962, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  480  Loss :  0.5901714563369751 dsm :  0.7239760756492615 neg entropy :  557.4814453125\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9253, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2494, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.2310, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  490  Loss :  0.6589434146881104 dsm :  0.8729011416435242 neg entropy :  551.3787231445312\n",
      "{'edge_loss': tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3839, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4907, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9757, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  500  Loss :  0.4435744881629944 dsm :  1.0225683450698853 neg entropy :  555.2775268554688\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0138, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0118, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1249, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  510  Loss :  0.4981493651866913 dsm :  0.5120412111282349 neg entropy :  554.0997924804688\n",
      "{'edge_loss': tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6421, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3813, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.1479, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  520  Loss :  0.3951515555381775 dsm :  0.011405774392187595 neg entropy :  557.3336791992188\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5659, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.9231, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  530  Loss :  0.549688458442688 dsm :  2.8374929428100586 neg entropy :  562.79150390625\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2345, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3238, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.5490, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  540  Loss :  0.6259160041809082 dsm :  4.944626331329346 neg entropy :  559.1480712890625\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6918, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.5405, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  550  Loss :  0.6522512435913086 dsm :  2.7578625679016113 neg entropy :  550.853759765625\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5903, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4496, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.1661, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  560  Loss :  0.4134219288825989 dsm :  0.2165936976671219 neg entropy :  559.9335327148438\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6520, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2728, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.2166, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  570  Loss :  0.44649842381477356 dsm :  1.4227179288864136 neg entropy :  558.4002075195312\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3860, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.7869, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  580  Loss :  0.5019096732139587 dsm :  2.6548075675964355 neg entropy :  563.1622314453125\n",
      "{'edge_loss': tensor(0.0276, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4520, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2730, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.2535, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  590  Loss :  0.5636840462684631 dsm :  6.666054725646973 neg entropy :  559.609619140625\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2500, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4076, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.0805, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  600  Loss :  0.5661860108375549 dsm :  2.0882625579833984 neg entropy :  554.6648559570312\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9200, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4254, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.2186, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  610  Loss :  0.6689861416816711 dsm :  1.412422776222229 neg entropy :  553.0772705078125\n",
      "{'edge_loss': tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5625, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3959, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.0622, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  620  Loss :  0.5863788723945618 dsm :  3.8109912872314453 neg entropy :  561.4548950195312\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9697, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2544, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(446.3028, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  630  Loss :  0.6082187294960022 dsm :  2.470355272293091 neg entropy :  560.3583374023438\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2355, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.7379, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  640  Loss :  0.28510016202926636 dsm :  0.49735745787620544 neg entropy :  553.8220825195312\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0306, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7978, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4238, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.0998, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  650  Loss :  0.5335935354232788 dsm :  2.9988012313842773 neg entropy :  563.3502807617188\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5287, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2790, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.3778, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  660  Loss :  0.5922681093215942 dsm :  1.792887568473816 neg entropy :  563.4464721679688\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7150, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3925, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.2984, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  670  Loss :  0.6448500156402588 dsm :  0.6806424856185913 neg entropy :  556.6868286132812\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2799, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.8577, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  680  Loss :  0.6734915375709534 dsm :  2.4131112098693848 neg entropy :  554.0035400390625\n",
      "{'edge_loss': tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1974, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4988, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.2469, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  690  Loss :  0.689494252204895 dsm :  4.753159046173096 neg entropy :  551.2496337890625\n",
      "{'edge_loss': tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4120, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.3284, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  700  Loss :  0.4732095003128052 dsm :  5.492743015289307 neg entropy :  561.24072265625\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0678, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3313, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.1854, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  710  Loss :  0.2778198719024658 dsm :  2.0332207679748535 neg entropy :  563.7177734375\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0313, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3184, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4527, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.4421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  720  Loss :  0.44860872626304626 dsm :  1.0232439041137695 neg entropy :  558.5436401367188\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0140, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1471, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2981, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(454.9770, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  730  Loss :  0.59038245677948 dsm :  1.997460961341858 neg entropy :  555.2295532226562\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0492, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.4241, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  740  Loss :  0.678442656993866 dsm :  3.9500787258148193 neg entropy :  554.8404541015625\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7926, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0770, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  750  Loss :  0.5967844724655151 dsm :  2.9503886699676514 neg entropy :  557.0037231445312\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8578, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.2882, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  760  Loss :  0.5377140641212463 dsm :  0.2987019121646881 neg entropy :  561.347412109375\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3209, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3703, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.3364, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  770  Loss :  0.5008328557014465 dsm :  0.9988266229629517 neg entropy :  555.7593994140625\n",
      "{'edge_loss': tensor(0.0274, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0406, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4385, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.1998, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  780  Loss :  0.5707816481590271 dsm :  0.5543437600135803 neg entropy :  559.2687377929688\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5348, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3856, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.8208, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  790  Loss :  0.5797078013420105 dsm :  1.8109201192855835 neg entropy :  565.13525390625\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4632, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3785, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.3536, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  800  Loss :  0.6339913606643677 dsm :  0.4344564974308014 neg entropy :  552.0048828125\n",
      "{'edge_loss': tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6247, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.7437, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  810  Loss :  0.46031153202056885 dsm :  1.2557650804519653 neg entropy :  557.0133056640625\n",
      "{'edge_loss': tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1969, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3163, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.3758, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  820  Loss :  0.6240503787994385 dsm :  9.306172370910645 neg entropy :  563.9951782226562\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.0344, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2760, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.5905, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  830  Loss :  0.4362189769744873 dsm :  0.9319376349449158 neg entropy :  559.4986572265625\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8642, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.3695, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  840  Loss :  0.6762761473655701 dsm :  6.130020618438721 neg entropy :  557.5643920898438\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6415, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4252, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.7000, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  850  Loss :  0.534221351146698 dsm :  0.027023186907172203 neg entropy :  556.2785034179688\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1578, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.8542, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  860  Loss :  0.536460280418396 dsm :  4.319084167480469 neg entropy :  563.8751220703125\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7529, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2135, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.8733, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  870  Loss :  0.7045933604240417 dsm :  0.3262278735637665 neg entropy :  549.3018798828125\n",
      "{'edge_loss': tensor(0.0474, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.0204, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4758, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.4337, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  880  Loss :  0.5634556412696838 dsm :  0.7013513445854187 neg entropy :  556.9984741210938\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8043, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3432, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3777, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  890  Loss :  0.5708705186843872 dsm :  0.47228407859802246 neg entropy :  556.4025268554688\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5464, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3650, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.7143, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  900  Loss :  0.5740496516227722 dsm :  0.2760309875011444 neg entropy :  556.3002319335938\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3799, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.8228, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  910  Loss :  0.5031978487968445 dsm :  4.0997161865234375 neg entropy :  563.1536865234375\n",
      "{'edge_loss': tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4447, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0362, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  920  Loss :  0.5887658596038818 dsm :  2.842057943344116 neg entropy :  559.9388427734375\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1535, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3396, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.8644, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  930  Loss :  0.5448428392410278 dsm :  0.4064386785030365 neg entropy :  560.72314453125\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0926, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3763, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.6760, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  940  Loss :  0.6185269355773926 dsm :  4.197868824005127 neg entropy :  560.4234619140625\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5489, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.9766, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  950  Loss :  0.5445752739906311 dsm :  0.4548661410808563 neg entropy :  562.3633422851562\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1182, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.9276, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  960  Loss :  0.5083674788475037 dsm :  1.61025071144104 neg entropy :  563.806884765625\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5715, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3187, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4870, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  970  Loss :  0.4383753836154938 dsm :  0.7987613081932068 neg entropy :  559.0341186523438\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0345, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3452, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.8726, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  980  Loss :  0.5619204640388489 dsm :  4.710205554962158 neg entropy :  558.7648315429688\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5508, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3963, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.2676, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  990  Loss :  0.5896837115287781 dsm :  1.9345813989639282 neg entropy :  556.68115234375\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5347, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.4229, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1000  Loss :  0.6015499234199524 dsm :  3.2116196155548096 neg entropy :  559.374755859375\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2615, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.0374, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1010  Loss :  0.5771200656890869 dsm :  0.9197835326194763 neg entropy :  556.5907592773438\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0469, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.5638, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1020  Loss :  0.5592401027679443 dsm :  1.2237285375595093 neg entropy :  559.0667114257812\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6399, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.7772, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1030  Loss :  0.5997772216796875 dsm :  2.1957192420959473 neg entropy :  557.1979370117188\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4509, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3345, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1379, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1040  Loss :  0.3657493591308594 dsm :  1.997388482093811 neg entropy :  562.595703125\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6108, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2621, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.7884, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1050  Loss :  0.583274245262146 dsm :  0.31989747285842896 neg entropy :  556.91552734375\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4399, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.8262, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1060  Loss :  0.6169081926345825 dsm :  3.907794237136841 neg entropy :  558.5949096679688\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2941, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.5801, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1070  Loss :  0.6467801332473755 dsm :  1.3937323093414307 neg entropy :  553.7551879882812\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8632, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4010, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.9856, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1080  Loss :  0.5506906509399414 dsm :  1.8687477111816406 neg entropy :  562.4259033203125\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6820, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4637, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(525.4846, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1090  Loss :  0.6467746496200562 dsm :  0.4095630645751953 neg entropy :  556.75439453125\n",
      "{'edge_loss': tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7429, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.9323, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1100  Loss :  0.4797776937484741 dsm :  3.35612416267395 neg entropy :  550.8043823242188\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0130, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3094, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3252, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.1426, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1110  Loss :  0.6633617281913757 dsm :  2.9377686977386475 neg entropy :  552.7860717773438\n",
      "{'edge_loss': tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5575, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.9286, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1120  Loss :  0.6408112049102783 dsm :  0.9174338579177856 neg entropy :  559.018798828125\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0164, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.2094, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1130  Loss :  0.5946181416511536 dsm :  0.9819747805595398 neg entropy :  555.3276977539062\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6562, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3204, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.2578, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1140  Loss :  0.5662996768951416 dsm :  0.8680093884468079 neg entropy :  557.7540893554688\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5096, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3892, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.7545, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1150  Loss :  0.5839073657989502 dsm :  1.9025262594223022 neg entropy :  562.2841796875\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8029, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3188, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.0380, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1160  Loss :  0.606924831867218 dsm :  1.4127824306488037 neg entropy :  557.8629760742188\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6249, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3945, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0744, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1170  Loss :  0.43581855297088623 dsm :  1.4862109422683716 neg entropy :  558.3468017578125\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0135, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3506, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3872, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.8686, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1180  Loss :  0.5832180976867676 dsm :  0.27421411871910095 neg entropy :  559.6705932617188\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7305, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3438, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3886, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1190  Loss :  0.515204906463623 dsm :  0.9046444892883301 neg entropy :  564.4469604492188\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0004, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6543, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.5189, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1200  Loss :  0.5122268795967102 dsm :  0.2473365068435669 neg entropy :  560.5833129882812\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0027, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3287, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.8467, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1210  Loss :  0.4991958737373352 dsm :  0.5830626487731934 neg entropy :  562.2646484375\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7405, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3662, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.7812, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1220  Loss :  0.558601975440979 dsm :  0.3429395854473114 neg entropy :  558.6277465820312\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2964, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3732, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.6964, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1230  Loss :  0.5600672364234924 dsm :  3.647203207015991 neg entropy :  558.5142822265625\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7377, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3444, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.6862, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1240  Loss :  0.650013267993927 dsm :  0.9795216917991638 neg entropy :  555.7283325195312\n",
      "{'edge_loss': tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3654, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.5923, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1250  Loss :  0.6586343050003052 dsm :  1.9743683338165283 neg entropy :  554.088623046875\n",
      "{'edge_loss': tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4781, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3942, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.9804, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1260  Loss :  0.6200483441352844 dsm :  1.734108567237854 neg entropy :  556.8516845703125\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0186, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3868, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.6343, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1270  Loss :  0.567411482334137 dsm :  1.4079021215438843 neg entropy :  556.7123413085938\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0858, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3480, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.5513, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1280  Loss :  0.5662370324134827 dsm :  1.5547298192977905 neg entropy :  560.594970703125\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7776, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4342, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.5439, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1290  Loss :  0.4226192831993103 dsm :  0.030448609963059425 neg entropy :  557.2846069335938\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0140, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3516, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4494, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.7944, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1300  Loss :  0.5459481477737427 dsm :  1.275018572807312 neg entropy :  552.6700439453125\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.7972, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2013, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.2349, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1310  Loss :  0.4101606607437134 dsm :  1.6788158416748047 neg entropy :  554.6605834960938\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3586, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(454.4388, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1320  Loss :  0.5589653849601746 dsm :  2.0360779762268066 neg entropy :  560.4361572265625\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4376, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4141, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.1193, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1330  Loss :  0.6250854134559631 dsm :  1.986236572265625 neg entropy :  555.9951171875\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0249, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0728, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1340  Loss :  0.5257628560066223 dsm :  0.7062578201293945 neg entropy :  557.60791015625\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9395, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.4093, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1350  Loss :  0.5559423565864563 dsm :  0.25225120782852173 neg entropy :  559.6151123046875\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7500, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3691, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.0720, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1360  Loss :  0.4248102605342865 dsm :  1.52578604221344 neg entropy :  556.9443969726562\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2682, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.9709, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1370  Loss :  0.3441113829612732 dsm :  2.0537571907043457 neg entropy :  564.2586059570312\n",
      "{'edge_loss': tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5204, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9656, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1380  Loss :  0.5503838658332825 dsm :  1.014733076095581 neg entropy :  560.69921875\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5878, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1846, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1390  Loss :  0.5686885118484497 dsm :  0.1502789855003357 neg entropy :  558.3014526367188\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8793, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.9525, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1400  Loss :  0.6144956946372986 dsm :  3.4469172954559326 neg entropy :  565.4235229492188\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5494, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4805, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.9875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1410  Loss :  0.4949350953102112 dsm :  0.9271799325942993 neg entropy :  560.9422607421875\n",
      "{'edge_loss': tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4867, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3483, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.6891, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1420  Loss :  0.584756076335907 dsm :  1.2060579061508179 neg entropy :  560.9577026367188\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6176, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2455, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.7338, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1430  Loss :  0.7476022839546204 dsm :  5.2764506340026855 neg entropy :  550.5866088867188\n",
      "{'edge_loss': tensor(0.0480, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.1332, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4138, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.7896, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1440  Loss :  0.5935125946998596 dsm :  2.606778860092163 neg entropy :  560.4718627929688\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9634, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3185, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.4622, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1450  Loss :  0.46775537729263306 dsm :  3.3673324584960938 neg entropy :  556.5629272460938\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9263, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2989, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.8550, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1460  Loss :  0.676862895488739 dsm :  3.2758948802948 neg entropy :  559.3598022460938\n",
      "{'edge_loss': tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1297, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.4213, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1470  Loss :  0.5374234318733215 dsm :  1.591133713722229 neg entropy :  563.6870727539062\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0003, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5433, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3373, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.0029, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1480  Loss :  0.28947821259498596 dsm :  1.735825777053833 neg entropy :  562.6378173828125\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0314, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3376, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3456, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.1989, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1490  Loss :  0.4099915623664856 dsm :  0.3939358592033386 neg entropy :  561.3855590820312\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0142, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3485, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3114, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.4651, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1500  Loss :  0.6333215832710266 dsm :  0.9977332949638367 neg entropy :  554.6228637695312\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2192, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3779, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.0578, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1510  Loss :  0.6508455872535706 dsm :  2.385511636734009 neg entropy :  560.1805419921875\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0383, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.8708, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1520  Loss :  0.5918439030647278 dsm :  1.4122718572616577 neg entropy :  562.1254272460938\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.6989, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1530  Loss :  0.6170662641525269 dsm :  0.09969576448202133 neg entropy :  557.0198364257812\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7021, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.4221, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1540  Loss :  0.5199111700057983 dsm :  1.5095022916793823 neg entropy :  560.8885498046875\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8422, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2870, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.0001, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1550  Loss :  0.5329795479774475 dsm :  0.011424711905419827 neg entropy :  560.7387084960938\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6941, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3406, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.5655, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1560  Loss :  0.37480628490448 dsm :  1.5130451917648315 neg entropy :  566.2877807617188\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.0560, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3739, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.5830, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1570  Loss :  0.5378732681274414 dsm :  1.6539363861083984 neg entropy :  561.7586669921875\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0259, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.3574, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1580  Loss :  0.6523747444152832 dsm :  5.184109687805176 neg entropy :  560.58154296875\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0403, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4192, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.0491, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1590  Loss :  0.5857869386672974 dsm :  1.6331895589828491 neg entropy :  554.7023315429688\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0527, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3189, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.7239, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1600  Loss :  0.47896650433540344 dsm :  0.43018776178359985 neg entropy :  561.4391479492188\n",
      "{'edge_loss': tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3259, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2776, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.2457, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1610  Loss :  0.5733451843261719 dsm :  0.3202969431877136 neg entropy :  562.7432861328125\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5197, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.4261, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1620  Loss :  0.11233441531658173 dsm :  0.18317411839962006 neg entropy :  562.2123413085938\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0483, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.1275, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.8628, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1630  Loss :  0.509492814540863 dsm :  0.2279239147901535 neg entropy :  559.8424682617188\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2966, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.6396, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1640  Loss :  0.6392642855644226 dsm :  3.659388780593872 neg entropy :  557.8675537109375\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6065, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4963, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(540.8486, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1650  Loss :  0.586411714553833 dsm :  4.245715618133545 neg entropy :  567.2516479492188\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.0042, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.9955, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1660  Loss :  0.6368905305862427 dsm :  5.075141429901123 neg entropy :  559.2107543945312\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1368, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.6372, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1670  Loss :  0.6231281757354736 dsm :  3.7997429370880127 neg entropy :  559.0035400390625\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6953, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3768, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.7439, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1680  Loss :  0.6109520792961121 dsm :  0.9304571151733398 neg entropy :  553.9973754882812\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3884, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.2591, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1690  Loss :  0.5302891135215759 dsm :  0.6768375635147095 neg entropy :  562.681396484375\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9380, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4131, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.6088, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1700  Loss :  0.4724007844924927 dsm :  0.11644939333200455 neg entropy :  554.9351806640625\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7026, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4668, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.9300, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1710  Loss :  0.4327968955039978 dsm :  2.14363169670105 neg entropy :  557.7418212890625\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5915, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.9742, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1720  Loss :  0.5621427893638611 dsm :  1.7896355390548706 neg entropy :  559.0264892578125\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5348, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1401, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1730  Loss :  0.5977795124053955 dsm :  1.5925110578536987 neg entropy :  554.6530151367188\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9400, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.5497, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1740  Loss :  0.5290694832801819 dsm :  1.3352468013763428 neg entropy :  564.8530883789062\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5374, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.0864, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1750  Loss :  0.5390468835830688 dsm :  0.7454506158828735 neg entropy :  557.702392578125\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4003, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.5617, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1760  Loss :  0.5760998725891113 dsm :  1.4063148498535156 neg entropy :  560.9811401367188\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0288, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1007, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1770  Loss :  0.601578950881958 dsm :  0.13036805391311646 neg entropy :  563.7511596679688\n",
      "{'edge_loss': tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8941, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.3217, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1780  Loss :  0.6062539219856262 dsm :  0.2257409393787384 neg entropy :  553.9779052734375\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7933, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4515, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.9441, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1790  Loss :  0.5278835892677307 dsm :  0.4241231381893158 neg entropy :  561.4934692382812\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4990, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.1175, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1800  Loss :  0.6212357878684998 dsm :  2.3446247577667236 neg entropy :  558.1287231445312\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1448, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3292, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.8118, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1810  Loss :  0.6107611060142517 dsm :  2.8026771545410156 neg entropy :  556.7576293945312\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2596, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.5050, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1820  Loss :  0.5919635891914368 dsm :  0.3526964485645294 neg entropy :  556.5068969726562\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3238, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3682, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.5230, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1830  Loss :  0.6670785546302795 dsm :  1.1077526807785034 neg entropy :  561.227294921875\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9883, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3118, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.8220, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1840  Loss :  0.21818986535072327 dsm :  2.3097758293151855 neg entropy :  559.7340698242188\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0314, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6713, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.1929, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1850  Loss :  0.6076749563217163 dsm :  2.06392240524292 neg entropy :  559.9793090820312\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0522, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3337, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1860  Loss :  0.6141261458396912 dsm :  7.982646942138672 neg entropy :  566.3417358398438\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.5503, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4279, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.6109, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1870  Loss :  0.6455246806144714 dsm :  4.8622307777404785 neg entropy :  564.6838989257812\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8070, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2821, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.4875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1880  Loss :  0.3842311501502991 dsm :  2.1117265224456787 neg entropy :  560.9365234375\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5771, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3121, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.1343, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1890  Loss :  0.5672183036804199 dsm :  5.349175930023193 neg entropy :  566.347900390625\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4973, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.8788, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1900  Loss :  0.6081861257553101 dsm :  0.4786672294139862 neg entropy :  561.6195068359375\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9776, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4266, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.7350, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1910  Loss :  0.5173330903053284 dsm :  0.6354396939277649 neg entropy :  556.7894897460938\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4287, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.7819, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1920  Loss :  0.5044691562652588 dsm :  0.057767029851675034 neg entropy :  560.5140991210938\n",
      "{'edge_loss': tensor(0.0292, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1057, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4775, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(533.9675, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1930  Loss :  0.5214956998825073 dsm :  4.115002632141113 neg entropy :  554.86181640625\n",
      "{'edge_loss': tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1635, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.8319, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1940  Loss :  0.19629603624343872 dsm :  0.6906353831291199 neg entropy :  561.799072265625\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0316, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5256, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2643, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(448.8709, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1950  Loss :  0.6170263290405273 dsm :  1.343812346458435 neg entropy :  560.9518432617188\n",
      "{'edge_loss': tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6330, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3039, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.2278, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1960  Loss :  0.5892497301101685 dsm :  1.2486622333526611 neg entropy :  553.14208984375\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.1779, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2602, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.6064, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1970  Loss :  0.5848734974861145 dsm :  1.809024453163147 neg entropy :  554.4083862304688\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9160, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3429, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.7506, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1980  Loss :  0.4375006854534149 dsm :  2.100898027420044 neg entropy :  554.4182739257812\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8983, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2558, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.3346, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  1990  Loss :  0.5397042036056519 dsm :  1.36696457862854 neg entropy :  564.2413330078125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1763, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.8245, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2000  Loss :  0.5661499500274658 dsm :  1.3935842514038086 neg entropy :  558.5768432617188\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7425, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4417, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.1165, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2010  Loss :  0.6099388003349304 dsm :  0.7892799377441406 neg entropy :  555.6974487304688\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7081, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4556, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.6856, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2020  Loss :  0.458400160074234 dsm :  0.4498428404331207 neg entropy :  563.8202514648438\n",
      "{'edge_loss': tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1376, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3157, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5135, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2030  Loss :  0.6184736490249634 dsm :  2.065720558166504 neg entropy :  560.5387573242188\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8792, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.5412, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2040  Loss :  0.5661764740943909 dsm :  1.8284605741500854 neg entropy :  563.1065673828125\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3264, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.4720, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2050  Loss :  0.5982500910758972 dsm :  5.088068962097168 neg entropy :  560.9461059570312\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3947, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4449, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(529.6874, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2060  Loss :  0.5712734460830688 dsm :  0.3528072237968445 neg entropy :  558.5764770507812\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6943, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3572, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.0461, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2070  Loss :  0.5637914538383484 dsm :  0.08049698919057846 neg entropy :  559.8129272460938\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6792, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2555, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.4814, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2080  Loss :  0.6267755627632141 dsm :  0.9550299048423767 neg entropy :  558.3305053710938\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4828, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3567, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.4287, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2090  Loss :  0.5862731337547302 dsm :  4.229060649871826 neg entropy :  556.4696655273438\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7413, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4194, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.8600, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2100  Loss :  0.5113604068756104 dsm :  0.3248048722743988 neg entropy :  565.9822998046875\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1285, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3975, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.8549, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2110  Loss :  0.6088529825210571 dsm :  0.36373353004455566 neg entropy :  559.0791015625\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9897, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4089, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.9683, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2120  Loss :  0.43481194972991943 dsm :  5.373082637786865 neg entropy :  566.1047973632812\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3142, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4488, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(528.5267, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2130  Loss :  0.5404349565505981 dsm :  1.2279770374298096 neg entropy :  564.6259155273438\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6648, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2891, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.3842, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2140  Loss :  0.6545825004577637 dsm :  3.8808205127716064 neg entropy :  555.6495971679688\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5563, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3873, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.6089, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2150  Loss :  0.6110776662826538 dsm :  1.2612100839614868 neg entropy :  558.7208251953125\n",
      "{'edge_loss': tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8203, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.6047, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2160  Loss :  0.3861549198627472 dsm :  0.3739510476589203 neg entropy :  560.0536499023438\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9820, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.8675, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2170  Loss :  0.637711226940155 dsm :  0.9121293425559998 neg entropy :  557.0723266601562\n",
      "{'edge_loss': tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4220, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.8419, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2180  Loss :  0.4248831272125244 dsm :  2.3326408863067627 neg entropy :  561.4750366210938\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7276, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.0972, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2190  Loss :  0.5403765439987183 dsm :  0.02159265987575054 neg entropy :  553.3143920898438\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9920, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.7555, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2200  Loss :  0.3693433701992035 dsm :  1.767634630203247 neg entropy :  564.4872436523438\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8486, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2912, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.5445, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2210  Loss :  0.5402868390083313 dsm :  1.2153756618499756 neg entropy :  558.0391235351562\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3540, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.3376, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2220  Loss :  0.5935667157173157 dsm :  2.4850213527679443 neg entropy :  562.39990234375\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3226, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.3913, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2230  Loss :  0.574921190738678 dsm :  1.104168176651001 neg entropy :  558.7794799804688\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0130, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.2654, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2240  Loss :  0.553784191608429 dsm :  1.262550711631775 neg entropy :  560.9928588867188\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0959, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3957, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.5440, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2250  Loss :  0.5761653184890747 dsm :  4.702667236328125 neg entropy :  564.6736450195312\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4239, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2559, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(454.6163, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2260  Loss :  0.5653371214866638 dsm :  0.08899234235286713 neg entropy :  556.7160034179688\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9292, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3536, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5047, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2270  Loss :  0.550861656665802 dsm :  1.081960916519165 neg entropy :  563.4822998046875\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8562, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3664, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.3660, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2280  Loss :  0.5408828258514404 dsm :  1.6853744983673096 neg entropy :  557.7567749023438\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2788, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4283, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.9200, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2290  Loss :  0.4564207196235657 dsm :  5.0029754638671875 neg entropy :  561.2694702148438\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5687, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.7558, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2300  Loss :  0.5608817934989929 dsm :  1.7758339643478394 neg entropy :  559.3602905273438\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0006, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3554, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.3066, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2310  Loss :  0.6501162648200989 dsm :  3.9801414012908936 neg entropy :  557.0316772460938\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2832, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4191, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.4291, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2320  Loss :  0.5348233580589294 dsm :  0.21609139442443848 neg entropy :  565.4547729492188\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.7663, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3258, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.3383, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2330  Loss :  0.6105458736419678 dsm :  2.321021795272827 neg entropy :  555.8074951171875\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3965, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4583, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.4841, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2340  Loss :  0.65999436378479 dsm :  3.4422223567962646 neg entropy :  552.3746337890625\n",
      "{'edge_loss': tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4250, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.3457, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2350  Loss :  0.5598689913749695 dsm :  0.09162180870771408 neg entropy :  558.2135620117188\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7323, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1729, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2360  Loss :  0.5936417579650879 dsm :  2.1568310260772705 neg entropy :  554.9789428710938\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3660, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.5627, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2370  Loss :  0.6347982883453369 dsm :  0.7173555493354797 neg entropy :  550.4417114257812\n",
      "{'edge_loss': tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.5010, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3598, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.5901, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2380  Loss :  0.5834406614303589 dsm :  0.128657266497612 neg entropy :  560.6119995117188\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5781, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1832, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2390  Loss :  0.552265465259552 dsm :  0.41149240732192993 neg entropy :  560.35693359375\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8815, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.4122, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2400  Loss :  0.5980836749076843 dsm :  0.6918946504592896 neg entropy :  562.1660766601562\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4007, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3636, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.7525, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2410  Loss :  0.4739002287387848 dsm :  1.6493362188339233 neg entropy :  559.04052734375\n",
      "{'edge_loss': tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0441, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3028, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(446.7214, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2420  Loss :  0.7055546045303345 dsm :  2.499089002609253 neg entropy :  556.5082397460938\n",
      "{'edge_loss': tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5828, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4895, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.8174, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2430  Loss :  0.6143690347671509 dsm :  0.4643661081790924 neg entropy :  556.405517578125\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5036, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3002, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.4456, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2440  Loss :  0.34464308619499207 dsm :  1.153880000114441 neg entropy :  556.8859252929688\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1296, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2738, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.7670, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2450  Loss :  0.5605271458625793 dsm :  2.417649745941162 neg entropy :  569.0337524414062\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.6066, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3092, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.9320, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2460  Loss :  0.4185497760772705 dsm :  1.3410536050796509 neg entropy :  559.0932006835938\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7164, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.5261, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2470  Loss :  0.5444064736366272 dsm :  1.3949344158172607 neg entropy :  560.0929565429688\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3561, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2918, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2480  Loss :  0.5580319762229919 dsm :  0.8318302035331726 neg entropy :  562.7314453125\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7169, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.2351, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  91  Batch :  2490  Loss :  0.5555997490882874 dsm :  4.278745174407959 neg entropy :  567.7196044921875\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.4997, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2930, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.9228, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3209, device='cuda:0'), 'property_loss': tensor(486.6379, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  0 Loss sum :  0.5186330080032349 dsm :  2.6380996704101562 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0261, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3620, device='cuda:0'), 'property_loss': tensor(513.9078, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  10 Loss sum :  0.3215084373950958 dsm :  2.7237918376922607 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0247, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2731, device='cuda:0'), 'property_loss': tensor(497.0213, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  20 Loss sum :  0.44342508912086487 dsm :  0.5080781579017639 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2566, device='cuda:0'), 'property_loss': tensor(481.8491, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  30 Loss sum :  0.5110740065574646 dsm :  1.439237356185913 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3856, device='cuda:0'), 'property_loss': tensor(505.2797, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  40 Loss sum :  0.5209231376647949 dsm :  0.27628952264785767 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0282, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3063, device='cuda:0'), 'property_loss': tensor(471.2366, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  50 Loss sum :  0.4879109263420105 dsm :  1.3718668222427368 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5079, device='cuda:0'), 'property_loss': tensor(526.6638, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  60 Loss sum :  0.6393868923187256 dsm :  2.225553035736084 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2497, device='cuda:0'), 'property_loss': tensor(456.7682, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  70 Loss sum :  0.5395628809928894 dsm :  4.611588954925537 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4491, device='cuda:0'), 'property_loss': tensor(526.4581, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  80 Loss sum :  0.5813576579093933 dsm :  3.1279919147491455 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3468, device='cuda:0'), 'property_loss': tensor(486.8349, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  90 Loss sum :  0.5767402052879333 dsm :  1.9126862287521362 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4191, device='cuda:0'), 'property_loss': tensor(525.9710, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  100 Loss sum :  0.5364063382148743 dsm :  2.4204719066619873 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3887, device='cuda:0'), 'property_loss': tensor(522.8060, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  110 Loss sum :  0.5260511040687561 dsm :  1.312580943107605 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.2992, device='cuda:0'), 'property_loss': tensor(484.1931, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  120 Loss sum :  0.5053947567939758 dsm :  0.958587110042572 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3466, device='cuda:0'), 'property_loss': tensor(491.2603, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  130 Loss sum :  0.5054804682731628 dsm :  0.4558320939540863 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2664, device='cuda:0'), 'property_loss': tensor(472.1452, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  140 Loss sum :  0.3360370993614197 dsm :  1.0467956066131592 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0'), 'node_loss': tensor(-0.0484, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4761, device='cuda:0'), 'property_loss': tensor(513.5410, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  150 Loss sum :  0.10211367905139923 dsm :  2.190275192260742 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0'), 'node_loss': tensor(-0.0158, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2769, device='cuda:0'), 'property_loss': tensor(480.5224, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  160 Loss sum :  0.3453163206577301 dsm :  2.041736364364624 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(-0.0148, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2528, device='cuda:0'), 'property_loss': tensor(445.7539, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  170 Loss sum :  0.3808800280094147 dsm :  0.8592260479927063 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0254, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3097, device='cuda:0'), 'property_loss': tensor(490.5061, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  180 Loss sum :  0.5037769079208374 dsm :  5.6098408699035645 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0287, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3175, device='cuda:0'), 'property_loss': tensor(505.5114, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  190 Loss sum :  0.4887421727180481 dsm :  0.40946537256240845 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2833, device='cuda:0'), 'property_loss': tensor(469.5104, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  200 Loss sum :  0.5369717478752136 dsm :  0.3880265951156616 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3757, device='cuda:0'), 'property_loss': tensor(502.6880, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  210 Loss sum :  0.5783523321151733 dsm :  4.37558126449585 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0292, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3285, device='cuda:0'), 'property_loss': tensor(491.7563, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  220 Loss sum :  0.4868381917476654 dsm :  0.14866475760936737 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3767, device='cuda:0'), 'property_loss': tensor(507.1081, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  230 Loss sum :  0.3570479452610016 dsm :  1.6144609451293945 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4270, device='cuda:0'), 'property_loss': tensor(518.0944, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  240 Loss sum :  0.37863993644714355 dsm :  1.3111923933029175 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2391, device='cuda:0'), 'property_loss': tensor(463.9664, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  250 Loss sum :  0.5028299689292908 dsm :  2.779418706893921 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0247, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3869, device='cuda:0'), 'property_loss': tensor(523.1229, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  260 Loss sum :  0.4531742036342621 dsm :  0.611824631690979 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3533, device='cuda:0'), 'property_loss': tensor(492.5544, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  270 Loss sum :  0.5473997592926025 dsm :  1.2826651334762573 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0278, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4398, device='cuda:0'), 'property_loss': tensor(532.6520, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  280 Loss sum :  0.531466007232666 dsm :  4.45943021774292 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4088, device='cuda:0'), 'property_loss': tensor(494.8039, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  290 Loss sum :  0.37900763750076294 dsm :  0.8882642984390259 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0'), 'node_loss': tensor(0.0022, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3540, device='cuda:0'), 'property_loss': tensor(473.0540, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  300 Loss sum :  0.5958652496337891 dsm :  1.9149010181427002 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0'), 'node_loss': tensor(0.0029, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2353, device='cuda:0'), 'property_loss': tensor(465.5482, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  310 Loss sum :  0.5330870747566223 dsm :  0.04443613439798355 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0'), 'node_loss': tensor(-0.0149, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3086, device='cuda:0'), 'property_loss': tensor(496.6113, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  320 Loss sum :  0.3569497764110565 dsm :  3.3728249073028564 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0'), 'node_loss': tensor(0.0015, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4453, device='cuda:0'), 'property_loss': tensor(536.3420, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  330 Loss sum :  0.5679264664649963 dsm :  5.847250461578369 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3152, device='cuda:0'), 'property_loss': tensor(477.4854, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  340 Loss sum :  0.40982747077941895 dsm :  5.337392330169678 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2955, device='cuda:0'), 'property_loss': tensor(472.7190, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  350 Loss sum :  0.5807527899742126 dsm :  3.777317523956299 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0256, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3213, device='cuda:0'), 'property_loss': tensor(509.2144, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  360 Loss sum :  0.4693712592124939 dsm :  1.9852272272109985 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(-0.0153, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2184, device='cuda:0'), 'property_loss': tensor(472.3838, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  370 Loss sum :  0.33588042855262756 dsm :  0.21571341156959534 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(0.0015, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2741, device='cuda:0'), 'property_loss': tensor(471.5477, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  380 Loss sum :  0.5156655311584473 dsm :  0.8941025137901306 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4224, device='cuda:0'), 'property_loss': tensor(516.3519, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  390 Loss sum :  0.5515506863594055 dsm :  1.101374864578247 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3563, device='cuda:0'), 'property_loss': tensor(491.2591, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  400 Loss sum :  0.5143399238586426 dsm :  0.513015866279602 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3475, device='cuda:0'), 'property_loss': tensor(496.6923, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  410 Loss sum :  0.5540119409561157 dsm :  1.317948818206787 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0280, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2616, device='cuda:0'), 'property_loss': tensor(471.5872, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  420 Loss sum :  0.3292992413043976 dsm :  2.5876433849334717 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0242, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2884, device='cuda:0'), 'property_loss': tensor(493.8913, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  430 Loss sum :  0.4348117709159851 dsm :  0.09690725058317184 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3392, device='cuda:0'), 'property_loss': tensor(496.9183, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  440 Loss sum :  0.5372605919837952 dsm :  2.660480260848999 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3478, device='cuda:0'), 'property_loss': tensor(476.8249, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  450 Loss sum :  0.6058288216590881 dsm :  0.7860164046287537 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0'), 'node_loss': tensor(0.0023, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3371, device='cuda:0'), 'property_loss': tensor(496.6652, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  460 Loss sum :  0.5702007412910461 dsm :  1.7519668340682983 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.2967, device='cuda:0'), 'property_loss': tensor(473.3351, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  470 Loss sum :  0.3890603184700012 dsm :  0.5701196789741516 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2527, device='cuda:0'), 'property_loss': tensor(456.5012, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  480 Loss sum :  0.44687724113464355 dsm :  4.881480693817139 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0263, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2873, device='cuda:0'), 'property_loss': tensor(485.5573, device='cuda:0')}\n",
      "Epoch (val) :  91   batch (val) :  490 Loss sum :  0.467321515083313 dsm :  0.938565194606781 neg entropy :  568.9645385742188\n",
      "Epoch :  92  Batch :  0  Loss :  0.5886193513870239 dsm :  2.9157283306121826 neg entropy :  558.7989501953125\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8677, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.1667, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  10  Loss :  0.5634099245071411 dsm :  1.2326425313949585 neg entropy :  559.6520385742188\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2104, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4037, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.9987, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  20  Loss :  0.4295661747455597 dsm :  0.2891305387020111 neg entropy :  561.8539428710938\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6441, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3343, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.8252, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  30  Loss :  0.6195884943008423 dsm :  0.6279682517051697 neg entropy :  551.0554809570312\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6178, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4389, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.4951, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  40  Loss :  0.5833339095115662 dsm :  1.4229854345321655 neg entropy :  558.1734619140625\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0182, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4056, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.2725, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  50  Loss :  0.49981218576431274 dsm :  0.8144968152046204 neg entropy :  565.0780029296875\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2248, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.2358, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  60  Loss :  0.5396084785461426 dsm :  0.903769314289093 neg entropy :  558.1550903320312\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2498, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3172, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.8159, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  70  Loss :  0.6094039678573608 dsm :  0.21822121739387512 neg entropy :  555.2916870117188\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9642, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3569, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.3477, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  80  Loss :  0.4483742415904999 dsm :  1.3374061584472656 neg entropy :  557.1604614257812\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1378, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3842, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.0060, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  90  Loss :  0.5465047955513 dsm :  0.22532720863819122 neg entropy :  563.2933959960938\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8793, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.9470, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  100  Loss :  0.6105493903160095 dsm :  2.477283477783203 neg entropy :  553.5370483398438\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8335, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0533, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  110  Loss :  0.5788934826850891 dsm :  1.3631110191345215 neg entropy :  559.5880126953125\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2688, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.2776, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  120  Loss :  0.6195411086082458 dsm :  1.6703888177871704 neg entropy :  556.0370483398438\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1451, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.6962, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  130  Loss :  0.6081828474998474 dsm :  2.419071912765503 neg entropy :  553.2005004882812\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7631, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3770, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.9669, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  140  Loss :  0.42261120676994324 dsm :  2.290867567062378 neg entropy :  561.10888671875\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1793, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3488, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2694, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  150  Loss :  0.37575578689575195 dsm :  1.6026279926300049 neg entropy :  553.73388671875\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2424, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3512, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.5052, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  160  Loss :  0.03739888593554497 dsm :  1.0866550207138062 neg entropy :  555.1588745117188\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0486, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7681, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2940, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.8542, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  170  Loss :  0.6274679899215698 dsm :  2.6476845741271973 neg entropy :  559.5213012695312\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8196, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4212, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.4474, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  180  Loss :  0.5476025342941284 dsm :  0.6223548054695129 neg entropy :  557.8225708007812\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1261, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2753, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.2389, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  190  Loss :  0.5247958302497864 dsm :  1.1608551740646362 neg entropy :  563.5107421875\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4687, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.8639, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  200  Loss :  0.6141910552978516 dsm :  0.06081898882985115 neg entropy :  555.4251708984375\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0673, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.8840, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  210  Loss :  0.5730084180831909 dsm :  0.8678633570671082 neg entropy :  558.2601928710938\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0437, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4004, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.9731, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  220  Loss :  0.5783272981643677 dsm :  2.2608344554901123 neg entropy :  562.2653198242188\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6107, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2941, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.6485, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  230  Loss :  0.29582488536834717 dsm :  6.349627494812012 neg entropy :  560.3846435546875\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0310, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8524, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.1292, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  240  Loss :  0.5518582463264465 dsm :  0.5295576453208923 neg entropy :  561.4835205078125\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6664, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3943, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.6839, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  250  Loss :  0.5660935640335083 dsm :  1.223573088645935 neg entropy :  551.8272094726562\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.5520, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.3647, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  260  Loss :  0.5777233839035034 dsm :  0.5979525446891785 neg entropy :  563.7633666992188\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6133, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.5551, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  270  Loss :  0.5811681151390076 dsm :  1.7791274785995483 neg entropy :  556.78173828125\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4828, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8085, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  280  Loss :  0.5616977214813232 dsm :  0.45144349336624146 neg entropy :  562.1544799804688\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8665, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3543, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.2794, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  290  Loss :  0.5913568139076233 dsm :  0.7594072222709656 neg entropy :  557.4226684570312\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7710, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1324, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  300  Loss :  0.6546525955200195 dsm :  0.03681795299053192 neg entropy :  553.0280151367188\n",
      "{'edge_loss': tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1133, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.7734, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  310  Loss :  0.362666517496109 dsm :  1.3232616186141968 neg entropy :  563.1334838867188\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4098, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.9410, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  320  Loss :  0.4239659905433655 dsm :  0.6890936493873596 neg entropy :  563.1721801757812\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4417, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.1379, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  330  Loss :  0.671158492565155 dsm :  1.3980411291122437 neg entropy :  554.6408081054688\n",
      "{'edge_loss': tensor(0.0434, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7779, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1684, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  340  Loss :  0.5446058511734009 dsm :  1.5907397270202637 neg entropy :  558.6796875\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5748, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.4258, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  350  Loss :  0.5174652338027954 dsm :  0.09580736607313156 neg entropy :  560.89404296875\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1027, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4757, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.8453, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  360  Loss :  0.5329610109329224 dsm :  1.6794923543930054 neg entropy :  558.2898559570312\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9117, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2733, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.9111, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  370  Loss :  0.386188268661499 dsm :  1.4520015716552734 neg entropy :  561.0416870117188\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6829, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.7656, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  380  Loss :  0.5961862206459045 dsm :  0.05759827420115471 neg entropy :  554.8873901367188\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4119, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3829, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4808, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  390  Loss :  0.5189643502235413 dsm :  0.6270827651023865 neg entropy :  560.1229858398438\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2220, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.0935, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  400  Loss :  0.5588346123695374 dsm :  0.4962814450263977 neg entropy :  557.7408447265625\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0837, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.4605, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  410  Loss :  0.6046561002731323 dsm :  2.0908937454223633 neg entropy :  560.5821533203125\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6886, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2646, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.0076, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  420  Loss :  0.6541054844856262 dsm :  1.484618067741394 neg entropy :  552.6802978515625\n",
      "{'edge_loss': tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0035, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9626, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.1243, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  430  Loss :  0.5288516879081726 dsm :  0.19070881605148315 neg entropy :  556.5703735351562\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5736, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2908, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.2245, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  440  Loss :  0.60658860206604 dsm :  0.18314580619335175 neg entropy :  564.2023315429688\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7405, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2608, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.9839, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  450  Loss :  0.4728226661682129 dsm :  3.2646164894104004 neg entropy :  559.1339721679688\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5887, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3857, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.2570, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  460  Loss :  0.57249516248703 dsm :  2.6038684844970703 neg entropy :  560.4944458007812\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2128, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2953, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.9101, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  470  Loss :  0.6731817722320557 dsm :  1.1268962621688843 neg entropy :  559.9025268554688\n",
      "{'edge_loss': tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0988, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.7361, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  480  Loss :  0.6422372460365295 dsm :  0.7685827016830444 neg entropy :  551.3322143554688\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1158, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5179, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1703, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  490  Loss :  0.5601698160171509 dsm :  0.38088080286979675 neg entropy :  558.9218139648438\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6852, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3677, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4096, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  500  Loss :  0.6312033534049988 dsm :  0.5159820914268494 neg entropy :  556.5341796875\n",
      "{'edge_loss': tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6903, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.4960, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  510  Loss :  0.6325439810752869 dsm :  3.4037113189697266 neg entropy :  558.0787963867188\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4311, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.6930, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  520  Loss :  0.5224907994270325 dsm :  0.13304561376571655 neg entropy :  560.2821655273438\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4638, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3019, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9900, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  530  Loss :  0.6063319444656372 dsm :  1.8439823389053345 neg entropy :  560.5704956054688\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7615, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.3304, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  540  Loss :  0.6569029092788696 dsm :  3.89957594871521 neg entropy :  559.046630859375\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9419, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.5928, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  550  Loss :  0.3844718933105469 dsm :  0.6576075553894043 neg entropy :  566.7495727539062\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6427, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.7402, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  560  Loss :  0.4598391354084015 dsm :  0.7921395301818848 neg entropy :  551.1482543945312\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6324, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4990, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.9958, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  570  Loss :  0.05887973681092262 dsm :  1.120718240737915 neg entropy :  555.569091796875\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0477, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9484, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4015, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.1490, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  580  Loss :  0.5700292587280273 dsm :  0.5662777423858643 neg entropy :  557.0082397460938\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7353, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3904, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.0973, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  590  Loss :  0.5822571516036987 dsm :  1.0185035467147827 neg entropy :  563.0772094726562\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1522, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.7711, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  600  Loss :  0.5487014055252075 dsm :  1.0710113048553467 neg entropy :  560.9512329101562\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4174, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4136, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.6377, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  610  Loss :  0.5740612149238586 dsm :  1.4836012125015259 neg entropy :  565.07373046875\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.9786, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.3275, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  620  Loss :  0.6118988990783691 dsm :  0.29562219977378845 neg entropy :  560.0538940429688\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2240, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2336, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(446.4116, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  630  Loss :  0.21833765506744385 dsm :  0.7738428115844727 neg entropy :  562.2255249023438\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0302, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5248, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4227, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(538.2130, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  640  Loss :  0.5903540849685669 dsm :  1.8543627262115479 neg entropy :  560.7849731445312\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7922, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3821, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.8139, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  650  Loss :  0.6174749135971069 dsm :  4.545765399932861 neg entropy :  557.7138671875\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6317, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3838, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.6441, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  660  Loss :  0.5691431164741516 dsm :  1.3121519088745117 neg entropy :  560.4583129882812\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0970, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.5821, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  670  Loss :  0.42852747440338135 dsm :  1.0811713933944702 neg entropy :  559.0936889648438\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3937, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3523, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.9779, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  680  Loss :  0.4102495014667511 dsm :  0.22104787826538086 neg entropy :  554.3828735351562\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2487, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.7580, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  690  Loss :  0.4237695038318634 dsm :  2.0745036602020264 neg entropy :  555.6503295898438\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6354, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.7975, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  700  Loss :  0.6518919467926025 dsm :  0.24893108010292053 neg entropy :  554.8141479492188\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2769, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3951, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1599, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  710  Loss :  0.439383327960968 dsm :  1.0984073877334595 neg entropy :  555.4627075195312\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0137, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1302, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9776, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  720  Loss :  0.5675157904624939 dsm :  2.185119390487671 neg entropy :  559.6165161132812\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0056, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3491, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.4964, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  730  Loss :  0.5927006602287292 dsm :  0.1069638729095459 neg entropy :  562.2545776367188\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0041, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2950, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3745, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.3387, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  740  Loss :  0.6448480486869812 dsm :  1.6672710180282593 neg entropy :  556.52490234375\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4446, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4188, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.7370, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  750  Loss :  0.5930604934692383 dsm :  1.4053728580474854 neg entropy :  559.0652465820312\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0381, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3139, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.8934, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  760  Loss :  0.5332200527191162 dsm :  2.188436508178711 neg entropy :  560.912109375\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1610, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5383, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  770  Loss :  0.5745242238044739 dsm :  0.4502764642238617 neg entropy :  563.9069213867188\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9547, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.7424, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  780  Loss :  0.5857141017913818 dsm :  0.8487430810928345 neg entropy :  559.8932495117188\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9066, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2844, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.7867, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  790  Loss :  0.12048614025115967 dsm :  4.885939598083496 neg entropy :  552.9981689453125\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0474, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3257, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.5887, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  800  Loss :  0.6062701344490051 dsm :  0.8351158499717712 neg entropy :  555.7954711914062\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8217, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.0345, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  810  Loss :  0.5757232308387756 dsm :  2.5991311073303223 neg entropy :  557.3588256835938\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4473, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.5977, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  820  Loss :  0.4995286464691162 dsm :  0.2650843560695648 neg entropy :  562.0847778320312\n",
      "{'edge_loss': tensor(0.0279, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1782, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4283, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(535.5244, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  830  Loss :  0.676504909992218 dsm :  1.468973994255066 neg entropy :  552.5769653320312\n",
      "{'edge_loss': tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2713, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3966, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.2302, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  840  Loss :  0.5187861919403076 dsm :  1.5267419815063477 neg entropy :  560.3829345703125\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2298, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.3353, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  850  Loss :  0.5728706121444702 dsm :  4.082031726837158 neg entropy :  560.33349609375\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8553, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.1651, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  860  Loss :  0.5851576328277588 dsm :  0.9250392913818359 neg entropy :  560.5574340820312\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0897, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.4717, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  870  Loss :  0.5330849289894104 dsm :  0.9935352206230164 neg entropy :  559.7606811523438\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9664, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4153, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.1890, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  880  Loss :  0.6196668148040771 dsm :  0.04681318998336792 neg entropy :  551.94921875\n",
      "{'edge_loss': tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7418, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.7278, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  890  Loss :  0.5985714197158813 dsm :  0.1442800611257553 neg entropy :  558.4011840820312\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0820, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3610, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.6790, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  900  Loss :  0.5487983226776123 dsm :  0.16859671473503113 neg entropy :  562.7242431640625\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1393, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2871, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.7887, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  910  Loss :  0.6231783628463745 dsm :  0.09851622581481934 neg entropy :  552.7106323242188\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2070, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4003, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9845, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  920  Loss :  0.4595826268196106 dsm :  0.5586210489273071 neg entropy :  554.3251342773438\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0136, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.7771, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  930  Loss :  0.5525648593902588 dsm :  1.3063733577728271 neg entropy :  554.3948974609375\n",
      "{'edge_loss': tensor(0.0487, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3709, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4589, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.7396, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  940  Loss :  0.5346959233283997 dsm :  0.733299195766449 neg entropy :  562.58154296875\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7375, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3010, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0438, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  950  Loss :  0.4376966059207916 dsm :  0.7392122149467468 neg entropy :  558.8463745117188\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0125, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0488, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3427, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.1532, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  960  Loss :  0.5645167231559753 dsm :  0.016879431903362274 neg entropy :  559.2506713867188\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4816, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3809, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.4273, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  970  Loss :  0.667325496673584 dsm :  2.0074667930603027 neg entropy :  557.8129272460938\n",
      "{'edge_loss': tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8722, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3826, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.2486, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  980  Loss :  0.6313932538032532 dsm :  4.444971561431885 neg entropy :  558.5836791992188\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1335, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3729, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.4429, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  990  Loss :  0.35415929555892944 dsm :  0.8719578981399536 neg entropy :  559.1444702148438\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4267, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.7241, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1000  Loss :  0.5667753219604492 dsm :  5.337691307067871 neg entropy :  564.2203979492188\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9264, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3528, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.1472, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1010  Loss :  0.5356776714324951 dsm :  0.8005215525627136 neg entropy :  562.2809448242188\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8997, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2662, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.5593, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1020  Loss :  0.26283568143844604 dsm :  3.6375019550323486 neg entropy :  557.45361328125\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0317, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1211, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3635, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.3180, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1030  Loss :  0.5539042353630066 dsm :  1.60723876953125 neg entropy :  558.4832153320312\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2999, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3132, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.5497, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1040  Loss :  0.6013777852058411 dsm :  2.3505711555480957 neg entropy :  560.154541015625\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2194, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4247, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.1302, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1050  Loss :  0.5452650785446167 dsm :  0.8655737042427063 neg entropy :  559.1012573242188\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5388, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.3723, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1060  Loss :  0.5485401749610901 dsm :  0.5702291131019592 neg entropy :  559.0814819335938\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2035, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3648, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.4853, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1070  Loss :  0.6818399429321289 dsm :  0.9458697438240051 neg entropy :  554.2223510742188\n",
      "{'edge_loss': tensor(0.0448, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.0283, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1080  Loss :  0.534959614276886 dsm :  1.6962894201278687 neg entropy :  560.6762084960938\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9589, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5062, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1090  Loss :  0.518543004989624 dsm :  0.05250100418925285 neg entropy :  562.3832397460938\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6479, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2672, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.9750, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1100  Loss :  0.5406948328018188 dsm :  0.3180710971355438 neg entropy :  560.9293823242188\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7218, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4180, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.7762, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1110  Loss :  0.6042899489402771 dsm :  1.4621206521987915 neg entropy :  556.7096557617188\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5362, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4008, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1147, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1120  Loss :  0.5632575154304504 dsm :  1.2953884601593018 neg entropy :  558.5245361328125\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2435, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2669, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(446.8281, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1130  Loss :  0.5981996655464172 dsm :  3.8490045070648193 neg entropy :  561.8938598632812\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6331, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3743, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.6361, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1140  Loss :  0.554970383644104 dsm :  0.05775652080774307 neg entropy :  558.9806518554688\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6136, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.6900, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1150  Loss :  0.42786282300949097 dsm :  3.3648064136505127 neg entropy :  557.8001098632812\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4681, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2974, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.4721, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1160  Loss :  0.36199989914894104 dsm :  1.130355715751648 neg entropy :  569.05419921875\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.9704, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.3276, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1170  Loss :  0.4022737145423889 dsm :  0.6779581904411316 neg entropy :  566.2838745117188\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3479, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3717, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9665, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1180  Loss :  0.6625574827194214 dsm :  3.4308948516845703 neg entropy :  552.8445434570312\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2839, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.6602, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1190  Loss :  0.6189259886741638 dsm :  0.1594201773405075 neg entropy :  552.4620361328125\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8225, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4825, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.4959, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1200  Loss :  0.5357814431190491 dsm :  2.0546014308929443 neg entropy :  562.1369018554688\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5070, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1459, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1210  Loss :  0.5693512558937073 dsm :  0.16062511503696442 neg entropy :  553.7579956054688\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0004, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4784, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.5570, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1220  Loss :  0.577724039554596 dsm :  2.6481387615203857 neg entropy :  556.8953857421875\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1416, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.9807, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1230  Loss :  0.5655677914619446 dsm :  0.7993678450584412 neg entropy :  554.0423583984375\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1580, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4293, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.2383, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1240  Loss :  0.604637086391449 dsm :  2.5012366771698 neg entropy :  555.6464233398438\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3685, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2720, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.3198, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1250  Loss :  0.578740656375885 dsm :  2.9104270935058594 neg entropy :  556.7378540039062\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3586, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.6574, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1260  Loss :  0.6662484407424927 dsm :  5.814141273498535 neg entropy :  558.92236328125\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3459, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3519, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.5280, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1270  Loss :  0.6116737723350525 dsm :  1.7673618793487549 neg entropy :  559.147705078125\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3631, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.1585, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1280  Loss :  0.6027897596359253 dsm :  0.7846113443374634 neg entropy :  558.2147216796875\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2489, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3728, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.3249, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1290  Loss :  0.5696311593055725 dsm :  0.8963373303413391 neg entropy :  557.4263916015625\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5400, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3582, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.6667, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1300  Loss :  0.5154803395271301 dsm :  1.031140685081482 neg entropy :  566.3170776367188\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.0472, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.0479, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1310  Loss :  0.5649510622024536 dsm :  2.22371768951416 neg entropy :  560.7136840820312\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7971, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4625, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.0527, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1320  Loss :  0.5970208644866943 dsm :  0.38650989532470703 neg entropy :  562.8707885742188\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1602, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.2125, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1330  Loss :  0.6167036294937134 dsm :  2.161165475845337 neg entropy :  556.2218627929688\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7018, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3631, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.7951, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1340  Loss :  0.5587557554244995 dsm :  2.3760135173797607 neg entropy :  560.746337890625\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8925, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3913, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.8279, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1350  Loss :  0.6060439348220825 dsm :  0.7830401062965393 neg entropy :  556.1707153320312\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5220, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.2061, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1360  Loss :  0.3512139916419983 dsm :  1.2256466150283813 neg entropy :  559.3804931640625\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0236, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2456, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.4193, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1370  Loss :  0.6525434255599976 dsm :  3.052258014678955 neg entropy :  557.3259887695312\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0041, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2533, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4743, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.4213, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1380  Loss :  0.6029072999954224 dsm :  2.5147197246551514 neg entropy :  558.0116577148438\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7144, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4431, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.0994, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1390  Loss :  0.3711627125740051 dsm :  0.47622963786125183 neg entropy :  559.7396240234375\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7008, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.2388, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1400  Loss :  0.6205835342407227 dsm :  0.41467857360839844 neg entropy :  557.3132934570312\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4877, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4054, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.7411, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1410  Loss :  0.5586023926734924 dsm :  1.5542200803756714 neg entropy :  560.161865234375\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1973, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3603, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.4651, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1420  Loss :  0.5902270674705505 dsm :  0.28130659461021423 neg entropy :  556.4111328125\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3874, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4921, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.3459, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1430  Loss :  0.5985845327377319 dsm :  0.20469029247760773 neg entropy :  565.101318359375\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.9959, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1440  Loss :  0.5816218852996826 dsm :  0.9426105618476868 neg entropy :  562.3521118164062\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4552, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.8877, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1450  Loss :  0.5766634345054626 dsm :  1.5040067434310913 neg entropy :  552.2628784179688\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.1671, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1460  Loss :  0.3969978392124176 dsm :  0.5765698552131653 neg entropy :  558.6207885742188\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4208, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.5648, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1470  Loss :  0.5497326850891113 dsm :  0.8878528475761414 neg entropy :  558.82373046875\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2277, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.5710, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1480  Loss :  0.6036962866783142 dsm :  2.4220800399780273 neg entropy :  558.5311889648438\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7914, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4483, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.9097, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1490  Loss :  0.541604220867157 dsm :  0.38189005851745605 neg entropy :  557.7988891601562\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6020, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3824, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.0969, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1500  Loss :  0.5701420307159424 dsm :  1.354267954826355 neg entropy :  569.9284057617188\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(247.6529, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2505, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.9498, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1510  Loss :  0.5801481008529663 dsm :  0.4729120433330536 neg entropy :  555.2338256835938\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9011, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4815, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.6040, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1520  Loss :  0.22117385268211365 dsm :  3.7933266162872314 neg entropy :  564.8305053710938\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6915, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.4892, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1530  Loss :  0.5892450213432312 dsm :  2.0023319721221924 neg entropy :  558.8009643554688\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6422, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8357, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1540  Loss :  0.6301349997520447 dsm :  0.18198858201503754 neg entropy :  549.56494140625\n",
      "{'edge_loss': tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.7185, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4300, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5510, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1550  Loss :  0.6733896136283875 dsm :  3.053321599960327 neg entropy :  553.7968139648438\n",
      "{'edge_loss': tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6328, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4159, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.7334, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1560  Loss :  0.5746448636054993 dsm :  0.03523581102490425 neg entropy :  556.5153198242188\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8726, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.7540, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1570  Loss :  0.4685124158859253 dsm :  0.49299994111061096 neg entropy :  558.9411010742188\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7467, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.0058, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1580  Loss :  0.6376158595085144 dsm :  1.9641002416610718 neg entropy :  560.5138549804688\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3313, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3008, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.2410, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1590  Loss :  0.2973693907260895 dsm :  1.5495508909225464 neg entropy :  554.0912475585938\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5551, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4381, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.3662, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1600  Loss :  0.5961189866065979 dsm :  3.6601948738098145 neg entropy :  559.359375\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7194, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.3643, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1610  Loss :  0.6616272330284119 dsm :  3.0763099193573 neg entropy :  550.6769409179688\n",
      "{'edge_loss': tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3619, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4005, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.3913, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1620  Loss :  0.43433520197868347 dsm :  2.603288412094116 neg entropy :  558.8610229492188\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2465, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3422, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.3704, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1630  Loss :  0.5347628593444824 dsm :  0.14703260362148285 neg entropy :  564.270751953125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1207, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3215, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.7432, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1640  Loss :  0.38641130924224854 dsm :  0.10640197992324829 neg entropy :  563.3453369140625\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7943, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.0388, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1650  Loss :  0.5402305722236633 dsm :  2.7857449054718018 neg entropy :  561.3422241210938\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2949, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2994, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.6424, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1660  Loss :  0.5742371082305908 dsm :  1.9708385467529297 neg entropy :  558.2423095703125\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3010, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2872, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.2396, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1670  Loss :  0.5577546954154968 dsm :  1.9820460081100464 neg entropy :  556.2791137695312\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0967, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4109, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.6181, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1680  Loss :  0.6126562356948853 dsm :  0.07905463874340057 neg entropy :  563.5248413085938\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7710, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3281, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.4212, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1690  Loss :  0.5836570262908936 dsm :  1.0310224294662476 neg entropy :  562.7747192382812\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8123, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.0320, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1700  Loss :  0.516769289970398 dsm :  0.21911707520484924 neg entropy :  559.0376586914062\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4655, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4138, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.8690, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1710  Loss :  0.5653979182243347 dsm :  5.322940349578857 neg entropy :  558.6181640625\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9574, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.3952, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1720  Loss :  0.34521424770355225 dsm :  0.5979413390159607 neg entropy :  564.4843139648438\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9533, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3293, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.8704, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1730  Loss :  0.5573441386222839 dsm :  2.73005747795105 neg entropy :  562.0973510742188\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4270, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2983, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.1529, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1740  Loss :  0.46010708808898926 dsm :  3.117777109146118 neg entropy :  557.7133178710938\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1316, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.3318, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1750  Loss :  0.4011074900627136 dsm :  0.3616991937160492 neg entropy :  560.660888671875\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7518, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3819, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9082, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1760  Loss :  0.5851054787635803 dsm :  3.7850289344787598 neg entropy :  559.8798828125\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1178, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3398, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.4878, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1770  Loss :  0.6810654997825623 dsm :  0.8598839044570923 neg entropy :  556.0029296875\n",
      "{'edge_loss': tensor(0.0463, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4655, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.0703, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1780  Loss :  0.5118040442466736 dsm :  0.026338184252381325 neg entropy :  564.1522827148438\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5693, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.6072, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1790  Loss :  0.4271325469017029 dsm :  0.5218969583511353 neg entropy :  559.0064086914062\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3966, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3857, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5385, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1800  Loss :  0.5579918026924133 dsm :  3.484760046005249 neg entropy :  555.9090576171875\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3859, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.5553, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1810  Loss :  0.5792004466056824 dsm :  3.7590386867523193 neg entropy :  567.8536987304688\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.3316, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.5347, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1820  Loss :  0.5965301990509033 dsm :  0.12224246561527252 neg entropy :  556.2474975585938\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3889, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2688, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.4175, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1830  Loss :  0.38145697116851807 dsm :  1.3354856967926025 neg entropy :  562.1146850585938\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0137, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1095, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.4122, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1840  Loss :  0.43648388981819153 dsm :  2.83392333984375 neg entropy :  556.7169799804688\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0138, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3441, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3590, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.4507, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1850  Loss :  0.37526756525039673 dsm :  0.274649977684021 neg entropy :  556.156494140625\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8819, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.6019, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1860  Loss :  0.3785095810890198 dsm :  2.0522775650024414 neg entropy :  551.23583984375\n",
      "{'edge_loss': tensor(0.0469, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0314, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9270, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4843, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.1789, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1870  Loss :  0.5658416152000427 dsm :  0.6194269061088562 neg entropy :  547.4389038085938\n",
      "{'edge_loss': tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0142, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.6942, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4740, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.2969, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1880  Loss :  0.6390231251716614 dsm :  6.212253093719482 neg entropy :  559.30908203125\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9601, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.4545, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1890  Loss :  0.5712317228317261 dsm :  0.0828826054930687 neg entropy :  556.9249877929688\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4591, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4365, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.8313, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1900  Loss :  0.6156360507011414 dsm :  0.6121196746826172 neg entropy :  559.7984619140625\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6811, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4092, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.2633, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1910  Loss :  0.5677345991134644 dsm :  1.2320044040679932 neg entropy :  561.1033325195312\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.7858, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3455, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.2081, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1920  Loss :  0.34355369210243225 dsm :  1.9648760557174683 neg entropy :  563.8629760742188\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0893, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.6353, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1930  Loss :  0.5879321694374084 dsm :  0.30880001187324524 neg entropy :  556.723388671875\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0715, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4785, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.9115, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1940  Loss :  0.6614910960197449 dsm :  0.5551362037658691 neg entropy :  554.88623046875\n",
      "{'edge_loss': tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6857, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4793, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.8666, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1950  Loss :  0.6331632137298584 dsm :  0.7074043154716492 neg entropy :  554.2260131835938\n",
      "{'edge_loss': tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4910, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.5932, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1960  Loss :  0.4880461096763611 dsm :  0.08694946020841599 neg entropy :  562.7299194335938\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0002, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5415, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3190, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.6726, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1970  Loss :  0.5732764005661011 dsm :  0.33565351366996765 neg entropy :  557.94287109375\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6888, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4003, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.6062, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1980  Loss :  0.5631115436553955 dsm :  1.3922268152236938 neg entropy :  556.3826293945312\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7189, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3170, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3036, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  1990  Loss :  0.6220256686210632 dsm :  3.3912065029144287 neg entropy :  556.8741455078125\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1004, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.5264, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2000  Loss :  0.6338955163955688 dsm :  7.353936672210693 neg entropy :  560.17724609375\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8616, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4265, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.3604, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2010  Loss :  0.4146532416343689 dsm :  1.2406593561172485 neg entropy :  558.7972412109375\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7726, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3537, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.9205, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2020  Loss :  0.5336214303970337 dsm :  0.34053316712379456 neg entropy :  557.2595825195312\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7224, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.0389, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2030  Loss :  0.537264883518219 dsm :  0.36991003155708313 neg entropy :  561.03759765625\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3748, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0002, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2040  Loss :  0.5666117668151855 dsm :  1.6256859302520752 neg entropy :  554.3464965820312\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5719, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4480, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.7292, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2050  Loss :  0.5541661381721497 dsm :  0.49922165274620056 neg entropy :  555.4559936523438\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4351, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4111, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(527.6190, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2060  Loss :  0.7405104041099548 dsm :  5.974925518035889 neg entropy :  554.7802124023438\n",
      "{'edge_loss': tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3963, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4020, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.4045, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2070  Loss :  0.7005531787872314 dsm :  2.741190195083618 neg entropy :  562.4402465820312\n",
      "{'edge_loss': tensor(0.0465, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0818, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3327, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.4350, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2080  Loss :  0.5913470983505249 dsm :  2.5446970462799072 neg entropy :  561.7492065429688\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2308, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4178, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.6302, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2090  Loss :  0.6411172151565552 dsm :  1.8893377780914307 neg entropy :  554.7449340820312\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0542, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3369, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.6538, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2100  Loss :  0.5104437470436096 dsm :  1.1021865606307983 neg entropy :  561.9693603515625\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9813, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.6697, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2110  Loss :  0.7050808072090149 dsm :  1.3580924272537231 neg entropy :  555.7650756835938\n",
      "{'edge_loss': tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1480, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.3384, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2120  Loss :  0.5721398591995239 dsm :  0.14208388328552246 neg entropy :  562.2174072265625\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4767, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3401, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5586, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2130  Loss :  0.6488790512084961 dsm :  0.3211027979850769 neg entropy :  560.3239135742188\n",
      "{'edge_loss': tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9948, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3915, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.4725, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2140  Loss :  0.5522037744522095 dsm :  1.4605172872543335 neg entropy :  560.351318359375\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4793, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3972, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.8560, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2150  Loss :  0.6450359225273132 dsm :  1.3360217809677124 neg entropy :  558.6016845703125\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4718, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4475, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.3732, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2160  Loss :  0.5133975744247437 dsm :  0.7535132765769958 neg entropy :  564.0599365234375\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8757, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2649, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.0133, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2170  Loss :  0.6696020364761353 dsm :  0.9143360257148743 neg entropy :  550.9816284179688\n",
      "{'edge_loss': tensor(0.0459, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.4535, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3259, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.7564, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2180  Loss :  0.5354282855987549 dsm :  0.49804621934890747 neg entropy :  561.5856323242188\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6089, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4365, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.8604, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2190  Loss :  0.5232143402099609 dsm :  2.2487332820892334 neg entropy :  560.6135864257812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1032, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1599, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.6540, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2200  Loss :  0.5832598209381104 dsm :  1.4844506978988647 neg entropy :  555.86669921875\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1839, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3090, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.3956, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2210  Loss :  0.5373172163963318 dsm :  0.12257426977157593 neg entropy :  564.2232055664062\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6194, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4239, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.2562, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2220  Loss :  0.40502074360847473 dsm :  2.310642957687378 neg entropy :  551.1559448242188\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.2099, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3213, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.8055, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2230  Loss :  0.5721517205238342 dsm :  0.6226955652236938 neg entropy :  560.4176025390625\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3253, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3329, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.6993, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2240  Loss :  0.6359843611717224 dsm :  1.6693271398544312 neg entropy :  556.0050659179688\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9039, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4044, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.9392, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2250  Loss :  0.6404656171798706 dsm :  4.9063897132873535 neg entropy :  564.9279174804688\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8811, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2589, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.1853, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2260  Loss :  0.6455192565917969 dsm :  3.046804666519165 neg entropy :  559.6764526367188\n",
      "{'edge_loss': tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3143, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2161, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(443.8923, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2270  Loss :  0.6421716213226318 dsm :  1.173803687095642 neg entropy :  554.6510620117188\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0035, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7041, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3267, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.3174, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2280  Loss :  0.473556786775589 dsm :  5.447183132171631 neg entropy :  560.6306762695312\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8531, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4467, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.9878, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2290  Loss :  0.5550917387008667 dsm :  1.09727942943573 neg entropy :  561.0507202148438\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9888, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3073, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.7498, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2300  Loss :  0.5978494882583618 dsm :  0.9687180519104004 neg entropy :  565.5272827148438\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0231, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4371, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(538.4826, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2310  Loss :  0.44333598017692566 dsm :  0.27829742431640625 neg entropy :  564.2015991210938\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4645, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9655, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2320  Loss :  0.5393238663673401 dsm :  0.8675058484077454 neg entropy :  553.4320678710938\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0147, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3780, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.1741, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2330  Loss :  0.6129173040390015 dsm :  1.5844179391860962 neg entropy :  552.9678955078125\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7890, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3634, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0214, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2340  Loss :  0.578140139579773 dsm :  1.1596049070358276 neg entropy :  556.7902221679688\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3689, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4069, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1367, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2350  Loss :  0.393150269985199 dsm :  0.730248749256134 neg entropy :  553.5942993164062\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7557, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2244, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(441.2940, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2360  Loss :  0.5474909543991089 dsm :  1.4034197330474854 neg entropy :  558.80078125\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5778, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2810, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.1145, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2370  Loss :  0.5124388337135315 dsm :  0.5683860182762146 neg entropy :  560.8185424804688\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4719, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3293, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9474, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2380  Loss :  0.5600334405899048 dsm :  1.369000792503357 neg entropy :  564.8615112304688\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9316, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4039, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.9953, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2390  Loss :  0.5788000226020813 dsm :  1.3204271793365479 neg entropy :  560.3192749023438\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4455, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4071, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.9881, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2400  Loss :  0.6247633695602417 dsm :  3.9105241298675537 neg entropy :  562.7903442382812\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4033, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3464, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.8892, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2410  Loss :  0.5658433437347412 dsm :  1.8161020278930664 neg entropy :  552.2369995117188\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.0121, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.7137, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2420  Loss :  0.5731297135353088 dsm :  0.4786723256111145 neg entropy :  558.0204467773438\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3903, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4011, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.3424, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2430  Loss :  0.5113351345062256 dsm :  2.258998155593872 neg entropy :  561.5416259765625\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1504, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2225, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(450.1061, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2440  Loss :  0.6277540326118469 dsm :  1.9968986511230469 neg entropy :  556.02783203125\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0284, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3921, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.1531, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2450  Loss :  0.6128498315811157 dsm :  2.002962589263916 neg entropy :  559.3985595703125\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2572, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.1829, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2460  Loss :  0.4246828854084015 dsm :  1.3231897354125977 neg entropy :  559.4686889648438\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1786, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3610, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.3875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2470  Loss :  0.5849981307983398 dsm :  2.286301374435425 neg entropy :  560.1162109375\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7320, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3535, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.7342, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2480  Loss :  0.5827353000640869 dsm :  3.6708314418792725 neg entropy :  557.9820556640625\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2192, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3852, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2248, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  92  Batch :  2490  Loss :  0.33537670969963074 dsm :  0.45141124725341797 neg entropy :  562.1119384765625\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0680, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.0226, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3205, device='cuda:0'), 'property_loss': tensor(488.5105, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  0 Loss sum :  0.5055922269821167 dsm :  0.7744178175926208 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0255, device='cuda:0'), 'node_loss': tensor(-0.0155, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3633, device='cuda:0'), 'property_loss': tensor(512.7604, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  10 Loss sum :  0.3135777711868286 dsm :  2.0113658905029297 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0251, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2734, device='cuda:0'), 'property_loss': tensor(496.7989, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  20 Loss sum :  0.4783731997013092 dsm :  3.711399793624878 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2594, device='cuda:0'), 'property_loss': tensor(480.6375, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  30 Loss sum :  0.5510159134864807 dsm :  5.427492141723633 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3873, device='cuda:0'), 'property_loss': tensor(504.3207, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  40 Loss sum :  0.522974967956543 dsm :  1.2971620559692383 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3038, device='cuda:0'), 'property_loss': tensor(469.3163, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  50 Loss sum :  0.4962601959705353 dsm :  0.9124774932861328 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5078, device='cuda:0'), 'property_loss': tensor(527.5599, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  60 Loss sum :  0.6173869371414185 dsm :  0.4284217953681946 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(0.0011, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2490, device='cuda:0'), 'property_loss': tensor(458.2919, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  70 Loss sum :  0.5006206035614014 dsm :  0.0780157819390297 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4517, device='cuda:0'), 'property_loss': tensor(529.2740, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  80 Loss sum :  0.5662665963172913 dsm :  1.4701807498931885 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0'), 'node_loss': tensor(0.0018, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3441, device='cuda:0'), 'property_loss': tensor(488.9149, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  90 Loss sum :  0.5559660196304321 dsm :  0.48384544253349304 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4185, device='cuda:0'), 'property_loss': tensor(526.3438, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  100 Loss sum :  0.5297693610191345 dsm :  1.6688851118087769 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3929, device='cuda:0'), 'property_loss': tensor(520.5781, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  110 Loss sum :  0.5163450837135315 dsm :  0.6589769721031189 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.2998, device='cuda:0'), 'property_loss': tensor(484.1928, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  120 Loss sum :  0.5326550006866455 dsm :  4.222341537475586 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3426, device='cuda:0'), 'property_loss': tensor(488.7394, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  130 Loss sum :  0.5214284062385559 dsm :  1.64739990234375 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(-0.0154, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2628, device='cuda:0'), 'property_loss': tensor(469.6552, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  140 Loss sum :  0.36010274291038513 dsm :  2.987285614013672 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0'), 'node_loss': tensor(-0.0486, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4797, device='cuda:0'), 'property_loss': tensor(515.4693, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  150 Loss sum :  0.08028360456228256 dsm :  0.17906229197978973 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2815, device='cuda:0'), 'property_loss': tensor(481.2188, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  160 Loss sum :  0.3937011957168579 dsm :  6.4577317237854 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(-0.0143, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2518, device='cuda:0'), 'property_loss': tensor(447.1295, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  170 Loss sum :  0.39263439178466797 dsm :  1.1407077312469482 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0253, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3061, device='cuda:0'), 'property_loss': tensor(495.0600, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  180 Loss sum :  0.48628348112106323 dsm :  4.0728044509887695 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0283, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3104, device='cuda:0'), 'property_loss': tensor(504.2225, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  190 Loss sum :  0.5027711987495422 dsm :  2.2600607872009277 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2804, device='cuda:0'), 'property_loss': tensor(467.7499, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  200 Loss sum :  0.533311665058136 dsm :  0.0885898768901825 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3808, device='cuda:0'), 'property_loss': tensor(505.6620, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  210 Loss sum :  0.5365087389945984 dsm :  0.07745537161827087 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3293, device='cuda:0'), 'property_loss': tensor(490.8227, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  220 Loss sum :  0.4886622428894043 dsm :  0.481764554977417 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3763, device='cuda:0'), 'property_loss': tensor(506.2120, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  230 Loss sum :  0.36773252487182617 dsm :  2.237964391708374 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4231, device='cuda:0'), 'property_loss': tensor(519.0263, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  240 Loss sum :  0.37063780426979065 dsm :  0.7178487777709961 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2401, device='cuda:0'), 'property_loss': tensor(464.5755, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  250 Loss sum :  0.4829977750778198 dsm :  0.64378422498703 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0247, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3900, device='cuda:0'), 'property_loss': tensor(527.7988, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  260 Loss sum :  0.44767165184020996 dsm :  0.06159024313092232 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0'), 'node_loss': tensor(0.0022, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3503, device='cuda:0'), 'property_loss': tensor(495.5100, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  270 Loss sum :  0.5765025615692139 dsm :  3.7254929542541504 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0279, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4372, device='cuda:0'), 'property_loss': tensor(532.1938, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  280 Loss sum :  0.5289778709411621 dsm :  3.8772075176239014 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0'), 'node_loss': tensor(-0.0155, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4080, device='cuda:0'), 'property_loss': tensor(495.7852, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  290 Loss sum :  0.39778387546539307 dsm :  1.5209163427352905 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0'), 'node_loss': tensor(0.0034, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3547, device='cuda:0'), 'property_loss': tensor(472.1548, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  300 Loss sum :  0.6242216229438782 dsm :  1.4159131050109863 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(0.0028, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2334, device='cuda:0'), 'property_loss': tensor(464.5508, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  310 Loss sum :  0.5458323955535889 dsm :  0.9980878829956055 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0286, device='cuda:0'), 'node_loss': tensor(-0.0140, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3104, device='cuda:0'), 'property_loss': tensor(496.3832, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  320 Loss sum :  0.34162890911102295 dsm :  0.7269583344459534 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4433, device='cuda:0'), 'property_loss': tensor(536.2910, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  330 Loss sum :  0.5369270443916321 dsm :  2.4951653480529785 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3245, device='cuda:0'), 'property_loss': tensor(477.0878, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  340 Loss sum :  0.38080108165740967 dsm :  1.516478180885315 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2972, device='cuda:0'), 'property_loss': tensor(474.5975, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  350 Loss sum :  0.548220694065094 dsm :  0.5800232291221619 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0253, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3174, device='cuda:0'), 'property_loss': tensor(504.2276, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  360 Loss sum :  0.45273828506469727 dsm :  0.6916581988334656 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2204, device='cuda:0'), 'property_loss': tensor(467.7739, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  370 Loss sum :  0.35477182269096375 dsm :  1.57160222530365 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2806, device='cuda:0'), 'property_loss': tensor(470.7346, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  380 Loss sum :  0.5061676502227783 dsm :  0.25718414783477783 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4164, device='cuda:0'), 'property_loss': tensor(516.2515, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  390 Loss sum :  0.565628707408905 dsm :  2.212888717651367 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3543, device='cuda:0'), 'property_loss': tensor(490.4493, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  400 Loss sum :  0.5249717235565186 dsm :  0.9468511939048767 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3443, device='cuda:0'), 'property_loss': tensor(497.5271, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  410 Loss sum :  0.5508443117141724 dsm :  0.539993941783905 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0276, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2671, device='cuda:0'), 'property_loss': tensor(469.3836, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  420 Loss sum :  0.32975995540618896 dsm :  3.0724284648895264 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0243, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2913, device='cuda:0'), 'property_loss': tensor(492.0256, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  430 Loss sum :  0.43533146381378174 dsm :  0.13030961155891418 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3377, device='cuda:0'), 'property_loss': tensor(499.0844, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  440 Loss sum :  0.520212709903717 dsm :  0.7118291258811951 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3492, device='cuda:0'), 'property_loss': tensor(474.4590, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  450 Loss sum :  0.596697986125946 dsm :  1.198384165763855 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0'), 'node_loss': tensor(0.0018, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3384, device='cuda:0'), 'property_loss': tensor(495.9953, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  460 Loss sum :  0.56504225730896 dsm :  1.2790731191635132 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.3030, device='cuda:0'), 'property_loss': tensor(474.6564, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  470 Loss sum :  0.4058440327644348 dsm :  3.756713628768921 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2520, device='cuda:0'), 'property_loss': tensor(455.7657, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  480 Loss sum :  0.4522668123245239 dsm :  4.267480850219727 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0263, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2862, device='cuda:0'), 'property_loss': tensor(481.6478, device='cuda:0')}\n",
      "Epoch (val) :  92   batch (val) :  490 Loss sum :  0.4787512719631195 dsm :  2.4712181091308594 neg entropy :  568.9645385742188\n",
      "Epoch :  93  Batch :  0  Loss :  0.5074691772460938 dsm :  1.3112577199935913 neg entropy :  559.0773315429688\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6196, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3583, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.2607, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  10  Loss :  0.6057118773460388 dsm :  2.587843179702759 neg entropy :  564.0548095703125\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3955, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3607, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4214, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  20  Loss :  0.48388436436653137 dsm :  0.4262793958187103 neg entropy :  565.0208740234375\n",
      "{'edge_loss': tensor(0.0280, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8166, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2112, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.7771, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  30  Loss :  0.5330172181129456 dsm :  7.549778938293457 neg entropy :  560.3908081054688\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0132, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2839, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2876, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.1607, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  40  Loss :  0.5595657229423523 dsm :  1.928797960281372 neg entropy :  562.5488891601562\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8749, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8769, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  50  Loss :  0.3957251012325287 dsm :  1.6017612218856812 neg entropy :  559.6975708007812\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1271, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2637, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.7710, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  60  Loss :  0.6491866707801819 dsm :  3.9095733165740967 neg entropy :  560.9102783203125\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3447, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.6077, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  70  Loss :  0.5863724946975708 dsm :  0.7482948303222656 neg entropy :  557.4011840820312\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6979, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5116, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  80  Loss :  0.5274590253829956 dsm :  0.143074169754982 neg entropy :  563.1106567382812\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8774, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3787, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.1604, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  90  Loss :  0.5397086143493652 dsm :  0.5466823577880859 neg entropy :  561.2992553710938\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8138, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.5937, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  100  Loss :  0.5565177202224731 dsm :  0.6348336935043335 neg entropy :  556.7257690429688\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4932, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3437, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.5669, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  110  Loss :  0.6053169369697571 dsm :  0.0539533868432045 neg entropy :  561.1353759765625\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3589, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4810, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.4676, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  120  Loss :  0.49975156784057617 dsm :  2.811262369155884 neg entropy :  550.9146728515625\n",
      "{'edge_loss': tensor(0.0421, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.3881, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4774, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.3153, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  130  Loss :  0.5563111901283264 dsm :  0.012564338743686676 neg entropy :  557.8275756835938\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3797, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3873, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.1828, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  140  Loss :  0.5923662781715393 dsm :  4.658804416656494 neg entropy :  565.1107788085938\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.7100, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3755, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.4264, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  150  Loss :  0.43058156967163086 dsm :  1.3558027744293213 neg entropy :  556.6181030273438\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2395, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.3028, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  160  Loss :  0.3554551303386688 dsm :  1.2699865102767944 neg entropy :  565.5911254882812\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0067, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.7350, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  170  Loss :  0.5389754176139832 dsm :  0.2781972289085388 neg entropy :  567.0360107421875\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8686, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.6431, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  180  Loss :  0.5781448483467102 dsm :  1.3965284824371338 neg entropy :  557.3056030273438\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3777, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3727, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0725, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  190  Loss :  0.39112818241119385 dsm :  0.6799094676971436 neg entropy :  557.5643920898438\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0142, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6185, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.2332, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  200  Loss :  0.41958391666412354 dsm :  1.155009388923645 neg entropy :  555.1341552734375\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8557, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.6973, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  210  Loss :  0.3160177171230316 dsm :  2.799367904663086 neg entropy :  559.5348510742188\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4025, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.0831, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  220  Loss :  0.5910211801528931 dsm :  1.1110674142837524 neg entropy :  555.3160400390625\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7140, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4065, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.1845, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  230  Loss :  0.5692659616470337 dsm :  0.1085803285241127 neg entropy :  558.5570678710938\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6584, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.1077, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  240  Loss :  0.6298395395278931 dsm :  5.981256484985352 neg entropy :  558.8163452148438\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1782, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4083, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.2674, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  250  Loss :  0.5826545357704163 dsm :  1.8190017938613892 neg entropy :  559.593994140625\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6903, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.7906, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  260  Loss :  0.5619654655456543 dsm :  0.9666686058044434 neg entropy :  557.8775634765625\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8918, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4688, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(535.5412, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  270  Loss :  0.5934499502182007 dsm :  4.181230545043945 neg entropy :  557.9913940429688\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5566, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3486, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.3373, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  280  Loss :  0.6142654418945312 dsm :  0.21792498230934143 neg entropy :  557.3487548828125\n",
      "{'edge_loss': tensor(0.0398, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2710, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3955, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.9875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  290  Loss :  0.6504039168357849 dsm :  5.3180317878723145 neg entropy :  552.7050170898438\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.9428, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.1201, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  300  Loss :  0.6376622915267944 dsm :  0.48092442750930786 neg entropy :  550.7186279296875\n",
      "{'edge_loss': tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.5706, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4067, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.3661, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  310  Loss :  0.7252709269523621 dsm :  1.656288743019104 neg entropy :  545.5384521484375\n",
      "{'edge_loss': tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.9443, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.2110, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  320  Loss :  0.44075965881347656 dsm :  1.9981199502944946 neg entropy :  551.3788452148438\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.4729, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4130, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.2778, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  330  Loss :  0.6234126687049866 dsm :  2.0925538539886475 neg entropy :  556.3408203125\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6223, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3067, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.3672, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  340  Loss :  0.6313089728355408 dsm :  3.8950448036193848 neg entropy :  556.2318725585938\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7715, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4663, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.4132, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  350  Loss :  0.48501357436180115 dsm :  0.5801762342453003 neg entropy :  563.5263671875\n",
      "{'edge_loss': tensor(0.0277, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8480, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3753, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.5262, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  360  Loss :  0.5692006349563599 dsm :  1.3179606199264526 neg entropy :  557.8796997070312\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4046, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.4099, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  370  Loss :  0.5370277762413025 dsm :  0.18480171263217926 neg entropy :  560.2102661132812\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2286, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3168, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5689, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  380  Loss :  0.5638600587844849 dsm :  1.6360279321670532 neg entropy :  558.3119506835938\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4508, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4510, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(538.7072, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  390  Loss :  0.5865739583969116 dsm :  0.13247805833816528 neg entropy :  559.4771118164062\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5835, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3731, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.0672, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  400  Loss :  0.497048020362854 dsm :  1.5558757781982422 neg entropy :  562.1688842773438\n",
      "{'edge_loss': tensor(0.0275, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6788, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.1812, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  410  Loss :  0.721497118473053 dsm :  1.1233373880386353 neg entropy :  544.595703125\n",
      "{'edge_loss': tensor(0.0489, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.0560, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4724, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5162, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  420  Loss :  0.5898369550704956 dsm :  3.2009823322296143 neg entropy :  560.1168823242188\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5249, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3235, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.7234, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  430  Loss :  0.3286811411380768 dsm :  0.4360872805118561 neg entropy :  564.1513671875\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1299, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.0826, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  440  Loss :  0.4478307366371155 dsm :  0.9442658424377441 neg entropy :  555.6718139648438\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2784, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.7535, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  450  Loss :  0.5534565448760986 dsm :  0.4365755021572113 neg entropy :  559.8069458007812\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0291, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3655, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.6631, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  460  Loss :  0.6468390226364136 dsm :  1.7268857955932617 neg entropy :  558.5653686523438\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2681, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4684, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.8320, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  470  Loss :  0.5209965705871582 dsm :  0.02658168412744999 neg entropy :  563.3319702148438\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3418, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.5937, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  480  Loss :  0.43913090229034424 dsm :  3.726118803024292 neg entropy :  560.8362426757812\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0178, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.8554, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  490  Loss :  0.5591368079185486 dsm :  0.615898072719574 neg entropy :  561.8424072265625\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2157, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3625, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.6637, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  500  Loss :  0.5641358494758606 dsm :  2.953096389770508 neg entropy :  557.3619995117188\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0864, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3938, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.4288, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  510  Loss :  0.4101884365081787 dsm :  0.48280343413352966 neg entropy :  554.2098999023438\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1632, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3402, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.6436, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  520  Loss :  0.6286802291870117 dsm :  1.8359947204589844 neg entropy :  553.8250122070312\n",
      "{'edge_loss': tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8898, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3862, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.5884, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  530  Loss :  0.4075092375278473 dsm :  0.9133870005607605 neg entropy :  556.892578125\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1466, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3718, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.1646, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  540  Loss :  0.5585547089576721 dsm :  0.7282927632331848 neg entropy :  562.14404296875\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0824, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.6166, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  550  Loss :  0.618620753288269 dsm :  0.5145255327224731 neg entropy :  553.3496704101562\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3840, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5066, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.2692, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  560  Loss :  0.39484691619873047 dsm :  1.471880316734314 neg entropy :  563.176513671875\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0136, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3773, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3057, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.3484, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  570  Loss :  0.43627315759658813 dsm :  1.930152177810669 neg entropy :  553.3676147460938\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0356, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3663, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1625, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  580  Loss :  0.5503839254379272 dsm :  1.01387357711792 neg entropy :  561.8390502929688\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9651, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.5187, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  590  Loss :  0.5634521842002869 dsm :  0.038037072867155075 neg entropy :  562.9757690429688\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8121, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3520, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.6977, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  600  Loss :  0.4943148195743561 dsm :  0.7311299443244934 neg entropy :  562.7200317382812\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4673, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3010, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.9767, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  610  Loss :  0.5507522821426392 dsm :  1.376953363418579 neg entropy :  557.9822998046875\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0039, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.2997, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  620  Loss :  0.6141791343688965 dsm :  5.509871482849121 neg entropy :  562.5490112304688\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4814, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3518, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0714, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  630  Loss :  0.4605587124824524 dsm :  5.270914554595947 neg entropy :  554.839599609375\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8356, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.0979, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  640  Loss :  0.567682683467865 dsm :  0.341756671667099 neg entropy :  560.3699340820312\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2124, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.4200, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  650  Loss :  0.5345386862754822 dsm :  0.6903700232505798 neg entropy :  563.9381103515625\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5544, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3414, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4232, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  660  Loss :  0.5641650557518005 dsm :  1.421912670135498 neg entropy :  558.2680053710938\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0850, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3888, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.3291, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  670  Loss :  0.6290360689163208 dsm :  1.0025001764297485 neg entropy :  555.7816772460938\n",
      "{'edge_loss': tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2249, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2833, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.9127, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  680  Loss :  0.5617519617080688 dsm :  1.0699961185455322 neg entropy :  560.624755859375\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0392, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4030, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.9309, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  690  Loss :  0.5434783101081848 dsm :  2.9874112606048584 neg entropy :  561.41943359375\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3480, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.1729, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  700  Loss :  0.5300423502922058 dsm :  0.34976038336753845 neg entropy :  561.2648315429688\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0739, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0289, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  710  Loss :  0.5392438173294067 dsm :  0.4096319377422333 neg entropy :  557.1011962890625\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1526, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.2669, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  720  Loss :  0.5324135422706604 dsm :  1.230703353881836 neg entropy :  563.1986694335938\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0673, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  730  Loss :  0.538291871547699 dsm :  2.7416999340057373 neg entropy :  559.2802734375\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8582, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.3015, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  740  Loss :  0.6068778038024902 dsm :  1.4120217561721802 neg entropy :  556.0946655273438\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7197, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4705, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.2212, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  750  Loss :  0.5946879386901855 dsm :  1.6773446798324585 neg entropy :  560.055908203125\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5624, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.8966, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  760  Loss :  0.6824508905410767 dsm :  1.6779810190200806 neg entropy :  552.8355712890625\n",
      "{'edge_loss': tensor(0.0458, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6315, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3876, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.9635, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  770  Loss :  0.4873007833957672 dsm :  1.2370620965957642 neg entropy :  550.9579467773438\n",
      "{'edge_loss': tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6687, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.5504, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  780  Loss :  0.5594078302383423 dsm :  1.3413658142089844 neg entropy :  563.06494140625\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0462, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2647, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.4101, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  790  Loss :  0.609700620174408 dsm :  3.3608875274658203 neg entropy :  562.6408081054688\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2135, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.9000, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  800  Loss :  0.4987722635269165 dsm :  0.2735523283481598 neg entropy :  562.7639770507812\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1543, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1816, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(438.8076, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  810  Loss :  0.615946352481842 dsm :  0.6928533911705017 neg entropy :  559.67919921875\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6230, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4907, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.2341, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  820  Loss :  0.42635637521743774 dsm :  0.5373677611351013 neg entropy :  554.5868530273438\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5008, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3973, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.2061, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  830  Loss :  0.6806517839431763 dsm :  2.522446870803833 neg entropy :  553.1146850585938\n",
      "{'edge_loss': tensor(0.0438, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1139, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4605, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.3293, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  840  Loss :  0.6010242700576782 dsm :  3.1765944957733154 neg entropy :  556.7420043945312\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1517, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4578, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.9201, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  850  Loss :  0.674386739730835 dsm :  2.380727767944336 neg entropy :  551.92578125\n",
      "{'edge_loss': tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6265, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4119, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.8614, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  860  Loss :  0.6641269326210022 dsm :  2.131586790084839 neg entropy :  562.0960083007812\n",
      "{'edge_loss': tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5624, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4144, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.3231, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  870  Loss :  0.5356768369674683 dsm :  2.881882429122925 neg entropy :  559.4003295898438\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0430, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3580, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.5548, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  880  Loss :  0.597736120223999 dsm :  1.5687073469161987 neg entropy :  554.435546875\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4637, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3654, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.0708, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  890  Loss :  0.4186224639415741 dsm :  1.1755203008651733 neg entropy :  559.8599853515625\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0140, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3718, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.8307, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  900  Loss :  0.5808027386665344 dsm :  1.0560449361801147 neg entropy :  560.31103515625\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3763, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4905, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.1657, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  910  Loss :  0.5499904751777649 dsm :  0.8901183009147644 neg entropy :  561.5787963867188\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7099, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3257, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.0331, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  920  Loss :  0.4906396269798279 dsm :  0.46107107400894165 neg entropy :  555.5123901367188\n",
      "{'edge_loss': tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6372, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.1704, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  930  Loss :  0.37785786390304565 dsm :  1.9697939157485962 neg entropy :  559.0781860351562\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3916, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2751, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.9709, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  940  Loss :  0.5466605424880981 dsm :  0.6402003169059753 neg entropy :  558.4130249023438\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2699, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.0032, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  950  Loss :  0.7028546333312988 dsm :  1.6744321584701538 neg entropy :  559.3785400390625\n",
      "{'edge_loss': tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5344, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3869, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.9961, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  960  Loss :  0.5702780485153198 dsm :  1.9166700839996338 neg entropy :  563.5282592773438\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2675, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4204, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(528.0196, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  970  Loss :  0.5706775188446045 dsm :  1.4611486196517944 neg entropy :  563.61181640625\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8925, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.5909, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  980  Loss :  0.5893331170082092 dsm :  0.4485315978527069 neg entropy :  556.1283569335938\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5926, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4554, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.4067, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  990  Loss :  0.36064353585243225 dsm :  2.1334850788116455 neg entropy :  558.2047729492188\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7144, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.1722, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1000  Loss :  0.5670754313468933 dsm :  0.790083110332489 neg entropy :  561.4390869140625\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6212, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3547, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.9278, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1010  Loss :  0.5198691487312317 dsm :  2.8672492504119873 neg entropy :  567.3156127929688\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.0287, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2719, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.0501, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1020  Loss :  0.24408182501792908 dsm :  0.3837999701499939 neg entropy :  556.8917236328125\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0319, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4557, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.8008, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1030  Loss :  0.5904903411865234 dsm :  3.0889599323272705 neg entropy :  559.6649780273438\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5979, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.6553, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1040  Loss :  0.6025182604789734 dsm :  1.477866768836975 neg entropy :  559.4559936523438\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8851, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4288, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.8242, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1050  Loss :  0.5533035397529602 dsm :  0.4062860608100891 neg entropy :  560.0943603515625\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5561, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4183, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.6464, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1060  Loss :  0.4516138732433319 dsm :  0.016607198864221573 neg entropy :  552.1134643554688\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0132, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.7980, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3667, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.9329, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1070  Loss :  0.3830116391181946 dsm :  1.3778785467147827 neg entropy :  560.2039184570312\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8074, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2826, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1536, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1080  Loss :  0.5433455109596252 dsm :  0.7674855589866638 neg entropy :  557.8135986328125\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6157, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3053, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.2044, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1090  Loss :  0.5768901705741882 dsm :  0.3303548991680145 neg entropy :  562.8541870117188\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9231, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3236, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.3503, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1100  Loss :  0.580302894115448 dsm :  2.2154924869537354 neg entropy :  561.3148803710938\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0708, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.3687, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1110  Loss :  0.43676304817199707 dsm :  0.6895292401313782 neg entropy :  557.500732421875\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0690, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.0453, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1120  Loss :  0.5546312928199768 dsm :  0.1294717788696289 neg entropy :  556.3021240234375\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2621, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4427, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.7521, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1130  Loss :  0.5936600565910339 dsm :  0.6683790683746338 neg entropy :  559.0038452148438\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0390, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4374, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.3911, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1140  Loss :  0.5959002375602722 dsm :  4.493602275848389 neg entropy :  554.0322265625\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7104, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3832, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.3612, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1150  Loss :  0.580288290977478 dsm :  0.39666876196861267 neg entropy :  558.07421875\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3717, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2258, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(432.2556, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1160  Loss :  0.5848658084869385 dsm :  1.745395541191101 neg entropy :  559.5245971679688\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7817, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2817, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.2274, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1170  Loss :  0.4162234663963318 dsm :  0.11309254169464111 neg entropy :  558.7028198242188\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1578, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3340, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.7687, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1180  Loss :  0.5985269546508789 dsm :  0.2702123522758484 neg entropy :  555.8435668945312\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8841, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4568, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.7532, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1190  Loss :  0.4858759641647339 dsm :  0.8485315442085266 neg entropy :  564.161865234375\n",
      "{'edge_loss': tensor(0.0272, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2529, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3260, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8974, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1200  Loss :  0.5627865791320801 dsm :  0.01741926372051239 neg entropy :  559.2990112304688\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9462, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4207, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.9716, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1210  Loss :  0.5496073961257935 dsm :  0.2587880492210388 neg entropy :  560.6962890625\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0004, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9774, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4289, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.1962, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1220  Loss :  0.5647478103637695 dsm :  1.0587705373764038 neg entropy :  557.32177734375\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0868, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.3120, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1230  Loss :  0.3809677064418793 dsm :  1.7781933546066284 neg entropy :  563.1900634765625\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7729, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2812, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.8431, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1240  Loss :  0.363165944814682 dsm :  3.5269317626953125 neg entropy :  560.3024291992188\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8214, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.9736, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1250  Loss :  0.5934630036354065 dsm :  0.9952936172485352 neg entropy :  560.66748046875\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7938, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3606, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.9898, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1260  Loss :  0.5985049605369568 dsm :  1.731337547302246 neg entropy :  558.9345703125\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5249, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3576, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.6113, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1270  Loss :  0.6395292282104492 dsm :  0.4047563970088959 neg entropy :  551.7308959960938\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0045, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5045, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.9975, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1280  Loss :  0.633115828037262 dsm :  5.167855739593506 neg entropy :  558.1466674804688\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2924, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4383, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.9763, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1290  Loss :  0.1856316477060318 dsm :  2.93612003326416 neg entropy :  557.5943603515625\n",
      "{'edge_loss': tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0486, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1595, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.6871, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1300  Loss :  0.5436581373214722 dsm :  2.25323486328125 neg entropy :  561.5346069335938\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1096, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3534, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.3294, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1310  Loss :  0.6075121164321899 dsm :  0.44612056016921997 neg entropy :  558.3362426757812\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9794, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.5431, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1320  Loss :  0.5734475255012512 dsm :  1.8292549848556519 neg entropy :  559.1298828125\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5115, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4333, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.5144, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1330  Loss :  0.404923677444458 dsm :  1.208617091178894 neg entropy :  559.4931030273438\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4904, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2848, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.2002, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1340  Loss :  0.5412166714668274 dsm :  0.39256390929222107 neg entropy :  559.6283569335938\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5719, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3791, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.7148, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1350  Loss :  0.6242177486419678 dsm :  0.9671621322631836 neg entropy :  564.3897705078125\n",
      "{'edge_loss': tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2028, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3797, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.4814, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1360  Loss :  0.56581711769104 dsm :  1.3040493726730347 neg entropy :  560.20947265625\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0462, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.7429, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1370  Loss :  0.6380150318145752 dsm :  4.24224853515625 neg entropy :  562.4265747070312\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5887, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4282, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.7363, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1380  Loss :  0.6048161387443542 dsm :  1.2248128652572632 neg entropy :  559.5584106445312\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6379, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4304, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.1466, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1390  Loss :  0.5127366781234741 dsm :  0.8641173243522644 neg entropy :  561.0828247070312\n",
      "{'edge_loss': tensor(0.0284, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0338, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4878, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(534.5102, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1400  Loss :  0.6450561285018921 dsm :  1.5245327949523926 neg entropy :  557.7776489257812\n",
      "{'edge_loss': tensor(0.0422, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6174, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3717, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.6923, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1410  Loss :  0.5874018669128418 dsm :  0.8753473162651062 neg entropy :  555.10888671875\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7640, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.7318, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1420  Loss :  0.551332414150238 dsm :  0.07992702722549438 neg entropy :  556.5217895507812\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1558, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3898, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.2856, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1430  Loss :  0.5660854578018188 dsm :  1.131399154663086 neg entropy :  557.57080078125\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8619, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3929, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4573, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1440  Loss :  0.5515013933181763 dsm :  0.1122097596526146 neg entropy :  563.5740356445312\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6383, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4228, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(538.7904, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1450  Loss :  0.5265818238258362 dsm :  1.1696882247924805 neg entropy :  562.9762573242188\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3360, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2709, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.8459, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1460  Loss :  0.6019404530525208 dsm :  1.7501758337020874 neg entropy :  555.14794921875\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0423, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.7868, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1470  Loss :  0.5185214877128601 dsm :  0.4355944097042084 neg entropy :  557.7702026367188\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3845, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.1453, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1480  Loss :  0.40750277042388916 dsm :  2.8633880615234375 neg entropy :  560.3956909179688\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0160, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5879, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2697, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.2164, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1490  Loss :  0.5624961256980896 dsm :  1.739741563796997 neg entropy :  557.105224609375\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6851, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4070, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2091, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1500  Loss :  0.5175172686576843 dsm :  2.5218377113342285 neg entropy :  564.0169677734375\n",
      "{'edge_loss': tensor(0.0278, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9855, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.1197, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1510  Loss :  0.5902211666107178 dsm :  1.26412832736969 neg entropy :  558.1466674804688\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3253, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2775, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.2232, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1520  Loss :  0.6212021708488464 dsm :  1.435153841972351 neg entropy :  552.4052124023438\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.8086, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4367, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.0724, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1530  Loss :  0.5979733467102051 dsm :  0.6934735178947449 neg entropy :  559.2994384765625\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3406, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.8802, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1540  Loss :  0.5712071061134338 dsm :  2.987407684326172 neg entropy :  559.8065795898438\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8400, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3130, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0566, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1550  Loss :  0.25929373502731323 dsm :  0.04082970321178436 neg entropy :  559.6383666992188\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6609, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4106, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.9666, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1560  Loss :  0.41315051913261414 dsm :  0.680377721786499 neg entropy :  558.8798828125\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0208, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2683, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.7385, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1570  Loss :  0.5092084407806396 dsm :  3.085911273956299 neg entropy :  561.3302612304688\n",
      "{'edge_loss': tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4393, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.2950, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1580  Loss :  0.6213533282279968 dsm :  1.084336757659912 neg entropy :  558.4854736328125\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7383, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3924, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.2988, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1590  Loss :  0.5632469654083252 dsm :  2.153748035430908 neg entropy :  556.2472534179688\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2691, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4040, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.8221, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1600  Loss :  0.5690242052078247 dsm :  2.869877576828003 neg entropy :  558.2520751953125\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1202, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3098, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.0454, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1610  Loss :  0.6135002970695496 dsm :  0.704136848449707 neg entropy :  553.174560546875\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3985, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.0859, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1620  Loss :  0.45850616693496704 dsm :  1.9461039304733276 neg entropy :  554.4869995117188\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6134, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.7967, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1630  Loss :  0.6120417714118958 dsm :  1.3271923065185547 neg entropy :  554.1569213867188\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0472, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4251, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1926, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1640  Loss :  0.5566509962081909 dsm :  0.7831081748008728 neg entropy :  557.0157470703125\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1198, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2999, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.5224, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1650  Loss :  0.5993251800537109 dsm :  2.8402059078216553 neg entropy :  560.068359375\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7619, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4305, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.9686, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1660  Loss :  0.661588728427887 dsm :  2.45682692527771 neg entropy :  559.10107421875\n",
      "{'edge_loss': tensor(0.0435, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3048, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.6483, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1670  Loss :  0.546359658241272 dsm :  1.7857754230499268 neg entropy :  561.5293579101562\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1345, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.3934, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1680  Loss :  0.6310230493545532 dsm :  0.7726194262504578 neg entropy :  560.4918823242188\n",
      "{'edge_loss': tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8941, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3616, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.6959, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1690  Loss :  0.6368707418441772 dsm :  1.1601566076278687 neg entropy :  555.0982666015625\n",
      "{'edge_loss': tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2786, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3634, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.2570, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1700  Loss :  0.5854732394218445 dsm :  4.722318172454834 neg entropy :  559.4268798828125\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3298, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3472, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.8979, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1710  Loss :  0.6124573349952698 dsm :  1.5285662412643433 neg entropy :  560.3809814453125\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3015, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.7711, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1720  Loss :  0.542657732963562 dsm :  5.357491493225098 neg entropy :  564.0324096679688\n",
      "{'edge_loss': tensor(0.0293, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6126, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3092, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.4424, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1730  Loss :  0.4507423937320709 dsm :  1.9070024490356445 neg entropy :  558.77587890625\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7615, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3700, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.0186, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1740  Loss :  0.5334681868553162 dsm :  0.8999356627464294 neg entropy :  564.6253662109375\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7215, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.5824, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1750  Loss :  0.43695324659347534 dsm :  0.5289643406867981 neg entropy :  560.6732788085938\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5872, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.7451, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1760  Loss :  0.5747144222259521 dsm :  1.3923991918563843 neg entropy :  559.7808837890625\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8929, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3634, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.8909, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1770  Loss :  0.4321092367172241 dsm :  3.2754859924316406 neg entropy :  559.5380249023438\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1247, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3992, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.9920, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1780  Loss :  0.4862472116947174 dsm :  3.9711544513702393 neg entropy :  557.2726440429688\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0138, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4381, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4008, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3729, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1790  Loss :  0.38248056173324585 dsm :  0.3460482954978943 neg entropy :  556.1310424804688\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6550, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4068, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.4854, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1800  Loss :  0.5779794454574585 dsm :  4.494424343109131 neg entropy :  559.501953125\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3949, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3474, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.4516, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1810  Loss :  0.6119885444641113 dsm :  2.8468141555786133 neg entropy :  558.0680541992188\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7093, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4290, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.7755, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1820  Loss :  0.6013295650482178 dsm :  0.39504265785217285 neg entropy :  561.3788452148438\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1286, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3446, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8890, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1830  Loss :  0.543031632900238 dsm :  0.6016301512718201 neg entropy :  559.2091674804688\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9983, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.5232, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1840  Loss :  0.39981624484062195 dsm :  0.5890617966651917 neg entropy :  558.0989379882812\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0324, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4023, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.2048, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1850  Loss :  0.5668630599975586 dsm :  1.4122933149337769 neg entropy :  558.0750122070312\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2784, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3538, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.9365, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1860  Loss :  0.579119861125946 dsm :  1.1103177070617676 neg entropy :  562.5902709960938\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2768, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.8311, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1870  Loss :  0.569302499294281 dsm :  4.135025978088379 neg entropy :  564.7515869140625\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4600, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4286, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(534.2271, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1880  Loss :  0.5557940602302551 dsm :  4.193958282470703 neg entropy :  557.5852661132812\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4786, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2936, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4516, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1890  Loss :  0.584142804145813 dsm :  0.7833176255226135 neg entropy :  556.8689575195312\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5688, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.0763, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1900  Loss :  0.44428351521492004 dsm :  2.7326369285583496 neg entropy :  555.0335083007812\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2509, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.4418, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1910  Loss :  0.40120387077331543 dsm :  3.908032178878784 neg entropy :  558.935302734375\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0230, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.2260, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1920  Loss :  0.5642632246017456 dsm :  0.11988184601068497 neg entropy :  564.0164794921875\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8078, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.8477, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1930  Loss :  0.638242781162262 dsm :  2.1236071586608887 neg entropy :  555.7354125976562\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1811, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.2155, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1940  Loss :  0.5993486046791077 dsm :  2.440648317337036 neg entropy :  554.4083251953125\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0056, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3550, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.6008, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1950  Loss :  0.615971565246582 dsm :  3.183027505874634 neg entropy :  551.8805541992188\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.0987, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4009, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.1164, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1960  Loss :  0.6286463141441345 dsm :  3.958456516265869 neg entropy :  563.3773803710938\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8617, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3638, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.4303, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1970  Loss :  0.3948213458061218 dsm :  0.20420804619789124 neg entropy :  557.8477172851562\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9969, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3207, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.6244, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1980  Loss :  0.4206986427307129 dsm :  0.3857593238353729 neg entropy :  555.16162109375\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.9237, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.0549, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  1990  Loss :  0.5304068326950073 dsm :  0.3161178529262543 neg entropy :  560.8507690429688\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4404, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.2602, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2000  Loss :  0.5641684532165527 dsm :  0.39648041129112244 neg entropy :  560.3839111328125\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2908, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3663, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.7340, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2010  Loss :  0.46712079644203186 dsm :  1.9361270666122437 neg entropy :  558.1892700195312\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5325, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.9447, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2020  Loss :  0.194754958152771 dsm :  0.4884760081768036 neg entropy :  561.1107177734375\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0316, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7164, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.0973, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2030  Loss :  0.6418660283088684 dsm :  1.749174952507019 neg entropy :  556.6012573242188\n",
      "{'edge_loss': tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0646, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3551, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0602, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2040  Loss :  0.5989060401916504 dsm :  1.4390901327133179 neg entropy :  556.7658081054688\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9551, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2890, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.3059, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2050  Loss :  0.6227518916130066 dsm :  0.31246134638786316 neg entropy :  557.6245727539062\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8172, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4289, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.3958, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2060  Loss :  0.3628910779953003 dsm :  1.2370657920837402 neg entropy :  562.9550170898438\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9930, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.8739, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2070  Loss :  0.6268792152404785 dsm :  4.699071407318115 neg entropy :  556.489990234375\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1913, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3470, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.4134, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2080  Loss :  0.6172530651092529 dsm :  0.16016976535320282 neg entropy :  555.5753173828125\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1937, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.1580, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2090  Loss :  0.4409797191619873 dsm :  0.10183755308389664 neg entropy :  557.48193359375\n",
      "{'edge_loss': tensor(0.0410, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7430, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2882, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.6523, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2100  Loss :  0.396516889333725 dsm :  3.051151990890503 neg entropy :  559.7181396484375\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5862, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(531.2674, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2110  Loss :  0.5894575119018555 dsm :  1.032059907913208 neg entropy :  561.6764526367188\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1317, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3913, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.6997, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2120  Loss :  0.3789304196834564 dsm :  1.4252989292144775 neg entropy :  563.9737548828125\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9029, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4048, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.2419, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2130  Loss :  0.6754876971244812 dsm :  0.8681193590164185 neg entropy :  552.408203125\n",
      "{'edge_loss': tensor(0.0453, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0581, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3850, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9832, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2140  Loss :  0.5975832343101501 dsm :  1.5837562084197998 neg entropy :  555.6600952148438\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7817, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4105, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.7887, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2150  Loss :  0.5054099559783936 dsm :  1.6081432104110718 neg entropy :  563.1460571289062\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9119, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.6044, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2160  Loss :  0.5196571350097656 dsm :  0.49186205863952637 neg entropy :  564.3231811523438\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9826, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2297, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(453.4134, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2170  Loss :  0.5424931645393372 dsm :  0.8626744151115417 neg entropy :  559.62255859375\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2653, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3404, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.7690, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2180  Loss :  0.572263777256012 dsm :  0.11589153110980988 neg entropy :  560.9789428710938\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2161, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3145, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.2772, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2190  Loss :  0.5655431151390076 dsm :  2.141913890838623 neg entropy :  560.5836791992188\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6516, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8978, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2200  Loss :  0.43318238854408264 dsm :  1.0809597969055176 neg entropy :  560.1420288085938\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0139, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3659, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.9459, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2210  Loss :  0.5697330236434937 dsm :  1.8243391513824463 neg entropy :  554.7952270507812\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1774, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3119, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.8987, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2220  Loss :  0.6127889156341553 dsm :  0.03385845571756363 neg entropy :  553.7623291015625\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2718, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3262, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.4810, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2230  Loss :  0.5980783104896545 dsm :  1.1035183668136597 neg entropy :  555.7615356445312\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1542, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3568, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.2770, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2240  Loss :  0.4614534378051758 dsm :  2.68314790725708 neg entropy :  559.3410034179688\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6845, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4664, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.6402, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2250  Loss :  0.5118263959884644 dsm :  0.6558690071105957 neg entropy :  558.3848876953125\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4784, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2838, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.5133, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2260  Loss :  0.6205158829689026 dsm :  0.013010228052735329 neg entropy :  556.661376953125\n",
      "{'edge_loss': tensor(0.0412, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0713, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.5836, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2270  Loss :  0.5519239902496338 dsm :  0.6651342511177063 neg entropy :  561.6904296875\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2265, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.3958, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2280  Loss :  0.5982550382614136 dsm :  0.6994354724884033 neg entropy :  556.0732421875\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8828, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2340, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.8777, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2290  Loss :  0.5481934547424316 dsm :  0.07756024599075317 neg entropy :  554.9146728515625\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5412, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4266, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.0583, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2300  Loss :  0.40369561314582825 dsm :  0.5523180365562439 neg entropy :  561.6480712890625\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9760, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3630, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8473, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2310  Loss :  0.39960500597953796 dsm :  1.8182321786880493 neg entropy :  561.5431518554688\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1521, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3939, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.0630, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2320  Loss :  0.5669658184051514 dsm :  2.0281128883361816 neg entropy :  564.98876953125\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2273, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3702, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.6925, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2330  Loss :  0.6517307758331299 dsm :  0.9305099844932556 neg entropy :  552.7535400390625\n",
      "{'edge_loss': tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5182, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4733, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.2703, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2340  Loss :  0.5783829689025879 dsm :  1.0317167043685913 neg entropy :  558.0122680664062\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7396, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3175, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.1863, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2350  Loss :  0.5550743937492371 dsm :  1.821811318397522 neg entropy :  561.1810913085938\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6379, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4453, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(526.8771, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2360  Loss :  0.5300552845001221 dsm :  0.639622151851654 neg entropy :  562.7014770507812\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4527, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3423, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9661, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2370  Loss :  0.5981594324111938 dsm :  4.527474403381348 neg entropy :  558.4171752929688\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9613, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4285, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.6956, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2380  Loss :  0.5413080453872681 dsm :  2.774172067642212 neg entropy :  564.3739624023438\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5803, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3098, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.9028, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2390  Loss :  0.6873151063919067 dsm :  1.8211212158203125 neg entropy :  553.9049682617188\n",
      "{'edge_loss': tensor(0.0451, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5560, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(450.5556, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2400  Loss :  0.6007158756256104 dsm :  1.7336562871932983 neg entropy :  563.6928100585938\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6378, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2921, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.4318, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2410  Loss :  0.6078066229820251 dsm :  3.110036849975586 neg entropy :  557.1918334960938\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1083, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.1936, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2420  Loss :  0.48192688822746277 dsm :  3.237666368484497 neg entropy :  559.2211303710938\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0135, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6475, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4064, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.3484, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2430  Loss :  0.6168345212936401 dsm :  1.7201998233795166 neg entropy :  557.27490234375\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8012, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.0075, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2440  Loss :  0.5993859767913818 dsm :  0.6659799218177795 neg entropy :  555.3285522460938\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0638, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3152, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.5801, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2450  Loss :  0.35944846272468567 dsm :  0.3238574266433716 neg entropy :  562.8681030273438\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3004, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3749, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.0478, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2460  Loss :  0.23532997071743011 dsm :  0.19675922393798828 neg entropy :  560.1691284179688\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0318, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3045, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.0736, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2470  Loss :  0.5856805443763733 dsm :  1.67424476146698 neg entropy :  556.9931030273438\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5529, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4538, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.1499, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2480  Loss :  0.5600901246070862 dsm :  1.2113265991210938 neg entropy :  556.3717651367188\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9317, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.4359, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  93  Batch :  2490  Loss :  0.5284589529037476 dsm :  1.1488536596298218 neg entropy :  556.8837280273438\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3697, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3716, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.3547, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3207, device='cuda:0'), 'property_loss': tensor(485.4023, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  0 Loss sum :  0.5343710780143738 dsm :  4.201897621154785 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0256, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3586, device='cuda:0'), 'property_loss': tensor(508.8145, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  10 Loss sum :  0.29818445444107056 dsm :  0.1562570035457611 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0245, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2730, device='cuda:0'), 'property_loss': tensor(495.8357, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  20 Loss sum :  0.46128761768341064 dsm :  2.139070987701416 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2578, device='cuda:0'), 'property_loss': tensor(481.4205, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  30 Loss sum :  0.5056861042976379 dsm :  0.5796417593955994 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3859, device='cuda:0'), 'property_loss': tensor(503.1077, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  40 Loss sum :  0.5422026515007019 dsm :  1.973464846611023 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3052, device='cuda:0'), 'property_loss': tensor(473.3814, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  50 Loss sum :  0.4972715377807617 dsm :  1.6517339944839478 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0398, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5102, device='cuda:0'), 'property_loss': tensor(527.8426, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  60 Loss sum :  0.628303050994873 dsm :  1.1370657682418823 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2448, device='cuda:0'), 'property_loss': tensor(456.1059, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  70 Loss sum :  0.5012056231498718 dsm :  0.43445608019828796 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4473, device='cuda:0'), 'property_loss': tensor(529.4387, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  80 Loss sum :  0.5805895328521729 dsm :  2.44716215133667 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0'), 'node_loss': tensor(0.0019, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3453, device='cuda:0'), 'property_loss': tensor(484.5065, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  90 Loss sum :  0.5627368092536926 dsm :  0.6961050033569336 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4178, device='cuda:0'), 'property_loss': tensor(525.2490, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  100 Loss sum :  0.5308079123497009 dsm :  1.1101064682006836 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0304, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3875, device='cuda:0'), 'property_loss': tensor(521.8212, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  110 Loss sum :  0.5243967175483704 dsm :  0.8831574320793152 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.2949, device='cuda:0'), 'property_loss': tensor(484.1151, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  120 Loss sum :  0.49169865250587463 dsm :  0.13939736783504486 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3403, device='cuda:0'), 'property_loss': tensor(489.9426, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  130 Loss sum :  0.5317533612251282 dsm :  3.0297398567199707 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0'), 'node_loss': tensor(-0.0153, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2633, device='cuda:0'), 'property_loss': tensor(469.6714, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  140 Loss sum :  0.35494476556777954 dsm :  2.548651933670044 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0'), 'node_loss': tensor(-0.0485, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4783, device='cuda:0'), 'property_loss': tensor(513.0341, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  150 Loss sum :  0.08007331192493439 dsm :  0.816754937171936 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2782, device='cuda:0'), 'property_loss': tensor(480.1523, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  160 Loss sum :  0.3517693877220154 dsm :  1.5385189056396484 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0'), 'node_loss': tensor(-0.0145, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2495, device='cuda:0'), 'property_loss': tensor(441.5040, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  170 Loss sum :  0.3877093195915222 dsm :  0.4835895597934723 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0255, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3041, device='cuda:0'), 'property_loss': tensor(493.5816, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  180 Loss sum :  0.4521101117134094 dsm :  0.44128283858299255 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0287, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3078, device='cuda:0'), 'property_loss': tensor(507.4667, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  190 Loss sum :  0.5083802342414856 dsm :  2.2852535247802734 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2810, device='cuda:0'), 'property_loss': tensor(464.9559, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  200 Loss sum :  0.59825199842453 dsm :  6.232757568359375 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3792, device='cuda:0'), 'property_loss': tensor(498.4865, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  210 Loss sum :  0.5506918430328369 dsm :  1.0927400588989258 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0286, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3303, device='cuda:0'), 'property_loss': tensor(490.8173, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  220 Loss sum :  0.48671382665634155 dsm :  0.7308441996574402 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3796, device='cuda:0'), 'property_loss': tensor(506.2121, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  230 Loss sum :  0.37129098176956177 dsm :  2.772191286087036 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4270, device='cuda:0'), 'property_loss': tensor(518.1042, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  240 Loss sum :  0.3668152987957001 dsm :  0.1574162095785141 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2352, device='cuda:0'), 'property_loss': tensor(463.1057, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  250 Loss sum :  0.48321399092674255 dsm :  1.1965142488479614 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0241, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3907, device='cuda:0'), 'property_loss': tensor(528.7553, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  260 Loss sum :  0.5004072785377502 dsm :  5.91771936416626 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0'), 'node_loss': tensor(0.0019, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3498, device='cuda:0'), 'property_loss': tensor(494.8617, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  270 Loss sum :  0.5446901321411133 dsm :  1.0097869634628296 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0282, device='cuda:0'), 'node_loss': tensor(0.0011, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4312, device='cuda:0'), 'property_loss': tensor(531.9179, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  280 Loss sum :  0.49574196338653564 dsm :  0.2722697854042053 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4078, device='cuda:0'), 'property_loss': tensor(495.6641, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  290 Loss sum :  0.4217805564403534 dsm :  5.009162425994873 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0'), 'node_loss': tensor(0.0025, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3527, device='cuda:0'), 'property_loss': tensor(474.3236, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  300 Loss sum :  0.595180869102478 dsm :  0.9070196151733398 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0'), 'node_loss': tensor(0.0028, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2353, device='cuda:0'), 'property_loss': tensor(468.5334, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  310 Loss sum :  0.5506296157836914 dsm :  0.5445994734764099 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0'), 'node_loss': tensor(-0.0139, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3055, device='cuda:0'), 'property_loss': tensor(496.8908, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  320 Loss sum :  0.3762962818145752 dsm :  3.840162992477417 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4406, device='cuda:0'), 'property_loss': tensor(537.5202, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  330 Loss sum :  0.5225912928581238 dsm :  1.395098090171814 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0'), 'node_loss': tensor(-0.0157, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3148, device='cuda:0'), 'property_loss': tensor(476.7946, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  340 Loss sum :  0.3748789131641388 dsm :  0.7535020112991333 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2918, device='cuda:0'), 'property_loss': tensor(472.7059, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  350 Loss sum :  0.5504462718963623 dsm :  0.21485428512096405 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0259, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3183, device='cuda:0'), 'property_loss': tensor(506.9809, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  360 Loss sum :  0.4846232533454895 dsm :  3.1423614025115967 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0'), 'node_loss': tensor(-0.0150, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2234, device='cuda:0'), 'property_loss': tensor(467.5751, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  370 Loss sum :  0.35806557536125183 dsm :  2.646667957305908 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2820, device='cuda:0'), 'property_loss': tensor(470.7145, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  380 Loss sum :  0.5203689336776733 dsm :  2.4621434211730957 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4196, device='cuda:0'), 'property_loss': tensor(519.3204, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  390 Loss sum :  0.5448300242424011 dsm :  0.7374403476715088 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0'), 'node_loss': tensor(0.0017, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3549, device='cuda:0'), 'property_loss': tensor(492.4464, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  400 Loss sum :  0.5259795784950256 dsm :  1.0402116775512695 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3482, device='cuda:0'), 'property_loss': tensor(499.4053, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  410 Loss sum :  0.540808916091919 dsm :  0.6841825246810913 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0278, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2664, device='cuda:0'), 'property_loss': tensor(470.7019, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  420 Loss sum :  0.3090497851371765 dsm :  0.38307881355285645 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0238, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2857, device='cuda:0'), 'property_loss': tensor(492.0318, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  430 Loss sum :  0.43707799911499023 dsm :  0.834477424621582 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3377, device='cuda:0'), 'property_loss': tensor(499.0631, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  440 Loss sum :  0.5117197632789612 dsm :  0.16351206600666046 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3516, device='cuda:0'), 'property_loss': tensor(475.8813, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  450 Loss sum :  0.6188778281211853 dsm :  3.007239580154419 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3388, device='cuda:0'), 'property_loss': tensor(498.1926, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  460 Loss sum :  0.5671602487564087 dsm :  1.3201912641525269 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0'), 'node_loss': tensor(-0.0161, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.3003, device='cuda:0'), 'property_loss': tensor(474.4596, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  470 Loss sum :  0.3930095136165619 dsm :  1.6772533655166626 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2546, device='cuda:0'), 'property_loss': tensor(452.7803, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  480 Loss sum :  0.40403977036476135 dsm :  1.2120190858840942 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0267, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2806, device='cuda:0'), 'property_loss': tensor(484.9054, device='cuda:0')}\n",
      "Epoch (val) :  93   batch (val) :  490 Loss sum :  0.48077136278152466 dsm :  2.0790352821350098 neg entropy :  568.9645385742188\n",
      "Epoch :  94  Batch :  0  Loss :  0.5849740505218506 dsm :  1.0490716695785522 neg entropy :  557.5421752929688\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2490, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2739, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(456.2415, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  10  Loss :  0.5453673601150513 dsm :  2.473931312561035 neg entropy :  560.1989135742188\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0938, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3555, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.0918, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  20  Loss :  0.4893759489059448 dsm :  0.7728944420814514 neg entropy :  557.9744262695312\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0622, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4440, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8022, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  30  Loss :  0.36748558282852173 dsm :  1.7960712909698486 neg entropy :  560.417724609375\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3848, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.2141, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  40  Loss :  0.3981812298297882 dsm :  1.9430630207061768 neg entropy :  560.8984985351562\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5457, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4102, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.3856, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  50  Loss :  0.5173066854476929 dsm :  0.5404948592185974 neg entropy :  559.7545166015625\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8956, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3613, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.0918, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  60  Loss :  0.4537743330001831 dsm :  2.5558459758758545 neg entropy :  562.4169311523438\n",
      "{'edge_loss': tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0146, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0967, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(434.0308, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  70  Loss :  0.5616326928138733 dsm :  1.0034388303756714 neg entropy :  562.8906860351562\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7140, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3136, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.9472, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  80  Loss :  0.6094790101051331 dsm :  0.770718514919281 neg entropy :  558.2454223632812\n",
      "{'edge_loss': tensor(0.0384, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1020, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4133, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.2346, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  90  Loss :  0.6082688570022583 dsm :  0.23782475292682648 neg entropy :  560.5292358398438\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4098, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2982, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.4868, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  100  Loss :  0.7582191824913025 dsm :  4.4911885261535645 neg entropy :  547.900390625\n",
      "{'edge_loss': tensor(0.0501, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3169, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3901, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.4530, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  110  Loss :  0.46629849076271057 dsm :  0.06410925835371017 neg entropy :  560.9793090820312\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2181, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0904, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  120  Loss :  0.5569597482681274 dsm :  0.5010064244270325 neg entropy :  557.54833984375\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7120, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4219, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.5340, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  130  Loss :  0.592166543006897 dsm :  1.9473772048950195 neg entropy :  559.9397583007812\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7022, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2986, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.8686, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  140  Loss :  0.6048109531402588 dsm :  2.0691275596618652 neg entropy :  561.4210815429688\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9914, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8943, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  150  Loss :  0.3737277388572693 dsm :  1.342123031616211 neg entropy :  559.9569091796875\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6678, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3224, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.7289, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  160  Loss :  0.5508330464363098 dsm :  0.5599241256713867 neg entropy :  556.5714721679688\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3199, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3751, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.2675, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  170  Loss :  0.561266303062439 dsm :  1.1951167583465576 neg entropy :  561.4695434570312\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1479, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3505, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5808, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  180  Loss :  0.5371198058128357 dsm :  1.3797693252563477 neg entropy :  560.0628051757812\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5972, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3643, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.3522, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  190  Loss :  0.5722470283508301 dsm :  0.17579501867294312 neg entropy :  558.3141479492188\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4588, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.5064, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  200  Loss :  0.627648115158081 dsm :  2.991741895675659 neg entropy :  561.1604614257812\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0337, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3337, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0712, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  210  Loss :  0.5397703051567078 dsm :  0.8342236876487732 neg entropy :  564.3936157226562\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1486, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3640, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.4411, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  220  Loss :  0.6130568981170654 dsm :  0.07226897776126862 neg entropy :  557.4343872070312\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3482, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8338, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  230  Loss :  0.5337638854980469 dsm :  0.7446264624595642 neg entropy :  560.825927734375\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2258, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.9315, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  240  Loss :  0.563694179058075 dsm :  3.8262226581573486 neg entropy :  557.1593627929688\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7127, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3870, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.5172, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  250  Loss :  0.6080284118652344 dsm :  0.1864013820886612 neg entropy :  559.2738037109375\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0439, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3358, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.7679, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  260  Loss :  0.5346419215202332 dsm :  1.900153398513794 neg entropy :  561.2808837890625\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0804, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3285, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.6515, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  270  Loss :  0.5801466107368469 dsm :  0.5969398021697998 neg entropy :  558.0443115234375\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6558, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2389, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(450.6194, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  280  Loss :  0.5137676000595093 dsm :  2.2853219509124756 neg entropy :  565.0824584960938\n",
      "{'edge_loss': tensor(0.0281, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0339, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.4752, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  290  Loss :  0.5708625912666321 dsm :  1.8020442724227905 neg entropy :  561.1104736328125\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4484, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.8170, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  300  Loss :  0.6004133224487305 dsm :  1.8049954175949097 neg entropy :  560.1432495117188\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4516, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.8427, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  310  Loss :  0.5779435038566589 dsm :  2.7226529121398926 neg entropy :  562.2619018554688\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4115, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3767, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8957, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  320  Loss :  0.43937739729881287 dsm :  0.819588840007782 neg entropy :  563.8108520507812\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6778, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.6000, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  330  Loss :  0.6278870105743408 dsm :  2.4734551906585693 neg entropy :  563.902587890625\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0041, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4413, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(523.2330, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  340  Loss :  0.5911332964897156 dsm :  1.3765186071395874 neg entropy :  553.50830078125\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3723, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4412, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.6646, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  350  Loss :  0.5527290105819702 dsm :  1.1747797727584839 neg entropy :  557.0014038085938\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4436, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1985, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  360  Loss :  0.5572440028190613 dsm :  0.3389277160167694 neg entropy :  559.6195068359375\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5171, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3525, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.1492, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  370  Loss :  0.548444926738739 dsm :  2.1470375061035156 neg entropy :  557.9462280273438\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1100, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.9334, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  380  Loss :  0.36359137296676636 dsm :  2.6638357639312744 neg entropy :  558.230712890625\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8516, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.6087, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  390  Loss :  0.6079633831977844 dsm :  0.6271265149116516 neg entropy :  558.1001586914062\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0863, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4758, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(533.4504, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  400  Loss :  0.5609504580497742 dsm :  0.4560888409614563 neg entropy :  557.1126098632812\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8261, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.5592, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  410  Loss :  0.5234072208404541 dsm :  0.7412538528442383 neg entropy :  565.1854858398438\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.9662, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3833, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.0697, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  420  Loss :  0.37810108065605164 dsm :  0.6010687947273254 neg entropy :  559.0537109375\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1971, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3109, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.7601, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  430  Loss :  0.5974671244621277 dsm :  2.7272231578826904 neg entropy :  551.6679077148438\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0891, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.1083, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  440  Loss :  0.6225318908691406 dsm :  3.118861436843872 neg entropy :  555.0128173828125\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0270, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.9819, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  450  Loss :  0.6393448114395142 dsm :  0.18202802538871765 neg entropy :  555.5897827148438\n",
      "{'edge_loss': tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1385, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4034, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.7572, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  460  Loss :  0.6030091643333435 dsm :  2.8828237056732178 neg entropy :  557.9747924804688\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4695, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.1422, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  470  Loss :  0.6116245985031128 dsm :  1.472899079322815 neg entropy :  558.2289428710938\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6865, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1888, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(429.0627, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  480  Loss :  0.5626026391983032 dsm :  1.5187867879867554 neg entropy :  560.9674072265625\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5316, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2831, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.2486, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  490  Loss :  0.5347015857696533 dsm :  0.20296119153499603 neg entropy :  560.1734008789062\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9012, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3584, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5144, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  500  Loss :  0.5915883779525757 dsm :  3.0231566429138184 neg entropy :  561.8275756835938\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3923, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.9172, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  510  Loss :  0.6168593168258667 dsm :  2.330702066421509 neg entropy :  554.2319946289062\n",
      "{'edge_loss': tensor(0.0393, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1975, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3330, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.1511, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  520  Loss :  0.6186205744743347 dsm :  2.4308297634124756 neg entropy :  559.6880493164062\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5564, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.0534, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  530  Loss :  0.58453369140625 dsm :  0.3386112153530121 neg entropy :  559.6952514648438\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0421, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3417, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.9033, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  540  Loss :  0.5999449491500854 dsm :  1.590814232826233 neg entropy :  556.921875\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3839, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5328, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(540.9493, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  550  Loss :  0.6731273531913757 dsm :  2.164177656173706 neg entropy :  559.09912109375\n",
      "{'edge_loss': tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7725, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4904, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.4213, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  560  Loss :  0.3581564128398895 dsm :  1.002130150794983 neg entropy :  561.429931640625\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0354, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.1830, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  570  Loss :  0.6255820989608765 dsm :  0.8834158778190613 neg entropy :  554.87841796875\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5193, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3326, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.5255, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  580  Loss :  0.6169794201850891 dsm :  0.5577492117881775 neg entropy :  559.0592651367188\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0797, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(458.6567, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  590  Loss :  0.5640190839767456 dsm :  1.8891420364379883 neg entropy :  562.0192260742188\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4143, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.2061, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  600  Loss :  0.5108625292778015 dsm :  0.7927488684654236 neg entropy :  563.4635620117188\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4790, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2031, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(435.3473, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  610  Loss :  0.6278747916221619 dsm :  2.612624406814575 neg entropy :  557.1397705078125\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1927, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.4104, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  620  Loss :  0.5892417430877686 dsm :  0.23326197266578674 neg entropy :  562.4633178710938\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3234, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4586, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.2562, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  630  Loss :  0.5207124948501587 dsm :  0.6335855722427368 neg entropy :  563.3348388671875\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0642, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4253, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.8449, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  640  Loss :  0.6124294400215149 dsm :  1.3585580587387085 neg entropy :  552.5414428710938\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.1483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4175, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.6386, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  650  Loss :  0.3855682611465454 dsm :  2.665367603302002 neg entropy :  558.2047119140625\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1319, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.2324, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  660  Loss :  0.509290337562561 dsm :  1.870689034461975 neg entropy :  560.3361206054688\n",
      "{'edge_loss': tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5339, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3203, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.1653, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  670  Loss :  0.6477079391479492 dsm :  0.026234552264213562 neg entropy :  553.373779296875\n",
      "{'edge_loss': tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6454, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4978, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.0521, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  680  Loss :  0.6182965636253357 dsm :  0.020913925021886826 neg entropy :  551.5406494140625\n",
      "{'edge_loss': tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6991, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4708, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.1315, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  690  Loss :  0.5173705220222473 dsm :  0.23481595516204834 neg entropy :  557.4689331054688\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2732, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1683, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(429.3045, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  700  Loss :  0.5244183540344238 dsm :  1.0100868940353394 neg entropy :  557.8868408203125\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6225, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3836, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.4021, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  710  Loss :  0.6276291012763977 dsm :  2.81728458404541 neg entropy :  553.3746948242188\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7623, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3671, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.1981, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  720  Loss :  0.5491943359375 dsm :  0.4057844281196594 neg entropy :  563.3839111328125\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4099, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.0505, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  730  Loss :  0.5786807537078857 dsm :  0.47788092494010925 neg entropy :  557.057373046875\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0377, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2933, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.6695, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  740  Loss :  0.5837578773498535 dsm :  0.8680295944213867 neg entropy :  558.3602294921875\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7695, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3564, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.3093, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  750  Loss :  0.5219258666038513 dsm :  0.25362393260002136 neg entropy :  557.94873046875\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3210, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3691, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.2668, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  760  Loss :  0.519339919090271 dsm :  1.6764878034591675 neg entropy :  561.3720092773438\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1352, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2539, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.9424, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  770  Loss :  0.41464728116989136 dsm :  2.8782553672790527 neg entropy :  555.4688720703125\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8053, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.0610, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  780  Loss :  0.40308207273483276 dsm :  1.9639443159103394 neg entropy :  561.8099975585938\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2568, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2900, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.8846, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  790  Loss :  0.4544818103313446 dsm :  1.7655600309371948 neg entropy :  564.6614379882812\n",
      "{'edge_loss': tensor(0.0242, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7951, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2557, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.9745, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  800  Loss :  0.7089595794677734 dsm :  1.4451749324798584 neg entropy :  545.9166259765625\n",
      "{'edge_loss': tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(237.6418, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4649, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1128, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  810  Loss :  0.593357503414154 dsm :  1.8729772567749023 neg entropy :  559.8504028320312\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3998, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3632, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.8121, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  820  Loss :  0.5804368853569031 dsm :  0.005897622089833021 neg entropy :  558.8317260742188\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7455, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3641, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.0400, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  830  Loss :  0.6836193799972534 dsm :  0.7041501998901367 neg entropy :  551.3588256835938\n",
      "{'edge_loss': tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6599, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4406, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.2993, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  840  Loss :  0.40043777227401733 dsm :  0.22245104610919952 neg entropy :  559.542724609375\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2757, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4358, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.7951, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  850  Loss :  0.385892778635025 dsm :  0.06771022826433182 neg entropy :  558.9547729492188\n",
      "{'edge_loss': tensor(0.0334, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0986, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3918, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5303, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  860  Loss :  0.5187269449234009 dsm :  0.08072877675294876 neg entropy :  555.7247924804688\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2940, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2577, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.0334, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  870  Loss :  0.4774547219276428 dsm :  0.872762143611908 neg entropy :  553.8306884765625\n",
      "{'edge_loss': tensor(0.0417, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0105, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5101, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.6966, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  880  Loss :  0.6200747489929199 dsm :  2.79504132270813 neg entropy :  553.9061889648438\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3009, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.4740, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  890  Loss :  0.5753909349441528 dsm :  0.28769180178642273 neg entropy :  558.45703125\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7207, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3587, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.5184, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  900  Loss :  0.5830864310264587 dsm :  1.4271893501281738 neg entropy :  559.9808959960938\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0027, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3498, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2802, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.6902, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  910  Loss :  0.6033146977424622 dsm :  1.0670160055160522 neg entropy :  555.0494384765625\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9602, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.4232, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  920  Loss :  0.6355433464050293 dsm :  2.2239134311676025 neg entropy :  554.1034545898438\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7025, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4761, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.7521, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  930  Loss :  0.44457104802131653 dsm :  1.3465455770492554 neg entropy :  556.5216674804688\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1992, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4262, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4731, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  940  Loss :  0.5460426807403564 dsm :  1.5713822841644287 neg entropy :  560.2000122070312\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9805, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4607, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.9976, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  950  Loss :  0.6584155559539795 dsm :  1.1611899137496948 neg entropy :  553.7101440429688\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1331, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3864, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.8026, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  960  Loss :  0.5583478212356567 dsm :  1.2607706785202026 neg entropy :  559.3009033203125\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9678, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.5717, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  970  Loss :  0.6577804684638977 dsm :  0.46904054284095764 neg entropy :  552.9269409179688\n",
      "{'edge_loss': tensor(0.0444, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6270, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4134, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.8948, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  980  Loss :  0.5414031744003296 dsm :  1.0650767087936401 neg entropy :  560.80908203125\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1915, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2901, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.6955, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  990  Loss :  0.58123779296875 dsm :  0.028483420610427856 neg entropy :  559.0299682617188\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0032, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0709, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.9324, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1000  Loss :  0.518679141998291 dsm :  3.3857266902923584 neg entropy :  552.8976440429688\n",
      "{'edge_loss': tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0133, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4593, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5219, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.2895, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1010  Loss :  0.5866291522979736 dsm :  1.306967854499817 neg entropy :  556.5103759765625\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9422, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.0075, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1020  Loss :  0.5301539897918701 dsm :  0.8514863848686218 neg entropy :  562.3886108398438\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2138, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2834, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.2483, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1030  Loss :  0.5930810570716858 dsm :  1.8699743747711182 neg entropy :  560.7962646484375\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7200, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3812, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.0188, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1040  Loss :  0.5558630228042603 dsm :  0.42066463828086853 neg entropy :  559.6364135742188\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0033, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9525, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3166, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.6128, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1050  Loss :  0.568408191204071 dsm :  2.278294324874878 neg entropy :  562.91650390625\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4591, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2938, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.3745, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1060  Loss :  0.6041621565818787 dsm :  0.8697659373283386 neg entropy :  564.2613525390625\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5889, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.2096, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1070  Loss :  0.4876447021961212 dsm :  0.08898504078388214 neg entropy :  560.6613159179688\n",
      "{'edge_loss': tensor(0.0284, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9245, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3457, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.0133, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1080  Loss :  0.6409762501716614 dsm :  2.2463722229003906 neg entropy :  554.5772705078125\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3446, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3711, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.7978, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1090  Loss :  0.24111133813858032 dsm :  0.2035694420337677 neg entropy :  558.231689453125\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0304, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1506, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3553, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.6911, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1100  Loss :  0.592393696308136 dsm :  1.9545526504516602 neg entropy :  560.2340698242188\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5725, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3374, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0836, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1110  Loss :  0.5990651249885559 dsm :  1.8929262161254883 neg entropy :  557.1105346679688\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4981, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.4657, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1120  Loss :  0.5797144174575806 dsm :  0.8290382623672485 neg entropy :  559.0198364257812\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1020, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3894, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.0643, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1130  Loss :  0.5786910653114319 dsm :  5.829651355743408 neg entropy :  564.6110229492188\n",
      "{'edge_loss': tensor(0.0313, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8365, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3450, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.4266, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1140  Loss :  0.09403447061777115 dsm :  0.5155459642410278 neg entropy :  559.3607788085938\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0472, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8361, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3498, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.9637, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1150  Loss :  0.5993732213973999 dsm :  1.5881160497665405 neg entropy :  558.7184448242188\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5298, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.9590, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1160  Loss :  0.5957302451133728 dsm :  0.7876303791999817 neg entropy :  557.3378295898438\n",
      "{'edge_loss': tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8964, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3778, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.8945, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1170  Loss :  0.6435018181800842 dsm :  3.544698715209961 neg entropy :  552.1256103515625\n",
      "{'edge_loss': tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3113, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3106, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.9266, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1180  Loss :  0.5518506765365601 dsm :  0.44779059290885925 neg entropy :  562.8827514648438\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8854, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.8513, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1190  Loss :  0.5702003240585327 dsm :  1.4181727170944214 neg entropy :  558.1316528320312\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4476, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4147, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.9806, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1200  Loss :  0.5287682414054871 dsm :  0.6200873851776123 neg entropy :  565.5460815429688\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3098, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(529.4326, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1210  Loss :  0.5580599904060364 dsm :  0.7267784476280212 neg entropy :  561.0860595703125\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4858, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3488, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.3458, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1220  Loss :  0.2972998321056366 dsm :  1.9922840595245361 neg entropy :  559.772216796875\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0302, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8879, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4431, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.3393, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1230  Loss :  0.5305771231651306 dsm :  2.72949481010437 neg entropy :  561.5463256835938\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3666, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2735, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.3821, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1240  Loss :  0.4884788393974304 dsm :  0.22989816963672638 neg entropy :  557.880859375\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0140, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8507, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3333, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.9876, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1250  Loss :  0.5583519339561462 dsm :  0.6684295535087585 neg entropy :  558.9210205078125\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8983, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4610, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.2389, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1260  Loss :  0.6225573420524597 dsm :  0.31052476167678833 neg entropy :  555.6378784179688\n",
      "{'edge_loss': tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1023, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5136, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.0197, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1270  Loss :  0.5331838726997375 dsm :  1.053171992301941 neg entropy :  560.4586791992188\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6388, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3838, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(525.4858, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1280  Loss :  0.5741892457008362 dsm :  1.3790580034255981 neg entropy :  556.6389770507812\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5239, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5752, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1290  Loss :  0.5929271578788757 dsm :  1.7119110822677612 neg entropy :  555.8464965820312\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9910, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.2169, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1300  Loss :  0.5909454822540283 dsm :  0.11417704820632935 neg entropy :  558.1856689453125\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1042, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.5216, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1310  Loss :  0.44791126251220703 dsm :  6.085003852844238 neg entropy :  556.4445190429688\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9587, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4201, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.0677, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1320  Loss :  0.3639552593231201 dsm :  1.1358424425125122 neg entropy :  561.8377685546875\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7137, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2453, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.4898, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1330  Loss :  0.43569615483283997 dsm :  0.7833577990531921 neg entropy :  561.7598266601562\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0066, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3009, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0894, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1340  Loss :  0.6154014468193054 dsm :  0.5157743692398071 neg entropy :  557.4237670898438\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9068, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.9351, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1350  Loss :  0.6081710457801819 dsm :  6.327519416809082 neg entropy :  562.4115600585938\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1881, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2947, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.6369, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1360  Loss :  0.5598055720329285 dsm :  0.6004905104637146 neg entropy :  561.717041015625\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0245, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3120, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.0117, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1370  Loss :  0.5400118827819824 dsm :  0.10849685966968536 neg entropy :  558.9987182617188\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1021, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.5263, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1380  Loss :  0.5944470167160034 dsm :  2.071794033050537 neg entropy :  560.3168334960938\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7018, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3760, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.8252, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1390  Loss :  0.41036924719810486 dsm :  2.2732129096984863 neg entropy :  560.6417236328125\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0897, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3665, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.1268, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1400  Loss :  0.6550071239471436 dsm :  5.02796745300293 neg entropy :  559.5761108398438\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8524, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(509.7951, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1410  Loss :  0.558387279510498 dsm :  2.1043577194213867 neg entropy :  560.8532104492188\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3582, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3673, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.5852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1420  Loss :  0.6123121976852417 dsm :  1.95037043094635 neg entropy :  553.5734252929688\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.4685, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3342, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.8549, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1430  Loss :  0.38755062222480774 dsm :  3.5839309692382812 neg entropy :  563.0961303710938\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0413, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3440, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.5635, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1440  Loss :  0.42592841386795044 dsm :  2.8043036460876465 neg entropy :  557.95068359375\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6177, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.2449, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1450  Loss :  0.6267421245574951 dsm :  4.543748378753662 neg entropy :  560.3629150390625\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4395, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3412, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.8620, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1460  Loss :  0.4861023724079132 dsm :  0.41882404685020447 neg entropy :  564.1517944335938\n",
      "{'edge_loss': tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9393, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3545, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.0497, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1470  Loss :  0.5848561525344849 dsm :  1.7201921939849854 neg entropy :  561.2913208007812\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3215, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3792, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.2112, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1480  Loss :  0.5948247909545898 dsm :  1.707338571548462 neg entropy :  560.1513061523438\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0039, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4039, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4186, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.2019, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1490  Loss :  0.6194893717765808 dsm :  1.8889579772949219 neg entropy :  554.44580078125\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0907, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4440, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.5026, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1500  Loss :  0.6498816013336182 dsm :  1.5573259592056274 neg entropy :  553.8331298828125\n",
      "{'edge_loss': tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6207, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4260, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.9642, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1510  Loss :  0.582238495349884 dsm :  1.7589889764785767 neg entropy :  561.4503173828125\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4988, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3133, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.7462, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1520  Loss :  0.5571544170379639 dsm :  0.8493161201477051 neg entropy :  557.9513549804688\n",
      "{'edge_loss': tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5445, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3038, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.1216, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1530  Loss :  0.5905104279518127 dsm :  2.102294683456421 neg entropy :  556.4242553710938\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2113, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4041, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(510.1137, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1540  Loss :  0.5439963340759277 dsm :  2.4989070892333984 neg entropy :  553.0010986328125\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5708, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3867, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.7603, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1550  Loss :  0.5876975059509277 dsm :  2.019542694091797 neg entropy :  562.3036499023438\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0865, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.4767, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1560  Loss :  0.5154233574867249 dsm :  1.1255139112472534 neg entropy :  560.2741088867188\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3064, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3147, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.5505, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1570  Loss :  0.5308327078819275 dsm :  1.244979739189148 neg entropy :  556.0363159179688\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3441, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3184, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(449.4771, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1580  Loss :  0.5399408340454102 dsm :  1.5781989097595215 neg entropy :  562.7916259765625\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2305, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.5758, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1590  Loss :  0.6077830791473389 dsm :  3.259722948074341 neg entropy :  556.8049926757812\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7129, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4289, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.6867, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1600  Loss :  0.38619548082351685 dsm :  3.750680685043335 neg entropy :  563.6729125976562\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2471, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.6332, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1610  Loss :  0.5924288630485535 dsm :  0.3217882513999939 neg entropy :  564.4483032226562\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5164, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(536.0294, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1620  Loss :  0.3809979557991028 dsm :  0.04131466895341873 neg entropy :  559.0827026367188\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7509, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3054, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.0083, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1630  Loss :  0.5447825789451599 dsm :  2.256063461303711 neg entropy :  562.2321166992188\n",
      "{'edge_loss': tensor(0.0322, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3021, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3035, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.3795, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1640  Loss :  0.5306896567344666 dsm :  2.725482940673828 neg entropy :  561.02978515625\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5220, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.2345, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1650  Loss :  0.5938270688056946 dsm :  3.546879529953003 neg entropy :  557.8756103515625\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8111, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3551, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.8119, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1660  Loss :  0.6175253987312317 dsm :  2.989469051361084 neg entropy :  559.8551635742188\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2088, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4128, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.2787, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1670  Loss :  0.6193354725837708 dsm :  0.041133034974336624 neg entropy :  560.4100341796875\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6757, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3288, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.9426, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1680  Loss :  0.5554922819137573 dsm :  0.3186124563217163 neg entropy :  558.2730712890625\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8927, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.6943, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1690  Loss :  0.562590479850769 dsm :  2.1777443885803223 neg entropy :  562.1995239257812\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.7211, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5500, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1700  Loss :  0.6100786924362183 dsm :  1.7739378213882446 neg entropy :  557.5416870117188\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6279, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4419, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.2682, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1710  Loss :  0.5709127187728882 dsm :  2.438095808029175 neg entropy :  564.186279296875\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.3020, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.5013, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1720  Loss :  0.5952056050300598 dsm :  0.7189823985099792 neg entropy :  561.5238037109375\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3028, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3773, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.2431, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1730  Loss :  0.5325373411178589 dsm :  0.729533314704895 neg entropy :  561.6430053710938\n",
      "{'edge_loss': tensor(0.0295, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0247, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4615, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.8242, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1740  Loss :  0.5458683371543884 dsm :  1.3531097173690796 neg entropy :  558.7982788085938\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4644, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4470, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.9434, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1750  Loss :  0.38961875438690186 dsm :  0.5423993468284607 neg entropy :  563.4401245117188\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5229, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3209, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.1421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1760  Loss :  0.5861110091209412 dsm :  1.3810389041900635 neg entropy :  552.9336547851562\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0466, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.2995, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1770  Loss :  0.5887724757194519 dsm :  3.3379929065704346 neg entropy :  562.6950073242188\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2534, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3817, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.0560, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1780  Loss :  0.6154342889785767 dsm :  1.6717246770858765 neg entropy :  559.90380859375\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6061, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2971, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.4142, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1790  Loss :  0.5703759789466858 dsm :  3.9032628536224365 neg entropy :  562.7346801757812\n",
      "{'edge_loss': tensor(0.0331, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5181, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.1601, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1800  Loss :  0.5679460763931274 dsm :  0.4150718152523041 neg entropy :  561.3060913085938\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0307, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.1695, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1810  Loss :  0.4551340341567993 dsm :  0.617840588092804 neg entropy :  555.8313598632812\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9598, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3997, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.4875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1820  Loss :  0.5856264233589172 dsm :  4.059568881988525 neg entropy :  556.8516845703125\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9039, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2853, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.1367, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1830  Loss :  0.5785068869590759 dsm :  2.3838446140289307 neg entropy :  553.3634643554688\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2959, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3479, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.5028, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1840  Loss :  0.5010030269622803 dsm :  1.669851303100586 neg entropy :  563.916748046875\n",
      "{'edge_loss': tensor(0.0291, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1963, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.1743, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1850  Loss :  0.6828761696815491 dsm :  0.8053514361381531 neg entropy :  551.5853881835938\n",
      "{'edge_loss': tensor(0.0456, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2762, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4436, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.4554, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1860  Loss :  0.5395152568817139 dsm :  1.2759393453598022 neg entropy :  562.233642578125\n",
      "{'edge_loss': tensor(0.0314, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6504, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4099, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.4985, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1870  Loss :  0.6065049767494202 dsm :  2.068443775177002 neg entropy :  558.6163330078125\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3771, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3071, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.3938, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1880  Loss :  0.5834413170814514 dsm :  0.9043733477592468 neg entropy :  554.89794921875\n",
      "{'edge_loss': tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3307, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.9348, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1890  Loss :  0.5137558579444885 dsm :  1.7658666372299194 neg entropy :  559.828369140625\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5340, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3145, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.3237, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1900  Loss :  0.5685731172561646 dsm :  0.7048531174659729 neg entropy :  557.0479125976562\n",
      "{'edge_loss': tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5166, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.2559, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1910  Loss :  0.6182739734649658 dsm :  1.6258305311203003 neg entropy :  558.44921875\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0330, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3696, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.5009, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1920  Loss :  0.5083895325660706 dsm :  0.15983068943023682 neg entropy :  563.1629028320312\n",
      "{'edge_loss': tensor(0.0300, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8790, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3730, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.4485, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1930  Loss :  0.5441209077835083 dsm :  0.2221859246492386 neg entropy :  561.2750244140625\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4612, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4576, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(517.1078, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1940  Loss :  0.673004686832428 dsm :  1.942272424697876 neg entropy :  554.3662109375\n",
      "{'edge_loss': tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6256, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4405, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.3726, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1950  Loss :  0.5570634007453918 dsm :  0.30511823296546936 neg entropy :  563.8308715820312\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9231, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2924, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.0717, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1960  Loss :  0.5921652317047119 dsm :  2.346440076828003 neg entropy :  557.7418823242188\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0985, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.0378, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1970  Loss :  0.6475845575332642 dsm :  1.2546590566635132 neg entropy :  562.5203247070312\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5042, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4957, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(525.7924, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1980  Loss :  0.4170312285423279 dsm :  1.5284500122070312 neg entropy :  556.234130859375\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3495, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2704, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(462.9857, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  1990  Loss :  0.5533874034881592 dsm :  0.8824202418327332 neg entropy :  558.9381103515625\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8277, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3142, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.9259, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2000  Loss :  0.6117027401924133 dsm :  3.9193711280822754 neg entropy :  557.7890014648438\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7626, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.3109, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2010  Loss :  0.44435349106788635 dsm :  0.44883403182029724 neg entropy :  551.8655395507812\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7718, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4602, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.8871, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2020  Loss :  0.6422317624092102 dsm :  3.5363833904266357 neg entropy :  555.5137329101562\n",
      "{'edge_loss': tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2914, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.0830, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2030  Loss :  0.5526902675628662 dsm :  3.924687623977661 neg entropy :  562.6708374023438\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6873, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3552, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9331, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2040  Loss :  0.5565605759620667 dsm :  0.23143163323402405 neg entropy :  558.1369018554688\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2880, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3445, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9442, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2050  Loss :  0.5967994332313538 dsm :  2.2849528789520264 neg entropy :  559.3480834960938\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6525, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3487, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.9967, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2060  Loss :  0.7533576488494873 dsm :  1.4207161664962769 neg entropy :  549.7021484375\n",
      "{'edge_loss': tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5997, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4853, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.4557, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2070  Loss :  0.5999981164932251 dsm :  3.6315505504608154 neg entropy :  555.6812744140625\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4553, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.0067, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2080  Loss :  0.6767760515213013 dsm :  1.1439570188522339 neg entropy :  552.2074584960938\n",
      "{'edge_loss': tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1684, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4545, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.4165, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2090  Loss :  0.5707830786705017 dsm :  0.5056001543998718 neg entropy :  560.1549072265625\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7321, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4115, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.1551, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2100  Loss :  0.5488814115524292 dsm :  1.3075052499771118 neg entropy :  555.3245239257812\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3291, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3608, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.7856, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2110  Loss :  0.5314638018608093 dsm :  0.5411362648010254 neg entropy :  560.2970581054688\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6959, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2932, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.8152, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2120  Loss :  0.34124231338500977 dsm :  1.0583540201187134 neg entropy :  564.6591796875\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8753, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2594, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.8608, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2130  Loss :  0.5680795311927795 dsm :  2.838286876678467 neg entropy :  561.558349609375\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6830, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2555, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(443.5991, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2140  Loss :  0.4127407371997833 dsm :  0.004522215574979782 neg entropy :  556.13818359375\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5979, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2791, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(450.7267, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2150  Loss :  0.430743008852005 dsm :  0.23733071982860565 neg entropy :  553.0924072265625\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.8669, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3789, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.6678, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2160  Loss :  0.5570364594459534 dsm :  1.7478224039077759 neg entropy :  560.0685424804688\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5594, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3363, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.9463, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2170  Loss :  0.5848987698554993 dsm :  1.6297048330307007 neg entropy :  560.90283203125\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0036, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7582, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2843, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.3941, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2180  Loss :  0.6460491418838501 dsm :  1.8685814142227173 neg entropy :  552.4723510742188\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7740, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0284, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2190  Loss :  0.6451478004455566 dsm :  2.299795389175415 neg entropy :  552.9606323242188\n",
      "{'edge_loss': tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7281, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2977, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.8965, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2200  Loss :  0.586650013923645 dsm :  1.508180022239685 neg entropy :  554.0372924804688\n",
      "{'edge_loss': tensor(0.0359, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2029, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3926, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(499.4604, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2210  Loss :  0.5530757904052734 dsm :  1.1992543935775757 neg entropy :  564.8546752929688\n",
      "{'edge_loss': tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9954, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2985, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.4764, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2220  Loss :  0.6361870765686035 dsm :  1.4991626739501953 neg entropy :  559.9537353515625\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3183, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4260, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.6877, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2230  Loss :  0.41479629278182983 dsm :  1.3729568719863892 neg entropy :  564.4474487304688\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0134, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6530, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3027, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.1080, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2240  Loss :  0.42901647090911865 dsm :  1.422094702720642 neg entropy :  555.5850830078125\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8741, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4586, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.5446, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2250  Loss :  0.6011643409729004 dsm :  1.9870096445083618 neg entropy :  560.3606567382812\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0118, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.4070, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2260  Loss :  0.5389870405197144 dsm :  1.947351098060608 neg entropy :  565.291015625\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8937, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3451, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.4564, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2270  Loss :  0.4837392568588257 dsm :  0.6081412434577942 neg entropy :  547.70654296875\n",
      "{'edge_loss': tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(238.9492, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4338, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.1585, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2280  Loss :  0.5735039710998535 dsm :  2.112818479537964 neg entropy :  563.8732299804688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9902, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.1785, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2290  Loss :  0.4364194869995117 dsm :  2.707151412963867 neg entropy :  556.1069946289062\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4928, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4259, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(521.4224, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2300  Loss :  0.4518643915653229 dsm :  0.3880556523799896 neg entropy :  561.4337158203125\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6953, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.0819, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2310  Loss :  0.5939940810203552 dsm :  2.4918458461761475 neg entropy :  560.0101318359375\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6210, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3712, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.7530, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2320  Loss :  0.4123902916908264 dsm :  1.5489695072174072 neg entropy :  553.595947265625\n",
      "{'edge_loss': tensor(0.0339, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0142, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0952, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4516, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.5806, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2330  Loss :  0.5868072509765625 dsm :  2.9515931606292725 neg entropy :  559.5684814453125\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0800, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4038, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9918, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2340  Loss :  0.6169227957725525 dsm :  0.5279489159584045 neg entropy :  556.5418090820312\n",
      "{'edge_loss': tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0888, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4302, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.3438, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2350  Loss :  0.6059922575950623 dsm :  2.379793882369995 neg entropy :  564.4584350585938\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0017, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1715, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3253, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.9627, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2360  Loss :  0.5934701561927795 dsm :  0.4975135922431946 neg entropy :  553.904541015625\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.5900, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4120, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.8866, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2370  Loss :  0.5249705910682678 dsm :  1.8413190841674805 neg entropy :  565.7122192382812\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4273, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2896, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.7646, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2380  Loss :  0.38633808493614197 dsm :  0.006246412638574839 neg entropy :  559.6681518554688\n",
      "{'edge_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7352, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4055, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.7437, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2390  Loss :  0.5327145457267761 dsm :  1.5872220993041992 neg entropy :  558.7902221679688\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2337, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3206, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.6954, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2400  Loss :  0.41179192066192627 dsm :  0.2075294703245163 neg entropy :  559.1061401367188\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8760, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3174, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.5574, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2410  Loss :  0.7718388438224792 dsm :  9.578526496887207 neg entropy :  557.1631469726562\n",
      "{'edge_loss': tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0044, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8683, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4032, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.4437, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2420  Loss :  0.4708186388015747 dsm :  0.1095716580748558 neg entropy :  562.9967651367188\n",
      "{'edge_loss': tensor(0.0282, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6672, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2188, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.2691, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2430  Loss :  0.5169848799705505 dsm :  1.1660736799240112 neg entropy :  563.5791015625\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9386, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.6113, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2440  Loss :  0.588706910610199 dsm :  0.7630933523178101 neg entropy :  557.8250122070312\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1780, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4312, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.7627, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2450  Loss :  0.5386764407157898 dsm :  2.0934250354766846 neg entropy :  563.1652221679688\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8506, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3825, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(512.4370, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2460  Loss :  0.5682713389396667 dsm :  0.04325518757104874 neg entropy :  555.7579956054688\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4944, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3907, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.2122, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2470  Loss :  0.6605780124664307 dsm :  2.9823901653289795 neg entropy :  549.7120971679688\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.7726, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3694, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.2755, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2480  Loss :  0.6800159811973572 dsm :  0.9815158247947693 neg entropy :  555.4376831054688\n",
      "{'edge_loss': tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0025, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8295, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4697, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.9359, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  94  Batch :  2490  Loss :  0.6201369762420654 dsm :  1.9564560651779175 neg entropy :  562.7169799804688\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8857, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4484, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.5754, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0'), 'node_loss': tensor(0.0003, device='cuda:0'), 'kld_loss': tensor(246.3784, device='cuda:0'), 'perm_loss': tensor(1.3270, device='cuda:0'), 'property_loss': tensor(487.0053, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  0 Loss sum :  0.5113815069198608 dsm :  1.6079330444335938 neg entropy :  566.0470581054688\n",
      "{'edge_loss': tensor(0.0259, device='cuda:0'), 'node_loss': tensor(-0.0151, device='cuda:0'), 'kld_loss': tensor(248.6075, device='cuda:0'), 'perm_loss': tensor(1.3607, device='cuda:0'), 'property_loss': tensor(509.3781, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  10 Loss sum :  0.3092349171638489 dsm :  0.8561161160469055 neg entropy :  570.6876831054688\n",
      "{'edge_loss': tensor(0.0245, device='cuda:0'), 'node_loss': tensor(0.0016, device='cuda:0'), 'kld_loss': tensor(247.5709, device='cuda:0'), 'perm_loss': tensor(1.2784, device='cuda:0'), 'property_loss': tensor(496.0327, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  20 Loss sum :  0.48026126623153687 dsm :  3.3759002685546875 neg entropy :  570.0636596679688\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(248.4145, device='cuda:0'), 'perm_loss': tensor(1.2587, device='cuda:0'), 'property_loss': tensor(478.4761, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  30 Loss sum :  0.5032811760902405 dsm :  0.602306067943573 neg entropy :  570.6050415039062\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(247.3622, device='cuda:0'), 'perm_loss': tensor(1.3860, device='cuda:0'), 'property_loss': tensor(505.1432, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  40 Loss sum :  0.5412090420722961 dsm :  2.2122511863708496 neg entropy :  568.64013671875\n",
      "{'edge_loss': tensor(0.0287, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(246.2787, device='cuda:0'), 'perm_loss': tensor(1.3010, device='cuda:0'), 'property_loss': tensor(472.4775, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  50 Loss sum :  0.4792326092720032 dsm :  0.013483325950801373 neg entropy :  564.5156860351562\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0'), 'node_loss': tensor(0.0023, device='cuda:0'), 'kld_loss': tensor(245.7591, device='cuda:0'), 'perm_loss': tensor(1.5121, device='cuda:0'), 'property_loss': tensor(529.3012, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  60 Loss sum :  0.639301061630249 dsm :  0.01475608628243208 neg entropy :  559.2891845703125\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.2894, device='cuda:0'), 'perm_loss': tensor(1.2495, device='cuda:0'), 'property_loss': tensor(457.4739, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  70 Loss sum :  0.5133918523788452 dsm :  2.2360758781433105 neg entropy :  565.2921142578125\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(247.4342, device='cuda:0'), 'perm_loss': tensor(1.4479, device='cuda:0'), 'property_loss': tensor(527.4810, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  80 Loss sum :  0.5656938552856445 dsm :  1.0274161100387573 neg entropy :  566.1141357421875\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(0.0020, device='cuda:0'), 'kld_loss': tensor(245.3498, device='cuda:0'), 'perm_loss': tensor(1.3495, device='cuda:0'), 'property_loss': tensor(489.0167, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  90 Loss sum :  0.590430736541748 dsm :  3.2789204120635986 neg entropy :  562.47998046875\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(245.2270, device='cuda:0'), 'perm_loss': tensor(1.4241, device='cuda:0'), 'property_loss': tensor(526.3542, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  100 Loss sum :  0.5311548709869385 dsm :  1.4745477437973022 neg entropy :  563.73046875\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(247.6843, device='cuda:0'), 'perm_loss': tensor(1.3904, device='cuda:0'), 'property_loss': tensor(522.0250, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  110 Loss sum :  0.5383889675140381 dsm :  2.4244422912597656 neg entropy :  567.861328125\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.8630, device='cuda:0'), 'perm_loss': tensor(1.2979, device='cuda:0'), 'property_loss': tensor(485.5399, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  120 Loss sum :  0.5692690014839172 dsm :  8.116209030151367 neg entropy :  567.3529663085938\n",
      "{'edge_loss': tensor(0.0297, device='cuda:0'), 'node_loss': tensor(0.0010, device='cuda:0'), 'kld_loss': tensor(248.5444, device='cuda:0'), 'perm_loss': tensor(1.3509, device='cuda:0'), 'property_loss': tensor(491.5437, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  130 Loss sum :  0.502875566482544 dsm :  0.44778186082839966 neg entropy :  570.06005859375\n",
      "{'edge_loss': tensor(0.0298, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(248.3613, device='cuda:0'), 'perm_loss': tensor(1.2692, device='cuda:0'), 'property_loss': tensor(470.5526, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  140 Loss sum :  0.3652353286743164 dsm :  3.561767578125 neg entropy :  569.3085327148438\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0'), 'node_loss': tensor(-0.0486, device='cuda:0'), 'kld_loss': tensor(245.3425, device='cuda:0'), 'perm_loss': tensor(1.4771, device='cuda:0'), 'property_loss': tensor(514.8442, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  150 Loss sum :  0.08868831396102905 dsm :  1.0983350276947021 neg entropy :  558.4530639648438\n",
      "{'edge_loss': tensor(0.0301, device='cuda:0'), 'node_loss': tensor(-0.0156, device='cuda:0'), 'kld_loss': tensor(248.6123, device='cuda:0'), 'perm_loss': tensor(1.2774, device='cuda:0'), 'property_loss': tensor(481.2450, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  160 Loss sum :  0.3343362808227539 dsm :  0.4470236003398895 neg entropy :  570.9759521484375\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0'), 'node_loss': tensor(-0.0144, device='cuda:0'), 'kld_loss': tensor(245.1835, device='cuda:0'), 'perm_loss': tensor(1.2538, device='cuda:0'), 'property_loss': tensor(447.0988, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  170 Loss sum :  0.393028199672699 dsm :  1.5328720808029175 neg entropy :  561.219970703125\n",
      "{'edge_loss': tensor(0.0257, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(248.7860, device='cuda:0'), 'perm_loss': tensor(1.3080, device='cuda:0'), 'property_loss': tensor(493.2286, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  180 Loss sum :  0.4715802073478699 dsm :  2.0752503871917725 neg entropy :  571.9547729492188\n",
      "{'edge_loss': tensor(0.0289, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(250.2324, device='cuda:0'), 'perm_loss': tensor(1.3102, device='cuda:0'), 'property_loss': tensor(506.7374, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  190 Loss sum :  0.5455924272537231 dsm :  5.991204738616943 neg entropy :  576.9503784179688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(249.3260, device='cuda:0'), 'perm_loss': tensor(1.2847, device='cuda:0'), 'property_loss': tensor(468.9612, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  200 Loss sum :  0.559816300868988 dsm :  2.1975247859954834 neg entropy :  571.263916015625\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0018, device='cuda:0'), 'kld_loss': tensor(245.7855, device='cuda:0'), 'perm_loss': tensor(1.3784, device='cuda:0'), 'property_loss': tensor(501.5929, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  210 Loss sum :  0.5569806694984436 dsm :  0.6857998967170715 neg entropy :  562.2514038085938\n",
      "{'edge_loss': tensor(0.0288, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(246.2937, device='cuda:0'), 'perm_loss': tensor(1.3303, device='cuda:0'), 'property_loss': tensor(491.3667, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  220 Loss sum :  0.5235849618911743 dsm :  4.1218342781066895 neg entropy :  565.7003173828125\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0'), 'node_loss': tensor(-0.0158, device='cuda:0'), 'kld_loss': tensor(244.6169, device='cuda:0'), 'perm_loss': tensor(1.3772, device='cuda:0'), 'property_loss': tensor(506.2121, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  230 Loss sum :  0.35870125889778137 dsm :  0.6941335797309875 neg entropy :  560.8875122070312\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(245.5498, device='cuda:0'), 'perm_loss': tensor(1.4268, device='cuda:0'), 'property_loss': tensor(517.7332, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  240 Loss sum :  0.3762699365615845 dsm :  1.158461093902588 neg entropy :  563.7278442382812\n",
      "{'edge_loss': tensor(0.0291, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9976, device='cuda:0'), 'perm_loss': tensor(1.2368, device='cuda:0'), 'property_loss': tensor(464.9915, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  250 Loss sum :  0.48469629883766174 dsm :  0.7339566946029663 neg entropy :  567.5310668945312\n",
      "{'edge_loss': tensor(0.0246, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(251.2949, device='cuda:0'), 'perm_loss': tensor(1.3900, device='cuda:0'), 'property_loss': tensor(525.6052, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  260 Loss sum :  0.4610545337200165 dsm :  1.4281859397888184 neg entropy :  577.054443359375\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0'), 'node_loss': tensor(0.0021, device='cuda:0'), 'kld_loss': tensor(248.5827, device='cuda:0'), 'perm_loss': tensor(1.3462, device='cuda:0'), 'property_loss': tensor(495.6145, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  270 Loss sum :  0.5690188407897949 dsm :  3.3305423259735107 neg entropy :  566.9274291992188\n",
      "{'edge_loss': tensor(0.0279, device='cuda:0'), 'node_loss': tensor(0.0012, device='cuda:0'), 'kld_loss': tensor(246.9365, device='cuda:0'), 'perm_loss': tensor(1.4306, device='cuda:0'), 'property_loss': tensor(534.6133, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  280 Loss sum :  0.5393438935279846 dsm :  4.812318325042725 neg entropy :  565.9137573242188\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0'), 'node_loss': tensor(-0.0160, device='cuda:0'), 'kld_loss': tensor(245.0403, device='cuda:0'), 'perm_loss': tensor(1.4094, device='cuda:0'), 'property_loss': tensor(495.7788, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  290 Loss sum :  0.38252782821655273 dsm :  0.5001813769340515 neg entropy :  558.5429077148438\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0'), 'node_loss': tensor(0.0035, device='cuda:0'), 'kld_loss': tensor(248.1779, device='cuda:0'), 'perm_loss': tensor(1.3530, device='cuda:0'), 'property_loss': tensor(471.6162, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  300 Loss sum :  0.6025255918502808 dsm :  0.3835020363330841 neg entropy :  564.707763671875\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(0.0028, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.2360, device='cuda:0'), 'property_loss': tensor(463.6641, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  310 Loss sum :  0.555561900138855 dsm :  2.056051254272461 neg entropy :  566.9277954101562\n",
      "{'edge_loss': tensor(0.0296, device='cuda:0'), 'node_loss': tensor(-0.0143, device='cuda:0'), 'kld_loss': tensor(249.3077, device='cuda:0'), 'perm_loss': tensor(1.3125, device='cuda:0'), 'property_loss': tensor(496.7330, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  320 Loss sum :  0.3666863441467285 dsm :  2.5396182537078857 neg entropy :  570.5037841796875\n",
      "{'edge_loss': tensor(0.0294, device='cuda:0'), 'node_loss': tensor(0.0013, device='cuda:0'), 'kld_loss': tensor(247.4953, device='cuda:0'), 'perm_loss': tensor(1.4422, device='cuda:0'), 'property_loss': tensor(536.5993, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  330 Loss sum :  0.5350255966186523 dsm :  2.688053607940674 neg entropy :  566.6505737304688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(245.5988, device='cuda:0'), 'perm_loss': tensor(1.3208, device='cuda:0'), 'property_loss': tensor(475.9643, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  340 Loss sum :  0.38757073879241943 dsm :  1.1294662952423096 neg entropy :  562.9228515625\n",
      "{'edge_loss': tensor(0.0357, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(245.0887, device='cuda:0'), 'perm_loss': tensor(1.2910, device='cuda:0'), 'property_loss': tensor(471.3932, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  350 Loss sum :  0.5627605319023132 dsm :  1.3853240013122559 neg entropy :  561.8796997070312\n",
      "{'edge_loss': tensor(0.0258, device='cuda:0'), 'node_loss': tensor(0.0005, device='cuda:0'), 'kld_loss': tensor(248.4885, device='cuda:0'), 'perm_loss': tensor(1.3163, device='cuda:0'), 'property_loss': tensor(508.0274, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  360 Loss sum :  0.4633060395717621 dsm :  1.2016931772232056 neg entropy :  570.73583984375\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0'), 'node_loss': tensor(-0.0152, device='cuda:0'), 'kld_loss': tensor(247.3157, device='cuda:0'), 'perm_loss': tensor(1.2195, device='cuda:0'), 'property_loss': tensor(469.3805, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  370 Loss sum :  0.34719768166542053 dsm :  0.22106850147247314 neg entropy :  566.6982421875\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(247.8457, device='cuda:0'), 'perm_loss': tensor(1.2760, device='cuda:0'), 'property_loss': tensor(471.5507, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  380 Loss sum :  0.5234501361846924 dsm :  1.859840750694275 neg entropy :  567.0247192382812\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0'), 'node_loss': tensor(0.0006, device='cuda:0'), 'kld_loss': tensor(245.9707, device='cuda:0'), 'perm_loss': tensor(1.4221, device='cuda:0'), 'property_loss': tensor(515.1387, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  390 Loss sum :  0.5443296432495117 dsm :  0.2170698195695877 neg entropy :  562.8146362304688\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0'), 'node_loss': tensor(0.0009, device='cuda:0'), 'kld_loss': tensor(247.2000, device='cuda:0'), 'perm_loss': tensor(1.3543, device='cuda:0'), 'property_loss': tensor(488.2715, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  400 Loss sum :  0.5582225322723389 dsm :  4.838932514190674 neg entropy :  567.54443359375\n",
      "{'edge_loss': tensor(0.0327, device='cuda:0'), 'node_loss': tensor(0.0014, device='cuda:0'), 'kld_loss': tensor(244.1462, device='cuda:0'), 'perm_loss': tensor(1.3410, device='cuda:0'), 'property_loss': tensor(495.7923, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  410 Loss sum :  0.5416996479034424 dsm :  1.0819445848464966 neg entropy :  561.7630004882812\n",
      "{'edge_loss': tensor(0.0277, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(246.8477, device='cuda:0'), 'perm_loss': tensor(1.2668, device='cuda:0'), 'property_loss': tensor(470.3643, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  420 Loss sum :  0.3450077772140503 dsm :  4.380302906036377 neg entropy :  564.384765625\n",
      "{'edge_loss': tensor(0.0249, device='cuda:0'), 'node_loss': tensor(0.0004, device='cuda:0'), 'kld_loss': tensor(249.3127, device='cuda:0'), 'perm_loss': tensor(1.2863, device='cuda:0'), 'property_loss': tensor(492.9079, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  430 Loss sum :  0.4413965940475464 dsm :  0.26942384243011475 neg entropy :  574.3713989257812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(244.9704, device='cuda:0'), 'perm_loss': tensor(1.3411, device='cuda:0'), 'property_loss': tensor(497.6170, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  440 Loss sum :  0.5159515142440796 dsm :  0.6822578310966492 neg entropy :  563.1355590820312\n",
      "{'edge_loss': tensor(0.0395, device='cuda:0'), 'node_loss': tensor(0.0008, device='cuda:0'), 'kld_loss': tensor(246.5221, device='cuda:0'), 'perm_loss': tensor(1.3545, device='cuda:0'), 'property_loss': tensor(474.4013, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  450 Loss sum :  0.6076948642730713 dsm :  1.2959526777267456 neg entropy :  561.1605224609375\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0'), 'node_loss': tensor(0.0019, device='cuda:0'), 'kld_loss': tensor(247.3254, device='cuda:0'), 'perm_loss': tensor(1.3406, device='cuda:0'), 'property_loss': tensor(497.7665, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  460 Loss sum :  0.5564832091331482 dsm :  0.4133128225803375 neg entropy :  567.6622924804688\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0'), 'node_loss': tensor(-0.0159, device='cuda:0'), 'kld_loss': tensor(249.6247, device='cuda:0'), 'perm_loss': tensor(1.3034, device='cuda:0'), 'property_loss': tensor(474.7212, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  470 Loss sum :  0.3881852328777313 dsm :  1.2909460067749023 neg entropy :  567.4237670898438\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0'), 'node_loss': tensor(-0.0149, device='cuda:0'), 'kld_loss': tensor(247.3339, device='cuda:0'), 'perm_loss': tensor(1.2513, device='cuda:0'), 'property_loss': tensor(455.2855, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  480 Loss sum :  0.4013598561286926 dsm :  0.6088685393333435 neg entropy :  564.1982421875\n",
      "{'edge_loss': tensor(0.0269, device='cuda:0'), 'node_loss': tensor(0.0007, device='cuda:0'), 'kld_loss': tensor(247.7058, device='cuda:0'), 'perm_loss': tensor(1.2816, device='cuda:0'), 'property_loss': tensor(482.3526, device='cuda:0')}\n",
      "Epoch (val) :  94   batch (val) :  490 Loss sum :  0.4799107313156128 dsm :  1.8534921407699585 neg entropy :  568.9645385742188\n",
      "Epoch :  95  Batch :  0  Loss :  0.6498532295227051 dsm :  0.4424402415752411 neg entropy :  557.3411254882812\n",
      "{'edge_loss': tensor(0.0411, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0036, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2399, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(503.6991, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  10  Loss :  0.3601830005645752 dsm :  2.9698662757873535 neg entropy :  561.2154541015625\n",
      "{'edge_loss': tensor(0.0285, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0143, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5362, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3198, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.3480, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  20  Loss :  0.5183500051498413 dsm :  0.078864686191082 neg entropy :  559.5426635742188\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9433, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.3852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  30  Loss :  0.5636909008026123 dsm :  0.4117143154144287 neg entropy :  563.2968139648438\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6582, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2954, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.9612, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  40  Loss :  0.5448030829429626 dsm :  0.0935501679778099 neg entropy :  554.5521850585938\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.7483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.5984, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  50  Loss :  0.5876852869987488 dsm :  2.03609561920166 neg entropy :  560.5609741210938\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3064, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3532, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.4568, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  60  Loss :  0.6526542901992798 dsm :  1.6781845092773438 neg entropy :  553.4021606445312\n",
      "{'edge_loss': tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6201, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.4324, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  70  Loss :  0.26231807470321655 dsm :  4.419463634490967 neg entropy :  562.6647338867188\n",
      "{'edge_loss': tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0321, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4639, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3823, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.4308, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  80  Loss :  0.2781265377998352 dsm :  3.819878339767456 neg entropy :  559.67919921875\n",
      "{'edge_loss': tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0305, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7326, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.0578, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  90  Loss :  0.5616012811660767 dsm :  0.26033052802085876 neg entropy :  561.54345703125\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1393, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.3170, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  100  Loss :  0.5918372869491577 dsm :  0.7025341987609863 neg entropy :  562.0816650390625\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.5461, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3746, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.5451, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  110  Loss :  0.6254392862319946 dsm :  0.6278875470161438 neg entropy :  555.9197387695312\n",
      "{'edge_loss': tensor(0.0407, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.9221, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4206, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.9634, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  120  Loss :  0.5589023232460022 dsm :  1.2037779092788696 neg entropy :  562.1638793945312\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5094, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.0427, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  130  Loss :  0.5920781493186951 dsm :  3.6029891967773438 neg entropy :  560.64453125\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2691, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4458, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(533.4711, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  140  Loss :  0.36514759063720703 dsm :  2.7391278743743896 neg entropy :  560.2088012695312\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7217, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3656, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.8271, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  150  Loss :  0.4270797371864319 dsm :  2.737550735473633 neg entropy :  560.0001220703125\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3221, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(463.4024, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  160  Loss :  0.4938541352748871 dsm :  1.0325678586959839 neg entropy :  560.2423706054688\n",
      "{'edge_loss': tensor(0.0291, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5601, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2368, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(459.3340, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  170  Loss :  0.38370048999786377 dsm :  3.556828260421753 neg entropy :  562.3514404296875\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5424, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2340, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(445.9507, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  180  Loss :  0.57804936170578 dsm :  0.7318669557571411 neg entropy :  563.2295532226562\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2814, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4794, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(524.5882, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  190  Loss :  0.270338773727417 dsm :  1.1204571723937988 neg entropy :  553.9121704101562\n",
      "{'edge_loss': tensor(0.0381, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0357, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.6350, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  200  Loss :  0.4266495704650879 dsm :  0.20733022689819336 neg entropy :  554.56103515625\n",
      "{'edge_loss': tensor(0.0387, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.5592, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3960, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.1928, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  210  Loss :  0.6123969554901123 dsm :  2.6816060543060303 neg entropy :  557.5916137695312\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6203, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.3851, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  220  Loss :  0.6034558415412903 dsm :  2.1678831577301025 neg entropy :  558.10693359375\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9923, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4332, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.7779, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  230  Loss :  0.37853550910949707 dsm :  0.5582138895988464 neg entropy :  556.968994140625\n",
      "{'edge_loss': tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3506, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(505.5134, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  240  Loss :  0.20850488543510437 dsm :  1.747086763381958 neg entropy :  557.6798706054688\n",
      "{'edge_loss': tensor(0.0310, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0312, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0349, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3799, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.2285, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  250  Loss :  0.3729724586009979 dsm :  3.2340781688690186 neg entropy :  560.2332763671875\n",
      "{'edge_loss': tensor(0.0306, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0156, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3144, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.8023, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  260  Loss :  0.64515221118927 dsm :  2.2473392486572266 neg entropy :  561.0133056640625\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0026, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2368, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3489, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.0937, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  270  Loss :  0.6594830751419067 dsm :  0.8402597308158875 neg entropy :  560.119140625\n",
      "{'edge_loss': tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.8051, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3499, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(465.2542, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  280  Loss :  0.6594367027282715 dsm :  1.9150656461715698 neg entropy :  558.6512451171875\n",
      "{'edge_loss': tensor(0.0439, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2046, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.0443, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  290  Loss :  0.5057183504104614 dsm :  1.2157976627349854 neg entropy :  562.6878051757812\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8824, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2539, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.3049, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  300  Loss :  0.5570324063301086 dsm :  1.6552940607070923 neg entropy :  562.4442749023438\n",
      "{'edge_loss': tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0507, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3913, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.5448, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  310  Loss :  0.04245331510901451 dsm :  0.7378391623497009 neg entropy :  557.857666015625\n",
      "{'edge_loss': tensor(0.0325, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0480, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1931, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.0240, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  320  Loss :  0.542690634727478 dsm :  0.6264220476150513 neg entropy :  559.1066284179688\n",
      "{'edge_loss': tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5917, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3183, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.8842, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  330  Loss :  0.6655995845794678 dsm :  6.05513858795166 neg entropy :  555.0505981445312\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6463, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3767, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.6132, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  340  Loss :  0.6197615265846252 dsm :  0.6597076654434204 neg entropy :  556.2103881835938\n",
      "{'edge_loss': tensor(0.0397, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1405, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4617, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.4239, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  350  Loss :  0.5754505395889282 dsm :  1.2955297231674194 neg entropy :  555.9973754882812\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6132, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3449, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.5702, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  360  Loss :  0.2588510513305664 dsm :  3.3203792572021484 neg entropy :  559.0158081054688\n",
      "{'edge_loss': tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0320, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4560, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2548, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(448.5733, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  370  Loss :  0.5770288109779358 dsm :  0.2737440764904022 neg entropy :  559.4439086914062\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8719, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.5750, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  380  Loss :  0.5877600908279419 dsm :  1.4548624753952026 neg entropy :  554.2366943359375\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.2706, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3611, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.2161, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  390  Loss :  0.5542698502540588 dsm :  2.0133817195892334 neg entropy :  559.025390625\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1471, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3531, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.0311, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  400  Loss :  0.5354809761047363 dsm :  2.78354811668396 neg entropy :  558.6434936523438\n",
      "{'edge_loss': tensor(0.0307, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8536, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3227, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5011, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  410  Loss :  0.528590738773346 dsm :  0.9237371683120728 neg entropy :  559.0330810546875\n",
      "{'edge_loss': tensor(0.0305, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1410, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4731, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(527.1302, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  420  Loss :  0.5064653158187866 dsm :  2.070280075073242 neg entropy :  562.3982543945312\n",
      "{'edge_loss': tensor(0.0277, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3907, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4446, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(528.5394, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  430  Loss :  0.5961716771125793 dsm :  2.236114501953125 neg entropy :  552.3485717773438\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.4978, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3897, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.9268, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  440  Loss :  0.60233074426651 dsm :  0.13186047971248627 neg entropy :  562.8671264648438\n",
      "{'edge_loss': tensor(0.0383, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0028, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1183, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3375, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.1470, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  450  Loss :  0.5400667786598206 dsm :  0.36733704805374146 neg entropy :  558.2515258789062\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5965, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3428, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.3796, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  460  Loss :  0.6365199089050293 dsm :  2.3428707122802734 neg entropy :  556.1996459960938\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2416, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2961, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(451.3607, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  470  Loss :  0.6056033372879028 dsm :  1.355948805809021 neg entropy :  554.6453857421875\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2881, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.7162, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  480  Loss :  0.4765208661556244 dsm :  1.3804192543029785 neg entropy :  563.9176635742188\n",
      "{'edge_loss': tensor(0.0267, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7542, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3043, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.1364, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  490  Loss :  0.6108091473579407 dsm :  1.845819115638733 neg entropy :  560.4679565429688\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4757, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.2189, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  500  Loss :  0.5749221444129944 dsm :  3.0621559619903564 neg entropy :  557.0870361328125\n",
      "{'edge_loss': tensor(0.0340, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0458, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3936, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.9285, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  510  Loss :  0.4051307439804077 dsm :  1.6230270862579346 neg entropy :  562.2662353515625\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.3443, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4824, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(529.2330, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  520  Loss :  0.6337617635726929 dsm :  2.9373152256011963 neg entropy :  554.0850830078125\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4169, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(472.1388, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  530  Loss :  0.474547415971756 dsm :  2.721338987350464 neg entropy :  558.962158203125\n",
      "{'edge_loss': tensor(0.0402, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7667, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4302, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.8166, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  540  Loss :  0.531873345375061 dsm :  1.1228951215744019 neg entropy :  561.5109252929688\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7745, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3367, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.4199, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  550  Loss :  0.3305665850639343 dsm :  0.18149395287036896 neg entropy :  563.1503295898438\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0271, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.9668, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  560  Loss :  0.6058064103126526 dsm :  0.9436742663383484 neg entropy :  550.2379150390625\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.3274, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3688, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.8957, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  570  Loss :  0.5721896886825562 dsm :  1.0630122423171997 neg entropy :  560.4667358398438\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4052, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3854, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.4187, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  580  Loss :  0.4589012563228607 dsm :  2.6127922534942627 neg entropy :  560.2532348632812\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0137, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2218, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.1786, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  590  Loss :  0.603918194770813 dsm :  1.093838095664978 neg entropy :  555.4503173828125\n",
      "{'edge_loss': tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5095, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4932, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(519.7878, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  600  Loss :  0.6171252727508545 dsm :  1.0517832040786743 neg entropy :  553.5183715820312\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6022, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3254, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.3330, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  610  Loss :  0.6374120116233826 dsm :  2.0796916484832764 neg entropy :  552.9017944335938\n",
      "{'edge_loss': tensor(0.0408, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4975, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3950, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.3237, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  620  Loss :  0.6247249245643616 dsm :  0.8581494688987732 neg entropy :  554.9342651367188\n",
      "{'edge_loss': tensor(0.0405, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0462, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.8694, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  630  Loss :  0.5456395149230957 dsm :  2.469071626663208 neg entropy :  559.3302001953125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8860, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3356, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(501.1968, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  640  Loss :  0.5411107540130615 dsm :  1.6302295923233032 neg entropy :  561.892578125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0005, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1001, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4267, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.0300, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  650  Loss :  0.3871478736400604 dsm :  4.855271816253662 neg entropy :  567.1575317382812\n",
      "{'edge_loss': tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6254, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3300, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.1722, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  660  Loss :  0.3478729724884033 dsm :  0.22940006852149963 neg entropy :  566.3953857421875\n",
      "{'edge_loss': tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9643, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.5749, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  670  Loss :  0.5820728540420532 dsm :  1.0359655618667603 neg entropy :  562.2205200195312\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0013, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2655, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(475.8070, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  680  Loss :  0.4330173134803772 dsm :  1.3086442947387695 neg entropy :  555.7571411132812\n",
      "{'edge_loss': tensor(0.0369, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1776, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(500.0950, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  690  Loss :  0.6930884122848511 dsm :  2.040649652481079 neg entropy :  554.8302612304688\n",
      "{'edge_loss': tensor(0.0445, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0031, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3676, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4082, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.9693, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  700  Loss :  0.5544775724411011 dsm :  3.008254289627075 neg entropy :  555.0175170898438\n",
      "{'edge_loss': tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4883, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2763, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(473.9130, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  710  Loss :  0.413163959980011 dsm :  0.13493196666240692 neg entropy :  557.3583374023438\n",
      "{'edge_loss': tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5377, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4161, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.0798, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  720  Loss :  0.6652715802192688 dsm :  3.582883596420288 neg entropy :  550.0400390625\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(239.3550, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3995, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5901, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  730  Loss :  0.5836375951766968 dsm :  6.626143932342529 neg entropy :  556.751708984375\n",
      "{'edge_loss': tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0144, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7701, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4235, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.3789, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  740  Loss :  0.2402345836162567 dsm :  0.4913109838962555 neg entropy :  555.0861206054688\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0317, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0363, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3740, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.3206, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  750  Loss :  0.55439293384552 dsm :  2.9428722858428955 neg entropy :  562.1544799804688\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9034, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2854, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.6433, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  760  Loss :  0.6180101037025452 dsm :  1.2543805837631226 neg entropy :  558.5747680664062\n",
      "{'edge_loss': tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3533, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3774, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.4373, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  770  Loss :  0.40896308422088623 dsm :  1.2549937963485718 neg entropy :  559.2918090820312\n",
      "{'edge_loss': tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9111, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3820, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.1916, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  780  Loss :  0.667502760887146 dsm :  7.960328578948975 neg entropy :  556.6407470703125\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1573, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3181, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(466.7807, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  790  Loss :  0.6336073875427246 dsm :  1.5671064853668213 neg entropy :  559.3818359375\n",
      "{'edge_loss': tensor(0.0423, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2462, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2868, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.1417, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  800  Loss :  0.5527918934822083 dsm :  3.871037006378174 neg entropy :  559.3953857421875\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8558, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2702, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.7421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  810  Loss :  0.5587505102157593 dsm :  1.4143909215927124 neg entropy :  560.3942260742188\n",
      "{'edge_loss': tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5110, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4244, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.8802, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  820  Loss :  0.5121330618858337 dsm :  4.510334014892578 neg entropy :  559.4421997070312\n",
      "{'edge_loss': tensor(0.0268, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0094, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(468.3084, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  830  Loss :  0.5645022392272949 dsm :  0.005501714535057545 neg entropy :  562.0596923828125\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.0018, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3244, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.5706, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  840  Loss :  0.6122236847877502 dsm :  0.3886583745479584 neg entropy :  557.4006958007812\n",
      "{'edge_loss': tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0038, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2573, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2534, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.8246, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  850  Loss :  0.6008856296539307 dsm :  0.06176615506410599 neg entropy :  559.2734375\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6752, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3541, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(488.5645, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  860  Loss :  0.42251378297805786 dsm :  0.2707866132259369 neg entropy :  557.3543701171875\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7525, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3586, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.9026, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  870  Loss :  0.530764102935791 dsm :  2.968104839324951 neg entropy :  563.1708374023438\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5658, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3931, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.2736, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  880  Loss :  0.5663061141967773 dsm :  1.3456192016601562 neg entropy :  558.32373046875\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6933, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(478.0982, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  890  Loss :  0.364529550075531 dsm :  1.3518846035003662 neg entropy :  560.5980834960938\n",
      "{'edge_loss': tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.4518, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3240, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.0073, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  900  Loss :  0.4733446538448334 dsm :  0.9923848509788513 neg entropy :  563.7052612304688\n",
      "{'edge_loss': tensor(0.0266, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6362, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2756, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9925, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  910  Loss :  0.5936650633811951 dsm :  1.8911319971084595 neg entropy :  561.0346069335938\n",
      "{'edge_loss': tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8563, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3210, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.7647, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  920  Loss :  0.6178621053695679 dsm :  2.632521390914917 neg entropy :  562.3886108398438\n",
      "{'edge_loss': tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.9645, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3351, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.3420, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  930  Loss :  0.5832679271697998 dsm :  0.167034313082695 neg entropy :  555.8527221679688\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0181, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3678, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(484.0887, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  940  Loss :  0.3911653757095337 dsm :  1.3100155591964722 neg entropy :  559.1726684570312\n",
      "{'edge_loss': tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1501, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(507.4652, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  950  Loss :  0.43902021646499634 dsm :  0.2645147740840912 neg entropy :  559.3704223632812\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0141, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3821, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3359, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.3604, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  960  Loss :  0.45997756719589233 dsm :  2.425262212753296 neg entropy :  553.9479370117188\n",
      "{'edge_loss': tensor(0.0379, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.0769, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4879, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(532.5613, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  970  Loss :  0.6011908054351807 dsm :  2.6050968170166016 neg entropy :  557.0421752929688\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4328, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3223, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.0933, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  980  Loss :  0.6410414576530457 dsm :  1.10381281375885 neg entropy :  561.4157104492188\n",
      "{'edge_loss': tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2464, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.4832, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  990  Loss :  0.6054273247718811 dsm :  0.11847596615552902 neg entropy :  552.9276733398438\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0020, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8463, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4329, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.1895, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1000  Loss :  0.6279111504554749 dsm :  1.5046659708023071 neg entropy :  560.6156005859375\n",
      "{'edge_loss': tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0029, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7795, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.4836, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1010  Loss :  0.5290921330451965 dsm :  0.8009769320487976 neg entropy :  557.7462768554688\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5984, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3066, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.7880, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1020  Loss :  0.5752356052398682 dsm :  5.211607456207275 neg entropy :  561.7847900390625\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4195, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2778, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(471.8718, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1030  Loss :  0.4592116177082062 dsm :  0.5352985262870789 neg entropy :  559.23681640625\n",
      "{'edge_loss': tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0148, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7076, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3265, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.3450, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1040  Loss :  0.6141499876976013 dsm :  1.6952139139175415 neg entropy :  559.5176391601562\n",
      "{'edge_loss': tensor(0.0380, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2103, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4294, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.6216, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1050  Loss :  0.5871224999427795 dsm :  4.4244303703308105 neg entropy :  560.1701049804688\n",
      "{'edge_loss': tensor(0.0342, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5349, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3602, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(487.9561, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1060  Loss :  0.6321532130241394 dsm :  0.35057327151298523 neg entropy :  556.2416381835938\n",
      "{'edge_loss': tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.8920, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.6667, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1070  Loss :  0.5203767418861389 dsm :  0.12658776342868805 neg entropy :  555.7434692382812\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6463, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2847, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(460.2191, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1080  Loss :  0.6449058651924133 dsm :  1.0007957220077515 neg entropy :  555.342529296875\n",
      "{'edge_loss': tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3901, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2962, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(449.6852, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1090  Loss :  0.42363789677619934 dsm :  5.263997554779053 neg entropy :  563.2074584960938\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0159, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.4274, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3052, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.6636, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1100  Loss :  0.49074241518974304 dsm :  3.3658645153045654 neg entropy :  550.8261108398438\n",
      "{'edge_loss': tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0149, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.2083, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3315, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(461.7066, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1110  Loss :  0.5608663558959961 dsm :  0.6756715774536133 neg entropy :  561.7039794921875\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3932, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4200, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.4886, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1120  Loss :  0.413225382566452 dsm :  0.34049782156944275 neg entropy :  555.6847534179688\n",
      "{'edge_loss': tensor(0.0366, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2103, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3949, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(495.4558, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1130  Loss :  0.5808312296867371 dsm :  2.0226359367370605 neg entropy :  559.0021362304688\n",
      "{'edge_loss': tensor(0.0351, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2253, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.4189, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1140  Loss :  0.52838534116745 dsm :  2.273418664932251 neg entropy :  560.0266723632812\n",
      "{'edge_loss': tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0006, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6208, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3112, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.7830, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1150  Loss :  0.6304661631584167 dsm :  6.637008190155029 neg entropy :  560.0645141601562\n",
      "{'edge_loss': tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.3280, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3316, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.5150, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1160  Loss :  0.6217596530914307 dsm :  1.2081024646759033 neg entropy :  560.7633666992188\n",
      "{'edge_loss': tensor(0.0385, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6808, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5083, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(541.9160, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1170  Loss :  0.6040453910827637 dsm :  2.8485453128814697 neg entropy :  553.1588745117188\n",
      "{'edge_loss': tensor(0.0368, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4308, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4114, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.9952, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1180  Loss :  0.640963077545166 dsm :  0.35618290305137634 neg entropy :  550.7008056640625\n",
      "{'edge_loss': tensor(0.0418, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.1237, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5016, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.4388, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1190  Loss :  0.5438200235366821 dsm :  0.7523651123046875 neg entropy :  558.2999267578125\n",
      "{'edge_loss': tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.7275, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4358, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(535.8574, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1200  Loss :  0.5341392755508423 dsm :  1.1078306436538696 neg entropy :  561.2692260742188\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5591, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3348, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(496.6801, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1210  Loss :  0.602630615234375 dsm :  0.6221880316734314 neg entropy :  556.4141235351562\n",
      "{'edge_loss': tensor(0.0382, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.3802, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4086, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(516.6696, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1220  Loss :  0.5271084904670715 dsm :  0.8548074960708618 neg entropy :  560.8561401367188\n",
      "{'edge_loss': tensor(0.0315, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9364, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3616, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.1809, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1230  Loss :  0.614063024520874 dsm :  0.6317958831787109 neg entropy :  559.55126953125\n",
      "{'edge_loss': tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7447, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4487, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.0245, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1240  Loss :  0.39737552404403687 dsm :  2.1839544773101807 neg entropy :  559.1596069335938\n",
      "{'edge_loss': tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3925, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3134, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.2009, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1250  Loss :  0.5628470182418823 dsm :  0.8617602586746216 neg entropy :  559.6776123046875\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7985, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3720, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.3133, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1260  Loss :  0.2650446891784668 dsm :  1.0948363542556763 neg entropy :  557.23046875\n",
      "{'edge_loss': tensor(0.0361, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0310, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2411, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4735, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.3670, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1270  Loss :  0.3384901285171509 dsm :  0.6677418351173401 neg entropy :  566.4470825195312\n",
      "{'edge_loss': tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0157, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8457, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4205, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(527.7410, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1280  Loss :  0.6292335987091064 dsm :  2.459582567214966 neg entropy :  559.638671875\n",
      "{'edge_loss': tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1683, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2651, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(435.7124, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1290  Loss :  0.6499564051628113 dsm :  0.5493361949920654 neg entropy :  557.138916015625\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7079, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4226, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.8784, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1300  Loss :  0.572257399559021 dsm :  1.6136387586593628 neg entropy :  558.9797973632812\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6999, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3205, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.4494, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1310  Loss :  0.3864902853965759 dsm :  1.943581223487854 neg entropy :  564.40673828125\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.2077, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(514.6437, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1320  Loss :  0.6155110001564026 dsm :  3.032986640930176 neg entropy :  562.374267578125\n",
      "{'edge_loss': tensor(0.0371, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0030, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8419, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2741, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(479.7068, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1330  Loss :  0.6118291020393372 dsm :  0.23684950172901154 neg entropy :  558.9149169921875\n",
      "{'edge_loss': tensor(0.0399, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.4629, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3669, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.1228, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1340  Loss :  0.43720248341560364 dsm :  0.05220257118344307 neg entropy :  560.0383911132812\n",
      "{'edge_loss': tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0147, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2370, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3906, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.2564, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1350  Loss :  0.597031831741333 dsm :  0.17100630700588226 neg entropy :  559.7313842773438\n",
      "{'edge_loss': tensor(0.0395, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8100, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2646, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(438.3617, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1360  Loss :  0.6260022521018982 dsm :  0.031984563916921616 neg entropy :  554.5791015625\n",
      "{'edge_loss': tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0007, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.8980, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3506, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(476.6284, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1370  Loss :  0.5945577621459961 dsm :  0.2069484442472458 neg entropy :  558.728515625\n",
      "{'edge_loss': tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2588, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4521, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(515.8257, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1380  Loss :  0.6174482107162476 dsm :  3.452672243118286 neg entropy :  554.447998046875\n",
      "{'edge_loss': tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0023, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4701, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4272, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.2264, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1390  Loss :  0.6427127122879028 dsm :  2.776954412460327 neg entropy :  559.7672119140625\n",
      "{'edge_loss': tensor(0.0406, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2901, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3661, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(470.5944, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1400  Loss :  0.6344952583312988 dsm :  0.005819238256663084 neg entropy :  559.4924926757812\n",
      "{'edge_loss': tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0004, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8838, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3214, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(469.3732, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1410  Loss :  0.5610570311546326 dsm :  1.4721465110778809 neg entropy :  562.0715942382812\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6851, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2670, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(452.7868, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1420  Loss :  0.4253799021244049 dsm :  2.741323709487915 neg entropy :  560.4024658203125\n",
      "{'edge_loss': tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0335, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3442, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.9217, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1430  Loss :  0.727607786655426 dsm :  2.870368242263794 neg entropy :  555.4900512695312\n",
      "{'edge_loss': tensor(0.0471, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0019, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3340, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5329, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(522.1440, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1440  Loss :  0.5709085464477539 dsm :  1.0980896949768066 neg entropy :  565.5279541015625\n",
      "{'edge_loss': tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(246.2933, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3679, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(486.7180, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1450  Loss :  0.5938302278518677 dsm :  0.7050397396087646 neg entropy :  557.25634765625\n",
      "{'edge_loss': tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0011, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0918, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4313, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(504.7393, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1460  Loss :  0.5411469340324402 dsm :  0.6653998494148254 neg entropy :  561.6600952148438\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0013, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2056, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3989, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.8318, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1470  Loss :  0.5677321553230286 dsm :  0.9044435620307922 neg entropy :  559.5170288085938\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.9483, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3522, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.5525, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1480  Loss :  0.5871812105178833 dsm :  6.45895528793335 neg entropy :  556.5214233398438\n",
      "{'edge_loss': tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.2375, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2746, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.8026, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1490  Loss :  0.5792636871337891 dsm :  0.9105138778686523 neg entropy :  563.7627563476562\n",
      "{'edge_loss': tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6523, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3660, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(498.4780, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1500  Loss :  0.5540770888328552 dsm :  0.053443122655153275 neg entropy :  556.6242065429688\n",
      "{'edge_loss': tensor(0.0349, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6333, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3629, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.3117, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1510  Loss :  0.5711866617202759 dsm :  4.0939507484436035 neg entropy :  561.0204467773438\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8429, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2766, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.6117, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1520  Loss :  0.5712096095085144 dsm :  0.8744127154350281 neg entropy :  563.9694213867188\n",
      "{'edge_loss': tensor(0.0356, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.8777, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(490.7395, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1530  Loss :  0.6454135775566101 dsm :  1.315924048423767 neg entropy :  555.7333374023438\n",
      "{'edge_loss': tensor(0.0414, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0541, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4821, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(513.7836, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1540  Loss :  0.6122753024101257 dsm :  1.4787167310714722 neg entropy :  563.3561401367188\n",
      "{'edge_loss': tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8823, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4318, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(518.9974, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1550  Loss :  0.5873573422431946 dsm :  3.4381256103515625 neg entropy :  558.6281127929688\n",
      "{'edge_loss': tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2620, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3536, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.4304, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1560  Loss :  0.6271236538887024 dsm :  2.1079089641571045 neg entropy :  559.1221923828125\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0021, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.3177, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3781, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(506.5146, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1570  Loss :  0.3869933784008026 dsm :  3.0458266735076904 neg entropy :  565.3287353515625\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0154, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.9487, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.1728, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1580  Loss :  0.5363567471504211 dsm :  0.955856442451477 neg entropy :  563.25\n",
      "{'edge_loss': tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5525, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3245, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(497.3555, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1590  Loss :  0.5545007586479187 dsm :  0.16829000413417816 neg entropy :  555.3106079101562\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0018, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4492, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3779, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(481.0486, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1600  Loss :  0.5326278805732727 dsm :  0.6596933007240295 neg entropy :  563.0590209960938\n",
      "{'edge_loss': tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.1419, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3592, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(493.5503, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1610  Loss :  0.6134896278381348 dsm :  7.00349760055542 neg entropy :  560.630859375\n",
      "{'edge_loss': tensor(0.0338, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6129, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3304, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.6794, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1620  Loss :  0.5283376574516296 dsm :  1.1343001127243042 neg entropy :  557.6778564453125\n",
      "{'edge_loss': tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0010, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.0590, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3403, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.0572, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1630  Loss :  0.6545685529708862 dsm :  0.9104119539260864 neg entropy :  560.7013549804688\n",
      "{'edge_loss': tensor(0.0437, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.2958, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3668, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.7546, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1640  Loss :  0.3763378858566284 dsm :  3.03039813041687 neg entropy :  563.163330078125\n",
      "{'edge_loss': tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.1200, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2098, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(434.2773, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1650  Loss :  0.6112167835235596 dsm :  0.5504640936851501 neg entropy :  560.50927734375\n",
      "{'edge_loss': tensor(0.0392, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.0562, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.2794, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1660  Loss :  0.5645779967308044 dsm :  0.548462986946106 neg entropy :  557.2340698242188\n",
      "{'edge_loss': tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0016, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1133, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(467.8140, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1670  Loss :  0.650700569152832 dsm :  1.4928959608078003 neg entropy :  557.4830322265625\n",
      "{'edge_loss': tensor(0.0420, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.8960, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4519, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(489.8022, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1680  Loss :  0.4605768918991089 dsm :  0.1921006739139557 neg entropy :  559.4987182617188\n",
      "{'edge_loss': tensor(0.0419, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.6025, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3788, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(485.7638, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1690  Loss :  0.40273335576057434 dsm :  1.187117099761963 neg entropy :  562.6159057617188\n",
      "{'edge_loss': tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0153, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6348, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4404, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.2586, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1700  Loss :  0.37055057287216187 dsm :  1.23627507686615 neg entropy :  565.7311401367188\n",
      "{'edge_loss': tensor(0.0341, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0158, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.6261, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.1926, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(457.4510, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1710  Loss :  0.5816394090652466 dsm :  0.745412290096283 neg entropy :  558.0408935546875\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.0805, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3323, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(480.1788, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1720  Loss :  0.6337491273880005 dsm :  0.7300646901130676 neg entropy :  559.3770751953125\n",
      "{'edge_loss': tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0024, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7308, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4627, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(529.7214, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1730  Loss :  0.6027660965919495 dsm :  2.3914380073547363 neg entropy :  561.1849975585938\n",
      "{'edge_loss': tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.7688, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(494.4451, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1740  Loss :  0.6315876841545105 dsm :  2.3077282905578613 neg entropy :  555.3948364257812\n",
      "{'edge_loss': tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0008, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(240.6570, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(483.4868, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1750  Loss :  0.6410607695579529 dsm :  1.3350948095321655 neg entropy :  555.1008911132812\n",
      "{'edge_loss': tensor(0.0404, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.6949, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(482.8720, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1760  Loss :  0.6651816368103027 dsm :  0.23826371133327484 neg entropy :  556.563720703125\n",
      "{'edge_loss': tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0034, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.1502, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(464.2376, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1770  Loss :  0.47287556529045105 dsm :  1.2837704420089722 neg entropy :  553.0111083984375\n",
      "{'edge_loss': tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0152, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.1478, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(491.4421, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1780  Loss :  0.7071079015731812 dsm :  3.9963974952697754 neg entropy :  553.0551147460938\n",
      "{'edge_loss': tensor(0.0454, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.6225, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4639, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(511.7336, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1790  Loss :  0.3650517165660858 dsm :  2.073179006576538 neg entropy :  561.4764404296875\n",
      "{'edge_loss': tensor(0.0302, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0151, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.5691, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(492.6404, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1800  Loss :  0.534262478351593 dsm :  0.26963213086128235 neg entropy :  563.7029418945312\n",
      "{'edge_loss': tensor(0.0321, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.5960, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.4017, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(520.8741, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1810  Loss :  0.4735719561576843 dsm :  5.262156963348389 neg entropy :  558.3665161132812\n",
      "{'edge_loss': tensor(0.0378, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0150, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.2664, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3794, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(474.6161, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1820  Loss :  0.2568591833114624 dsm :  1.6710180044174194 neg entropy :  558.2645874023438\n",
      "{'edge_loss': tensor(0.0352, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0320, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(244.6307, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.5272, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(530.6733, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1830  Loss :  0.5298821330070496 dsm :  4.042632579803467 neg entropy :  556.4114379882812\n",
      "{'edge_loss': tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.5855, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2576, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(440.4437, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1840  Loss :  0.5145558714866638 dsm :  0.8220956921577454 neg entropy :  565.1600952148438\n",
      "{'edge_loss': tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(245.4382, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2189, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(455.7305, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1850  Loss :  0.5828635692596436 dsm :  0.22172918915748596 neg entropy :  557.4714965820312\n",
      "{'edge_loss': tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0030, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(241.4523, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3452, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(502.3875, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1860  Loss :  0.5572383403778076 dsm :  4.9475016593933105 neg entropy :  561.1610717773438\n",
      "{'edge_loss': tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(0.0015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(242.7858, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.2819, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(477.1556, device='cuda:0', grad_fn=<MseLossBackward0>)}\n",
      "Epoch :  95  Batch :  1870  Loss :  0.3703433573246002 dsm :  1.5413392782211304 neg entropy :  559.9397583007812\n",
      "{'edge_loss': tensor(0.0318, device='cuda:0', grad_fn=<DivBackward0>), 'node_loss': tensor(-0.0155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'kld_loss': tensor(243.1136, device='cuda:0', grad_fn=<MeanBackward0>), 'perm_loss': tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>), 'property_loss': tensor(508.7801, device='cuda:0', grad_fn=<MseLossBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "beta = 0.01\n",
    "gamma = 1e-4\n",
    "best_loss = 10000000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    sum_errors = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "\n",
    "        node_features, edge_features, mask, props = batch_data\n",
    "        node_features, edge_features, mask, props = node_features.to(device), edge_features.to(device), mask.to(device), props.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        graph_pred, perm, graph_emb, mu, logvar, model_out, t_noise = model(node_features, edge_features, mask, training=True, tau=1.0)\n",
    "        node_logits, edge_logits, pred_props = graph_pred\n",
    "\n",
    "        vae_loss = critic(node_features, edge_features, props, node_logits, edge_logits, pred_props, mask, perm, mu, logvar)\n",
    "\n",
    "        batch_vae_loss = vae_loss['node_loss'] * 10 + vae_loss['edge_loss'] * 10 + vae_loss['perm_loss'] * 0.1\n",
    "        diffusion_loss = torch.sum((t_noise - model_out).pow(2), dim = 1).mean()\n",
    "        negative_entropy = - torch.mean(torch.sum(logvar,dim=1))\n",
    "        batch_all_loss = batch_vae_loss + diffusion_loss * beta + negative_entropy * gamma\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Epoch : \", epoch, \" Batch : \", batch_idx, \" Loss : \", batch_all_loss.data.item(), \"dsm : \", diffusion_loss.data.item(), \"neg entropy : \", negative_entropy.data.item())\n",
    "            print(vae_loss)\n",
    "\n",
    "        sum_errors = sum_errors + vae_loss['node_loss'].data.item() * 10 + vae_loss['edge_loss'].data.item() * 10 \\\n",
    "         + diffusion_loss.data.item() * beta + negative_entropy.data.item() * gamma\n",
    "\n",
    "        batch_all_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        del batch_all_loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    train_loss_list.append(sum_errors / len(train_loader))\n",
    "    val_loss = val_preds(epoch) / len(val_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    np.save(model_save_dir + \"train_loss_hist\", np.array(train_loss_list))\n",
    "    np.save(model_save_dir + \"val_loss_hist\", np.array(val_loss_list))\n",
    "\n",
    "    logging_txt(epoch)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        save_model_path = model_save_dir + \"pigvae_best_model\" + \".pt\"\n",
    "        torch.save(model, save_model_path)\n",
    "\n",
    "        optimizer_path = model_save_dir + \"opt_best_model\" + \".pt\"\n",
    "        torch.save(optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "        best_loss = val_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
