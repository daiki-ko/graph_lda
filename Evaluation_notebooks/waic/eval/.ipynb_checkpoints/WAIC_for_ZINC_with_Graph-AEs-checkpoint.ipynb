{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2ed900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.dense import floyd_warshall_numpy\n",
    "\n",
    "from networkx.generators.random_graphs import *\n",
    "from networkx.generators.ego import ego_graph\n",
    "from networkx.generators.geometric import random_geometric_graph\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e808080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e032989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = [\"bace\", \"ctsd\", \"mmp2\", \"malaria\", \"esol\", \"freesolv\", \"lipo\", \"logp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba7b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Parameter, Sequential\n",
    "from torch.nn import Linear, Tanh, ReLU, CELU\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal, Categorical, Normal, MultivariateNormal\n",
    "\n",
    "class MLP_Regressor(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim):\n",
    "        super(MLP_Regressor, self).__init__()\n",
    "        \n",
    "        self.swish = nn.SiLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.rfc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.rfc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.rfc3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        dh = self.tanh(self.rfc1(z))\n",
    "        dh = self.tanh(self.rfc2(dh))\n",
    "        return self.rfc3(dh)\n",
    "     \n",
    "    def forward(self, z, target):\n",
    "        y_u = self.decode(z)\n",
    "        \n",
    "        log_prob_ys = Normal(y_u, 1).log_prob(target)\n",
    "        \n",
    "        return log_prob_ys, log_prob_ys.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133d469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waics(model, torch_ys, torch_zs, batch_indices, posterior_params):\n",
    "    \n",
    "    burn_in = 2000\n",
    "    get_posterior_num = len(posterior_params) - burn_in\n",
    "\n",
    "    nlogp_list = []\n",
    "    var_list = []\n",
    "    model.eval()\n",
    "\n",
    "    for id, indices in enumerate(batch_indices): #observed samples loop\n",
    "\n",
    "        print(\"sample :\", id)\n",
    "        ts = torch_ys[indices]\n",
    "        zs = torch_zs[indices]\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            ts = ts.to(device)\n",
    "            zs = zs.to(device)\n",
    "\n",
    "        prob_per_batch = [] #for Tn\n",
    "        logps_per_batch = [] #for Vn\n",
    "\n",
    "        #観測データを固定して、事後パラメータをサンプリング\n",
    "        for i, posterior_param in enumerate(posterior_params[-get_posterior_num:]): #すでにcudaにのってる\n",
    "\n",
    "            model.load_state_dict(posterior_param)\n",
    "\n",
    "            batch_logp_per_posterior, batch_prob_per_posterior = model(zs, ts) #shape = (batch_size, 1)\n",
    "            \n",
    "            prob_per_batch.append(batch_prob_per_posterior.to('cpu').detach().numpy().copy().reshape(-1)) #for Tn\n",
    "            logps_per_batch.append(batch_logp_per_posterior.to('cpu').detach().numpy().copy().reshape(-1)) # for Vn\n",
    "            \n",
    "            del posterior_param\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        nlogp_list.extend(-1 * np.log(np.mean(prob_per_batch, axis = 0))) # for Tn\n",
    "        var_list.extend(np.var(np.array(logps_per_batch), axis = 0)) # for Vn\n",
    "        \n",
    "        del prob_per_batch, logps_per_batch, ts, zs\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return nlogp_list, var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdf711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d82540",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/'\n",
    "load_model_dir = root + 'save_models/zinc/pig-ae_models/'\n",
    "\n",
    "def get_batch_index(indices, batch_size=None, n_batch=None):\n",
    "\n",
    "    n_batch = len(indices)//batch_size\n",
    "    batch_ids = np.array_split(indices, n_batch)\n",
    "    return(batch_ids), n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef80e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165ff32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmc/zinc/bace/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n",
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "lmc/zinc/ctsd/ae/\n",
      "sample : 0\n",
      "lmc/zinc/mmp2/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n",
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "sample : 10\n",
      "sample : 11\n",
      "sample : 12\n",
      "sample : 13\n",
      "sample : 14\n",
      "sample : 15\n",
      "sample : 16\n",
      "sample : 17\n",
      "sample : 18\n",
      "sample : 19\n",
      "lmc/zinc/malaria/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n",
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "sample : 10\n",
      "sample : 11\n",
      "sample : 12\n",
      "sample : 13\n",
      "sample : 14\n",
      "sample : 15\n",
      "sample : 16\n",
      "sample : 17\n",
      "sample : 18\n",
      "sample : 19\n",
      "sample : 20\n",
      "sample : 21\n",
      "sample : 22\n",
      "sample : 23\n",
      "sample : 24\n",
      "sample : 25\n",
      "sample : 26\n",
      "sample : 27\n",
      "sample : 28\n",
      "sample : 29\n",
      "sample : 30\n",
      "sample : 31\n",
      "sample : 32\n",
      "sample : 33\n",
      "sample : 34\n",
      "sample : 35\n",
      "sample : 36\n",
      "sample : 37\n",
      "sample : 38\n",
      "sample : 39\n",
      "sample : 40\n",
      "sample : 41\n",
      "sample : 42\n",
      "sample : 43\n",
      "sample : 44\n",
      "sample : 45\n",
      "sample : 46\n",
      "sample : 47\n",
      "sample : 48\n",
      "sample : 49\n",
      "sample : 50\n",
      "sample : 51\n",
      "sample : 52\n",
      "sample : 53\n",
      "sample : 54\n",
      "sample : 55\n",
      "sample : 56\n",
      "sample : 57\n",
      "sample : 58\n",
      "sample : 59\n",
      "lmc/zinc/esol/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n",
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "sample : 10\n",
      "sample : 11\n",
      "sample : 12\n",
      "sample : 13\n",
      "sample : 14\n",
      "sample : 15\n",
      "sample : 16\n",
      "sample : 17\n",
      "sample : 18\n",
      "sample : 19\n",
      "sample : 20\n",
      "lmc/zinc/freesolv/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1897292/3274911829.py:36: RuntimeWarning: divide by zero encountered in log\n",
      "  nlogp_list.extend(-1 * np.log(np.mean(prob_per_batch, axis = 0))) # for Tn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "sample : 10\n",
      "sample : 11\n",
      "lmc/zinc/lipo/ae/\n",
      "sample : 0\n",
      "sample : 1\n",
      "sample : 2\n",
      "sample : 3\n",
      "sample : 4\n",
      "sample : 5\n",
      "sample : 6\n",
      "sample : 7\n",
      "sample : 8\n",
      "sample : 9\n",
      "sample : 10\n",
      "sample : 11\n",
      "sample : 12\n",
      "sample : 13\n",
      "sample : 14\n",
      "sample : 15\n",
      "sample : 16\n",
      "sample : 17\n",
      "sample : 18\n",
      "sample : 19\n",
      "sample : 20\n",
      "sample : 21\n",
      "sample : 22\n",
      "sample : 23\n",
      "sample : 24\n",
      "sample : 25\n",
      "sample : 26\n",
      "sample : 27\n",
      "sample : 28\n",
      "sample : 29\n",
      "sample : 30\n",
      "sample : 31\n",
      "sample : 32\n",
      "sample : 33\n",
      "sample : 34\n",
      "sample : 35\n",
      "sample : 36\n",
      "sample : 37\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import future, sys, os, datetime, argparse, copy, warnings, time\n",
    "\n",
    "nlogp_lists = []\n",
    "var_lists = []\n",
    "\n",
    "for task in task_names:\n",
    "\n",
    "    posterior_save_dir = \"lmc/zinc/\" + task + \"/ae/\"\n",
    "    posterior_save_dir = root + \"posteriors/waic/zinc/\" + task + \"/ae/\"\n",
    "    \n",
    "    print(posterior_save_dir)\n",
    "    \n",
    "    z_mus = np.load(sample_load_dir + \"embs_mu.npy\")\n",
    "    targets = np.load(sample_load_dir + \"targets.npy\")\n",
    "    targets = np.reshape(targets, (targets.shape[0], 1))\n",
    "\n",
    "    torch_mus = torch.from_numpy(z_mus.astype(np.float32)).clone()\n",
    "    torch_zs = torch_mus\n",
    "    torch_ys = torch.from_numpy(targets.astype(np.float32)).clone()\n",
    "\n",
    "    batch_indices, n_batch = get_batch_index(np.arange(len(torch_ys)), batch_size=batch_size)\n",
    "\n",
    "    f1 = open(posterior_save_dir + \"posterior_params.pickle\",'rb')\n",
    "    posterior_params = pickle.load(f1)\n",
    "\n",
    "    model = MLP_Regressor(90, 256).to(device)\n",
    "\n",
    "    nlogp_list, var_list  = get_waics(model, torch_ys, torch_zs, batch_indices, posterior_params)\n",
    "    \n",
    "    nlogp_lists.append(nlogp_list)\n",
    "    var_lists.append(var_list)\n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668c46e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.652771 1.6270512 0.025719708\n",
      "1.3126745 1.2788761 0.03379849\n",
      "1.9250054 1.8946797 0.030325755\n",
      "1.9307127 1.8981124 0.032600235\n",
      "1.9693598 1.9125398 0.056819867\n",
      "inf inf 2.9009142\n",
      "1.5807693 1.5678978 0.0128715485\n"
     ]
    }
   ],
   "source": [
    "for nlogp_list, var_list in zip(nlogp_lists, var_lists):\n",
    "    print(np.mean(nlogp_list) + np.mean(var_list), np.mean(nlogp_list), np.mean(var_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195a648-de2f-40a5-8c3a-cea858635bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ids = [44, 215, 362]\n",
    "#no_ids = [362]\n",
    "\n",
    "#nlogp_lists[0], var_lists[0]\n",
    "\n",
    "nlogp_list = []\n",
    "var_list = []\n",
    "\n",
    "for id, (nlogp, var) in enumerate(zip(nlogp_lists[-2], var_lists[-2])):\n",
    "    \n",
    "    if id not in no_ids:\n",
    "        nlogp_list.append(nlogp)\n",
    "        var_list.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f336dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3850403 3.5036266 0.8814136\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(nlogp_list) + np.mean(var_list), np.mean(nlogp_list), np.mean(var_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884389cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
