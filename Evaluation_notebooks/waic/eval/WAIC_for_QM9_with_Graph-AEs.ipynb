{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2ed900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.dense import floyd_warshall_numpy\n",
    "\n",
    "from networkx.generators.random_graphs import *\n",
    "from networkx.generators.ego import ego_graph\n",
    "from networkx.generators.geometric import random_geometric_graph\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e808080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = ['mu', 'alpha', 'homo', 'lumo', 'r2', 'zpve', 'u0','cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d072584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Parameter, Sequential\n",
    "from torch.nn import Linear, Tanh, ReLU, CELU\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal, Categorical, Normal, MultivariateNormal\n",
    "\n",
    "class MLP_Regressor(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim):\n",
    "        super(MLP_Regressor, self).__init__()\n",
    "        \n",
    "        self.swish = nn.SiLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.rfc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.rfc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.rfc3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        dh = self.swish(self.rfc1(z))\n",
    "        dh = self.swish(self.rfc2(dh))\n",
    "        return self.rfc3(dh)\n",
    "     \n",
    "    def forward(self, z, target):\n",
    "        y_u = self.decode(z)\n",
    "        \n",
    "        log_prob_ys = Normal(y_u, 1).log_prob(target)\n",
    "        #log_prob_zs = MultivariateNormal(z_mu, z_var).log_prob(z).sum()\n",
    "        \n",
    "        return log_prob_ys, log_prob_ys.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7133d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d926c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waics(model, torch_ys, torch_zs, batch_indices, posterior_params):\n",
    "    \n",
    "    burn_in = 2000\n",
    "    get_posterior_num = len(posterior_params) - burn_in\n",
    "\n",
    "    nlogp_list = []\n",
    "    var_list = []\n",
    "    model.eval()\n",
    "\n",
    "    for id, indices in enumerate(batch_indices): #observed samples loop\n",
    "\n",
    "        print(\"sample :\", id)\n",
    "        ts = torch_ys[indices]\n",
    "        zs = torch_zs[indices]\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            ts = ts.to(device)\n",
    "            zs = zs.to(device)\n",
    "\n",
    "        prob_per_batch = [] #for Tn\n",
    "        logps_per_batch = [] #for Vn\n",
    "\n",
    "        #観測データを固定して、事後パラメータをサンプリング\n",
    "        for i, posterior_param in enumerate(posterior_params[-get_posterior_num:]): #すでにcudaにのってる\n",
    "\n",
    "            model.load_state_dict(posterior_param)\n",
    "\n",
    "            batch_logp_per_posterior, batch_prob_per_posterior = model(zs, ts) #shape = (batch_size, 1)\n",
    "            \n",
    "            prob_per_batch.append(batch_prob_per_posterior.to('cpu').detach().numpy().copy().reshape(-1)) #for Tn\n",
    "            logps_per_batch.append(batch_logp_per_posterior.to('cpu').detach().numpy().copy().reshape(-1)) # for Vn\n",
    "            \n",
    "            del posterior_param\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        nlogp_list.extend(-1 * np.log(np.mean(prob_per_batch, axis = 0))) # for Tn\n",
    "        var_list.extend(np.var(np.array(logps_per_batch), axis = 0)) # for Vn\n",
    "        \n",
    "        del prob_per_batch, logps_per_batch, ts, zs\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return nlogp_list, var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdf711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d82540",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/'\n",
    "load_model_dir = root + 'save_models/qm9/pig-e3ae_models/'\n",
    "\n",
    "def get_batch_index(indices, batch_size=None, n_batch=None):\n",
    "\n",
    "    n_batch = len(indices)//batch_size\n",
    "    batch_ids = np.array_split(indices, n_batch)\n",
    "    return(batch_ids), n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef80e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01d8efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmc/qm9/homo/ae/\n",
      "sample : 0\n",
      "sample : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1440416/1978773294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_Regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnlogp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_waics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_zs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mnlogp_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlogp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1440416/3274911829.py\u001b[0m in \u001b[0;36mget_waics\u001b[0;34m(model, torch_ys, torch_zs, batch_indices, posterior_params)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mbatch_logp_per_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_prob_per_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shape = (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprob_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prob_per_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for Tn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1440416/1563667710.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, target)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mlog_prob_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#log_prob_zs = MultivariateNormal(z_mu, z_var).log_prob(z).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import future, sys, os, datetime, argparse, copy, warnings, time\n",
    "\n",
    "task_list = [\"homo\", \"lumo\"]\n",
    "\n",
    "nlogp_lists = []\n",
    "var_lists = []\n",
    "\n",
    "for id, task in enumerate(task_names):\n",
    "    \n",
    "    if task in task_list:\n",
    "\n",
    "        sample_load_dir = load_model_dir + \"samples_for_mcmc/\"\n",
    "        posterior_save_dir = root + \"posteriors/waic/qm9/\" + task + \"/ae/\"\n",
    "\n",
    "        print(posterior_save_dir)\n",
    "\n",
    "        z_mus = np.load(sample_load_dir + \"embs_mu.npy\")[0:n_samples]\n",
    "        targets = np.load(sample_load_dir + \"all_targets.npy\")[0:n_samples,id]\n",
    "        targets = np.reshape(targets, (targets.shape[0], 1))\n",
    "        \n",
    "        torch_mus = torch.from_numpy(z_mus.astype(np.float32)).clone()\n",
    "        torch_ys = torch.from_numpy(targets.astype(np.float32)).clone()\n",
    "        torch_zs = torch_mus\n",
    "\n",
    "        batch_indices, n_batch = get_batch_index(np.arange(len(torch_ys)), batch_size=batch_size)\n",
    "\n",
    "        f1 = open(posterior_save_dir + \"posterior_params.pickle\",'rb')\n",
    "        posterior_params = pickle.load(f1)\n",
    "\n",
    "        model = MLP_Regressor(50, 128).to(device)\n",
    "        nlogp_list, var_list  = get_waics(model, torch_ys, torch_zs, batch_indices, posterior_params)\n",
    "        \n",
    "        nlogp_lists.append(nlogp_list)\n",
    "        var_lists.append(var_list)\n",
    "\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22b552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3510b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nlogp_list, var_list in zip(nlogp_lists, var_lists):\n",
    "    print(np.mean(nlogp_list) + np.mean(var_list), np.mean(nlogp_list), np.mean(var_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
